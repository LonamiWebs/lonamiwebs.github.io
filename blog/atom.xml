<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><title>Lonami's Site - My Blog</title><link href="https://lonami.dev/blog/atom.xml" rel="self" type="application/atom+xml"/><link href="https://lonami.dev/blog/"/><updated>2023-08-05T00:00:00+00:00</updated><id>https://lonami.dev/blog/atom.xml</id><entry xml:lang="en"><title>Downloading Minecraft modpacks without using adware launchers</title><published>2023-08-05T00:00:00+00:00</published><updated>2023-08-05T00:00:00+00:00</updated><link href="https://lonami.dev/blog/inspecting-tls-traffic/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/inspecting-tls-traffic/</id><content type="html">&lt;p>Every now and then, I get the urge to download and install a &lt;a href="https://www.minecraft.net/">Minecraft&lt;/a> modpack. Mind you, it's often the case that I go through the installation process, and only then realize I don't &lt;em>actually&lt;/em> want to play it, because I might not be in the mood to do so.&lt;/p>&lt;p>&lt;a href="https://www.curseforge.com/">CurseForge&lt;/a> has pretty much become the de-facto place to find and download mods. Or at least, that's the impression I get when looking for Minecraft mods.&lt;/p>&lt;p>There's just one tiny problem. They really, &lt;em>really&lt;/em> want you to use their desktop application, either from the &lt;a href="https://www.overwolf.com/">Overwolf&lt;/a> launcher or the "standalone".&lt;/p>&lt;p>It used to be the case that you were able to go into the Files of a specific mod project and download a single ZIP with all the &lt;code>.jar&lt;/code> mods. I can no longer find this. Some projects offer a "server" download, which is very handy, because it has all the mods, but it might not work directly for the client installation of your Minecraft launcher.&lt;/p>&lt;p>It seems your only choice is to painstakingly download the mods one by one, or use their ad-filled launchers. I haven't done a lot of analysis on these launchers, but it's probably safe to call them spyware. At least, the amount of ad-vendors they list when you open it to accept the privacy policy (because of course there's one, it's really just a webpage bundled into an executable file!) is concerning to me (the scrollbar is &lt;em>long&lt;/em>).&lt;/p>&lt;p>I don't like either option, so I'm making up a third and a fourth.&lt;/p>&lt;blockquote>&lt;p>This post is about me figuring the whole thing out, so it's a bit all over the place. You've been warned!&lt;/p>&lt;/blockquote>&lt;h2 id="automating-the-browser">&lt;a href="#automating-the-browser">Automating the browser&lt;/a>&lt;/h2>&lt;p>My first instinct was to automate the browser. Using something like &lt;a href="https://selenium-python.readthedocs.io">Selenium from Python&lt;/a> didn't sound too bad, since I'm familiar with Python already.&lt;/p>&lt;p>It shouldn't be too bad, either. It is possible to download a ZIP file for the modpack which contains some configuration overrides along with the list of mods. Nice!&lt;/p>&lt;p>In theory, all we would need to do is grab the link for the modpack we desire, click on the Download button, inspect the ZIP, and figure out the next URLs. Cool!&lt;/p>&lt;p>Except, the download starts automatically, so you probably want a &lt;a href="https://stackoverflow.com/a/29777967">custom download folder&lt;/a>. &lt;a href="https://stackoverflow.com/q/46470473">Experimenting with preference values at runtime is just as annoying&lt;/a>. As far as I can tell, there's no clean way to detect these, so one would instead watch the directory and figure out when new files are added. And there are cookie banners that block the view and can appear at any time.&lt;/p>&lt;p>Overall, automating web interaction sounds extremely annoying. It could be done, but it's not really fun to me. And the idea of running &lt;em>an entire web browser&lt;/em> to download a few files does not sit right with me.&lt;/p>&lt;h2 id="inspecting-the-apps-traffic">&lt;a href="#inspecting-the-apps-traffic">Inspecting the app's traffic&lt;/a>&lt;/h2>&lt;p>Now, to do this, of course we will need to install one of those two launchers. It sucks, but it's only temporary. So go ahead and install one (or wait until we have the rest of the tools in place). You could use a virtual machine for this, but I cannot be bothered.&lt;/p>&lt;p>We'll obviously need a tool that can help us reading the network traffic of the launcher. I've lost track on how many times I've installed and uninstalled &lt;a href="https://www.wireshark.org/">Wireshark&lt;/a>. It's really great, but I use it very sparingly and I am terrible at it, so I uninstall it after I'm done. Perhaps one day I'll finally get the hang of it and be able to do cool things.&lt;/p>&lt;p>Unfortunately, &lt;a href="https://wiki.wireshark.org/TLS">Wireshark alone won't do&lt;/a>. The launcher, like most "applications" nowadays is really just a browser in disguise connecting and accessing resources via HTTPS. It's that "S" in "HTTPS" that bothers me. Because the connection is secure, the traffic is encrypted, and I cannot be bothered to figure out how the application uses TLS to try and have it spit the secrets.&lt;/p>&lt;p>The &lt;a href="https://wiki.wireshark.org/TLS">Wireshark wiki does include some tips&lt;/a>. It would've been wise of me to at least try these first, such as running the &lt;code>CurseForge.exe&lt;/code> from Git Bash with &lt;code>SSLKEYLOGFILE=lol.log&lt;/code>, and it &lt;em>actually&lt;/em> creates the file! But this is not what I did, so we won't go this route. It's also less widely applicable, so it's nice to explore more "general" solutions.&lt;/p>&lt;p>I had recently read the &lt;a href="https://jade.fyi/blog/announcing-clipper/">announcement post for Clipper&lt;/a>, claiming to offer "TLS-transparent HTTP debugging for native apps". Sounds neat, that's just what I want! Except, &lt;a href="https://github.com/lf-/clipper#development">the easy way to build it is with Nix&lt;/a>. I could boot into my Linux partition and try to use CurseForge there. I could even try WSL. But neither are in a workable state, so those options are out.&lt;/p>&lt;p>After &lt;a href="https://stackoverflow.com/q/57306192">asking around the internet some more&lt;/a>, one might discover &lt;a href="https://www.netresec.com/?page=PolarProxy">PolarProxy&lt;/a>. Sounds like it could work! After download, we can run it with:&lt;/p>&lt;pre>&lt;code class="language-sh">PolarProxy -p 443,80 -o pcaplog -f proxyflows.log -x polarproxy.cer --httpconnect 10443 --certhttp 10080 --pcapoverip 57012
&lt;/code>&lt;/pre>&lt;p>Where:&lt;/p>&lt;ul>&lt;li>&lt;code>-p&lt;/code> sets the LISTEN-PORT "TCP port to bind proxy to" and DECRYPTED-PORT "TCP server port to use for decrypted traffic in PCAP". I'm not entirely sure what this does, but it was in their examples.&lt;/li>&lt;li>&lt;code>-o&lt;/code> sets the "output directory for hourly rotated PCAP files". Make sure you create that folder first! It makes it convenient to keep the traffic saved as we can later analyse it at our leisure.&lt;/li>&lt;li>&lt;code>-f&lt;/code> to "[l]og flow metadata for proxied sessions". Again, not sure what this is for. Probably not needed, but doesn't hurt.&lt;/li>&lt;li>&lt;code>-x&lt;/code> to "[e]xport DER encoded public CA certificate". We need this, because we want to Install Certificate to the Local Machine and to place it in the "Trusted Root Certification Authorities". This is explained in the same &lt;a href="https://www.netresec.com/?page=PolarProxy">PolarProxy&lt;/a> page. You shouldn't need this for subsequent runs though.&lt;/li>&lt;li>&lt;code>--httpconnect&lt;/code> to "[r]un local HTTP CONNECT proxy server". I had to use this when configuring proxy settings.&lt;/li>&lt;li>&lt;code>--certhttp&lt;/code> to "host the X.509 root CA cert". Probably not needed.&lt;/li>&lt;li>&lt;code>--pcapoverip&lt;/code> to "[s]erve decrypted TLS data as PCAP-over-IP". This makes it so that one can run Wireshark with &lt;code>wireshark -k -i TCP@127.0.0.1:57012&lt;/code>, which is convenient to do it live.&lt;/li>&lt;/ul>&lt;p>We can then Change proxy settings in our System settings by enabling Use a proxy server with the address shown from the &lt;code>ipconfig&lt;/code> command and this same port. (You probably could use &lt;code>127.0.0.1&lt;/code> too.)&lt;/p>&lt;p>Now! With all that done, if we run the CurseForge application, we should be generating some PCAP files or, alternatively, getting the decrypted traffic in Wireshark! Go ahead and download the modpack you want from it, and once it's done, our PCAP should be complete. You can then stop the capture to reduce the amount of information we need to go through.&lt;/p>&lt;h2 id="understanding-the-apps-traffic">&lt;a href="#understanding-the-apps-traffic">Understanding the app's traffic&lt;/a>&lt;/h2>&lt;p>Great, now we have a packet capture with a lot of data in it. How do we go about finding the right things in there?&lt;/p>&lt;p>We can then type &lt;code>http&lt;/code> into the filter to get suggestions for &lt;code>http.request.full_uri or http2.request.full_uri&lt;/code>. Using that, we can filter the packets and see some paths in the Info column, as it will display anything with a full URI in it.&lt;/p>&lt;p>You should see GET requests to places like &lt;code>/monsdk/electron/...&lt;/code> (how unsurprising) and, more interestingly, to &lt;code>/v1/minecraft/modloader&lt;/code>! Clicking here we can see that it's making the request to the host api.curseforge.com! You can go ahead and colorize the TCP conversation to see related messages. If you're confident that it looks promising, you can also Follow the HTTP conversation entirely (which is a bit slower because it needs to run a new filter).&lt;/p>&lt;p>If you look into the HTTP data Wireshark decoded, you will spot... bingo! The &lt;code>x-api-key&lt;/code> header! You can also see the &lt;code>User-Agent&lt;/code> among other headers, so we can fully recreate this on our own now!&lt;/p>&lt;p>Now that we know this &lt;code>x-api-key&lt;/code> is used, we can filter by it with &lt;code>http contains "API ID PASTED HERE"&lt;/code>, and we will get all the traffic sent using that API key. In my capture, it seems like there are two conversations.&lt;/p>&lt;p>Feel free to go ahead and right-click the columns to change your Column Preferences to display other information you might want to go through. Simply set the Field to anything you want from the &lt;code>http&lt;/code> namespace. And be sure to check the source and destination to know the direction a message is going in!&lt;/p>&lt;p>In my case, the second conversation is the one requesting the modpack I am interested in. Following that conversation and then displaying only the outgoing messages, it is very easy to see all the GET and POST requests being made:&lt;/p>&lt;pre>GET /v1/mods/MODID
GET /v1/mods/MODID/files/FILEID
POST /v1/mods
GET /v1/mods/ANOTHER-MODID/files/ANOTHER-FILEID
...
&lt;/pre>&lt;p>It seems like first it will request information about the mod (or modpack) you are interested in. This presumably returns a list of files, and likely the latest one is chosen. After a POST to &lt;code>/v1/mods&lt;/code>, a long trail of &lt;code>GET&lt;/code> to various files is made. We can save the conversation to a file to more easily analyze it (such as disabling word-wrap to easily see where requests start and end).&lt;/p>&lt;p>&lt;a href="https://stackoverflow.com/q/8903815">You might be able to use other tools to export the request-response&lt;/a>, but I just post-processed the text file a bit ot make it nicer to read (as there is no newline after response bodies). Nothing a simple &lt;code>([^\n])((?:GET|POST) /)&lt;/code> regexp can't fix.&lt;/p>&lt;p>After this, the rest is history! We managed to read through the encrypted traffic to extract the API key, which &lt;a href="https://github.com/Lonami/curseforge-downloader">can be used to write a custom downloader&lt;/a>. I won't go into the details, because the API could change any time, so that's left as an exercise to the reader. Enjoy!&lt;/p></content></entry><entry xml:lang="en"><title>In defense of stale-bots</title><published>2023-07-27T00:00:00+00:00</published><updated>2023-08-12T00:00:00+00:00</updated><link href="https://lonami.dev/blog/stalebots/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/stalebots/</id><content type="html">&lt;p>You are a young developer. You're only getting started, and learning new things as you go, but you love the idea of telling computers what to do. &lt;em>Automating&lt;/em> mundane tasks. It's really exciting to have this much freedom and control over something you own. Your only limit is your imagination!&lt;/p>&lt;p>Time goes by. You've come across GitHub quite a few times by now. A lot of code searches lead to GitHub projects created by other people. Other hobbyists, like you, doing what they love: &lt;em>coding&lt;/em>.&lt;/p>&lt;p>Until now, you've been keeping your code to yourself. It's not really nice code. The code structure is rather poor. It's difficult to add new features. It has bugs. Boy does it have bugs. But it works for you. It makes your day-by-day a little nicer.&lt;/p>&lt;blockquote>&lt;p>"What if I just shared this with others?"&lt;/p>&lt;/blockquote>&lt;p>You've taken a lot of, er, inspiration, from open source projects over the past year. A lot of them are very useful! But not &lt;em>quite&lt;/em> what you needed. On the other hand, &lt;em>your&lt;/em> project solves &lt;em>your&lt;/em> problems perfectly. By publishing your work, you would give back to that community. Share improvements. And others with a similar problem to yours would really value it!&lt;/p>&lt;p>So you do it. You wake up the next day, and the project seems to have piqued the interest of many. That's… really awesome! It's a nice feeling.&lt;/p>&lt;p>Not long after, pull requests start coming in. New feature additions, bug fixing, improving performance… And so do the issues.&lt;/p>&lt;p>You knew the project wasn't perfect. The code had certainly grown a lot, and not in a very nice way. But it worked. It had the features you needed. It was good enough.&lt;/p>&lt;p>You begin nicely answering questions in the issue tracker. Accepting most new features. Fixing bugs you never would've encountered yourself.&lt;/p>&lt;p>You start a new job as a junior programming. How exciting! And there you meet your significant-other. A wonderful person in all aspects. You spend a lot of time with them and learning in your job.&lt;/p>&lt;p>Time goes by. You're starting to grow a bit tired of this GitHub thing. The project has attracted &lt;em>a lot&lt;/em> of attention. Many new issues are being created every day. Some extremely high quality! But plenty downright insulting you. You begin to close issues you know you won't work on.&lt;/p>&lt;p>This project wasn't your job. It never was. It was a hobby. A passion project. Which worked perfectly fine for you.&lt;/p>&lt;p>The constant notifications still bother you. You've disabled them. But the ever-growing issue count is always in the back of your mind. Thinking you need to bring it down. People &lt;em>want&lt;/em> to use your work! You &lt;em>want&lt;/em> to have a functional project! But you no longer have time.&lt;/p>&lt;p>You come across this "stale bot". It can &lt;em>automate&lt;/em> the process of closing down issues! Being the automation-lover you are, you begin using it in a blink. Then, people can continue benefiting from your work, and you can stop worrying about having to deal with all the bug reports and reviews.&lt;/p>&lt;p>People are now angry their issue is closed without explanation. They're opening duplicates. Can't they see, this was just a hobby? This isn't your job! Why won't they realize this is &lt;em>your&lt;/em> project? You don't have the time to fix all the issues. The stale bot is simply automating the process.&lt;/p>&lt;p>This isn't for you. The situation is frustrating and annoying to deal with. You take the project down. After all, it doesn't need to be online for you to make full use of it.&lt;/p>&lt;p>You did get feedback. You learnt a few things. The code is more performant, even if a bit harder to understand at places. There are new features, which… you don't really have a need for, but are cool, I guess. But you're glad you don't need to deal with the noise any longer.&lt;/p>&lt;hr>&lt;blockquote>&lt;p>It is frustrating when you spend a lot of time on something for it to be ignored. Well-detailed bug reports, with stack traces, bisections pointing to the problem. Large patches for a new feature or a bug fix. There's progress, even if a little slow. Why can't the author have the decency of at least reading through?&lt;/p>&lt;/blockquote>&lt;p>It is probably not their job.&lt;/p>&lt;blockquote>&lt;p>Why did they post their work online if they were not willing to build a commuity?&lt;/p>&lt;/blockquote>&lt;p>They may have had a different goal in mind. They could simply want to share the work. Not deal with users, some of which have strong opinions and reflect it with equally strong language.&lt;/p>&lt;blockquote>&lt;p>There was a lot of high quality issues!&lt;/p>&lt;/blockquote>&lt;p>And a large amount of angry comments. Not everyone has such thick skin. It gets to you. Your brain remembers bad experiences.&lt;/p>&lt;blockquote>&lt;p>Couldn't they just lock the issues? Make it clear it's a won't-fix.&lt;/p>&lt;/blockquote>&lt;p>Maybe. The thought may not have crossed their mind. They may have weighed the pros and cons, and perhaps they wanted discussion to still happen, and take on the more interesting suggestions. They may only read through sparingly, picking up on a few. The rest would be closed automatically.&lt;/p>&lt;blockquote>&lt;p>Why did not they make their stance clear? Make it clear you're not accepting contributions.&lt;/p>&lt;/blockquote>&lt;p>Why should they? They're just sharing their work. They'll work on things they find appealing. They don't want to deal with codes of conduct, educating users, writing documentation, or fixing obscure bugs. They just wanted to share their work.&lt;/p>&lt;blockquote>&lt;p>They're willing to accept patches. Why not leave the issues open so others can pick them up?&lt;/p>&lt;/blockquote>&lt;p>Perhaps they just want an easy way to reduce clutter in the issues section. To keep only the ones the maintainer is actually interested in.&lt;/p>&lt;blockquote>&lt;p>The amount of issues wouldn't become a problem if they were triaged properly. Adding a tag is very easy!&lt;/p>&lt;/blockquote>&lt;p>But it is still a non-zero amount of effort. You still need to think about it. Read through. Actively do it. And they may simply have no desire to do so.&lt;/p>&lt;blockquote>&lt;p>The maintainer is just lazy. Malpractice.&lt;/p>&lt;/blockquote>&lt;p>But it's &lt;em>their&lt;/em> issue tracker for &lt;em>their&lt;/em> project. Wanting to keep a small amount of issues open is not necessarily evil. They may simply want to share code, not spend time moderating and triaging.&lt;/p>&lt;blockquote>&lt;p>The issue tracker is not only for the maintainer to use, it's for the users too!&lt;/p>&lt;/blockquote>&lt;p>That is not an universal truth. The maintainer gets the final say on how their project is run. If they want public issues and sparingly work on some on their free time, they can do so. If the project is large enough, unofficial communities can form elsewhere. The place to share knowledge does not necessarily need to be "official".&lt;/p>&lt;blockquote>&lt;p>The maintainer does not understand their responsibilities. They should hand over their hat if they're not willing to deal with issues properly.&lt;/p>&lt;/blockquote>&lt;p>The maintainer is simply sharing their work. There's no responsibility to keep issues open. This might be an unspoken "rule" of open source, but it's actually just a strong convention. The maintainer decides what "properly" means for their project. The existence of a stale bot should be clue enough on the maintainer's stance. The maintainer can keep sharing their work their way while forks exist.&lt;/p>&lt;blockquote>&lt;p>Closing issues as stale does not mean the issue is gone. They still exist.&lt;/p>&lt;/blockquote>&lt;p>Certainly. But when browsing through the issues, there is no denying that there is a lot less clutter. And if your goal is to take a look every now and then, it works great.&lt;/p>&lt;blockquote>&lt;p>Stale bots waste everyone's time. It's not always obvious that they are being used, and those interested need to actively keep the issues open to prevent automatic closing.&lt;/p>&lt;/blockquote>&lt;p>That's a choice the users make. The maintainer's stance is clear: the stale bot runs on the issue board. It is not the maintainer's problem that some users insist, even after it's clear that they maintainer doesn't care.&lt;/p>&lt;p>The lack of discoverability on whether stale bots are being used or not is a fair point. However, if the repository lacks contribution guidelines, you might want to spare a minute to check for the existence of a "stale" label, or do a quick search to figure out if issues are closed as "stale". By doing this, you don't need to commit to creating well-detailed reports if you're not willing to put up with the fact that it might just get closed without the author reading it.&lt;/p>&lt;blockquote>&lt;p>Stale bots create fatigue for everyone, as duplicate issues are created and those watching get pinged. This is rude on part of the maintainer.&lt;/p>&lt;/blockquote>&lt;p>Yes, this is annoying for the users. But not necessarily intentional malice from the maintainer. It is simply how they chose to automate a process. Open source has a few unspoken rules. Perhaps our junior developer was unaware of them. It is possible to educate them. Explain why you're against stale bots, and politely ask them to clarify what their stance is.&lt;/p>&lt;blockquote>&lt;p>Hobby projects are not an excuse to mistreat the community. Maintainers may not owe us support, but they owe us respect.&lt;/p>&lt;/blockquote>&lt;p>The maintainer may not have wanted to have a community in the first place. Social rules may say this behaviour is impolite. This is a fair point. Ask the maintainer to make it clear what their stance is. This question is uncomfortable, so it may happen that the topic is avoided. Whatever the maintainer's answer is, remember they have the final say on how they run their project. You should respect this choice, even if you strongly dislike it and it makes you uncomfortable. Their project might not be for you.&lt;/p>&lt;hr>&lt;p>As unsatisfying as it is, it's a choice the maintainer can make. They may be aware of this problem and actively try to document how contributions are handled. But they don't have to. GitHub enables the issue tracker by default. The maintainer may want to keep it for their own use. They may not want to build a community.&lt;/p>&lt;p>Users have their own expectations. There's an issue tracker, so I can report bugs, right? Well, yes. You can report issues. But that doesn't mean the maintainer has to read them. And this does not make them a bad person.&lt;/p>&lt;p>Forking is always an option. Become a maintainer who is more engaged in building a community yourself. Triage the issues. This is not for everyone.&lt;/p>&lt;p>Stale bots are simply automating a task. One solution of many. And like every solution, it comes with trade-offs. Yes, it feels more "humane" for the maintainer to close the report as "won't-fix" with an explanation. Not everyone has time for that, or the temperament to do so. The maintainer does not necessarily feel "shame" for having a lot of issues open. They might simply want to keep a small amount of them open.&lt;/p>&lt;p>It's true. The maintainer may not care about your issues. But those are &lt;em>your&lt;/em> issues, not &lt;em>theirs&lt;/em>. They're free to spend their free time however they wish. And if they wish, they can choose to ignore and close said issues, while keeping a public project page up. If the maintainer's stance is not clear, take the opportunity to educate them on why it's important to make it clear. There are unspoken rules they may not be aware of.&lt;/p>&lt;p>If your expectations don't match those of the maintainer, don't get angry at the maintainer. You can consider their use of stale bots as their stance on the matter. You can disagree. Take a step back. Read the contribution rules and don't engage if you disagree. Save yourself a bad time.&lt;/p>&lt;p>To make it clear: this post's protagonist is a hobbyst. Of course, everyone's situation is different, and stale bots used by companies are a whole other matter. But don't go making other people's lives miserable. There's enough of that already. Some just want to code, not build a community. Harassing maintainers is never okay.&lt;/p>&lt;hr>&lt;p>Personally, I haven't used stale bots before, and don't plan to in the near future. I haven't burnt out on answering issues just yet. (Plus, I find the whole process extremely dull, even if they're easy to "set up".)&lt;/p>&lt;p>When I was getting started in the open source world, I was thrilled to get bug reports and be able to answer. And not just bugs, but questions too. Code reviews, it was great!&lt;/p>&lt;p>I did eventually get tired. Some of my past answers were starting to be clearly impolite. I've been a dick to people. Sorry about that.&lt;/p>&lt;p>I've now realized angry answers help nobody, and try to at least provide some context, before closing issues myself if it's not actionable. The quality of my answer still depends on the quality of the question. But I really try to remain polite.&lt;/p>&lt;p>I think this is the best a maintainer can do. But I acknowledge it takes a lot of time, temper, dedication. And so, I can understand those who choose to use stale bots instead. They may not be aware of all the trade-offs and implications, but they can be educated.&lt;/p>&lt;p>Respect their choice, and keep it cool.&lt;/p></content></entry><entry xml:lang="en"><title>Writing our own Cheat Engine: Multilevel pointers</title><published>2021-08-20T00:00:00+00:00</published><updated>2021-10-17T00:00:00+00:00</updated><link href="https://lonami.dev/blog/woce-8/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/woce-8/</id><content type="html">&lt;blockquote>&lt;p>Or: Dissecting Cheat Engine's Pointermaps&lt;/p>&lt;/blockquote>&lt;p>This is part 8 on the &lt;em>Writing our own Cheat Engine&lt;/em> series:&lt;/p>&lt;ul>&lt;li>&lt;a href="/blog/woce-1">Part 1: Introduction&lt;/a> (start here if you're new to the series!)&lt;/li>&lt;li>&lt;a href="/blog/woce-2">Part 2: Exact Value scanning&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-3">Part 3: Unknown initial value&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-4">Part 4: Floating points&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-5">Part 5: Code finder&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-6">Part 6: Pointers&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-7">Part 7: Code Injection&lt;/a>&lt;/li>&lt;li>Part 8: Multilevel pointers&lt;/li>&lt;/ul>&lt;p>In part 7 we learnt how to allocate memory in the remote process, and how we can use that memory to inject our own code for the remote process to execute. Although we didn't bother with an assembler, it shows just how strong this technique can really be. With it we've completed the Read, Write and eXecute trio!&lt;/p>&lt;p>Now it's time to find how we can make our work persist. Having to manually find where some value lives is boring. If the game is able to find the player's health for its calculations, no matter how many times we restart it, then why can't we?&lt;/p>&lt;p>This entry will review how Cheat Engine's pointermaps work, analyze them, and in the end we will approach the problem in our own way. Because this post is quite lengthy, here's a table of contents:&lt;/p>&lt;ul>&lt;li>&lt;a href="#multilevel-pointers">Multilevel pointers&lt;/a>&lt;/li>&lt;li>&lt;a href="#pointers-pointing-points">Pointers pointing points&lt;/a>&lt;/li>&lt;li>&lt;a href="#pointer-maps">Pointer maps&lt;/a>&lt;/li>&lt;li>&lt;a href="#single-threaded-naive-approach">Single-threaded naive approach&lt;/a>&lt;/li>&lt;li>&lt;a href="#speeding-up-the-scan">Speeding up the scan&lt;/a>&lt;/li>&lt;li>&lt;a href="#working-out-a-poc">Working out a PoC&lt;/a>&lt;/li>&lt;li>&lt;a href="#doing-more-for-better-runtime-speed">Doing more for better runtime speed&lt;/a>&lt;/li>&lt;li>&lt;a href="#doing-less-for-better-runtime-speed">Doing less for better runtime speed&lt;/a>&lt;/li>&lt;li>&lt;a href="#retrospective">Retrospective&lt;/a>&lt;/li>&lt;li>&lt;a href="#finale">Finale&lt;/a>&lt;/li>&lt;/ul>&lt;h2 id="multilevel-pointers">&lt;a href="#multilevel-pointers">Multilevel pointers&lt;/a>&lt;/h2>&lt;details open>&lt;summary>Cheat Engine Tutorial: Step 7&lt;/summary>&lt;blockquote>&lt;p>This step will explain how to use multi-level pointers.&lt;/p>&lt;p>In step 6 you had a simple level-1 pointer, with the first address found already being the real base address. This step however is a level-4 pointer. It has a pointer to a pointer to a pointer to a pointer to a pointer to the health.&lt;/p>&lt;p>You basicly do the same as in step 6. Find out what accesses the value, look at the instruction and what probably is the base pointer value, and what is the offset, and already fill that in or write it down. But in this case the address you'll find will also be a pointer. You just have to find out the pointer to that pointer exactly the same way as you did with the value. Find out what accesses that address you found, look at the assembler instruction, note the probable instruction and offset, and use that, and continue till you can't get any further (usually when the base address is a static address, shown up as green).&lt;/p>&lt;p>Click Change Value to let the tutorial access the health. If you think you've found the pointer path click Change Register. The pointers and value will then change and you'll have 3 seconds to freeze the address to 5000.&lt;/p>&lt;p>Extra: This problem can also be solved using a auto assembler script, or using the pointer scanner.&lt;/p>&lt;p>Extra2: In some situations it is recommended to change ce's codefinder settings to Access violations when encountering instructions like mov eax,[eax] since debugregisters show it AFTER it was changed, making it hard to find out the the value of the pointer.&lt;/p>&lt;p>Extra3: If you're still reading. You might notice that when looking at the assembler instructions that the pointer is being read and filled out in the same codeblock (same routine, if you know assembler, look up till the start of the routine). This doesn't always happen, but can be really useful in finding a pointer when debugging is troublesome.&lt;/p>&lt;/blockquote>&lt;/details>&lt;h2 id="pointers-pointing-points">&lt;a href="#pointers-pointing-points">Pointers pointing points&lt;/a>&lt;/h2>&lt;p>If you say "pointer" enough, you'll end up having &lt;a href="https://en.wikipedia.org/wiki/Semantic_satiation">semantic satiation&lt;/a>. My goal by the end of this post is that you actually get to experience that phenomenon. Anyway, no real program would actually have pointers pointing to pointers which themselves point to a different point (and, you've guessed it, this point points to another pointer pointing to yet another pointer), right? That would be silly. Why would I have a value behind, say, 5 references? I'm not writing Rust code like &lt;code>&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;value&lt;/code>.&lt;/p>&lt;p>But I am sure you are much more likely to be doing something like &lt;code>game.world.areas[i].players[j].regen()&lt;/code>. And there's a lot of references there:&lt;/p>&lt;pre> game.world.areas[i].players[j].regen()
^    ^           ^^^        ^^^      ^^
|    |            |          |        \called by &amp;amp;mut ref
|    |            |           \taking by &amp;amp;mut ref
|    |             \taking by &amp;amp;mut ref
|     \accessing by &amp;amp;mut ref
 \this game is actually in a `Box` (so you're accessing it behind other ref)
&lt;/pre>&lt;p>Each of those is a different structure, with many fields each (for example, the areas also contain enemies and items dropped in different vectors). When there's more than one field, the pointer often points &lt;span class="dim">(sorry)&lt;/span> to the beginning of the structure, and you need to add some offset to reach the desired field.&lt;/p>&lt;pre>&lt;code class="language-rust">#[repr(C)] // &amp;lt;- used for clarity to get precise offsets
struct Area {
    /* offset 00 */ pub monsters: Vec&amp;lt;Monster&amp;gt;,
    /* offset 24 */ pub items: Vec&amp;lt;Item&amp;gt;,
    /* offset 48 */ pub kill_goal: u32,
    /* offset 52 */ pub players: Vec&amp;lt;Player&amp;gt;,
}
&lt;/code>&lt;/pre>&lt;p>If you have a reference to some &lt;code>&amp;amp;Area&lt;/code> but access the &lt;code>players&lt;/code> field, you actually need to read from &lt;code>[addrof area + 52]&lt;/code>. This is why the tutorial step suggests to "look at the instruction", because it very likely encodes the offset somewhere (if not directly, nearby). Looking at instructions to determine offsets works because normally people want their games to be fast, so they make good use of the available CPU instructions. Obfuscating hot code could slow a game way too much (but it may still be done to some degree!).&lt;/p>&lt;p>To complicate things further, the same reference to one thing may be stored in multiple locations, making it possible to find your goal address through many different paths. In Rust, this happens when you have a shared pointer, such as &lt;code>Rc&amp;lt;T&amp;gt;&lt;/code> or &lt;code>Arc&amp;lt;T&amp;gt;&lt;/code> (or if you go the &lt;code>unsafe&lt;/code> route and have the same &lt;code>*const T&lt;/code> value scattered around).&lt;/p>&lt;p>The tutorial suggests to complete this step in the same way we did back in step 6. Add a watchpoint, find out what code is accessing this address, look around the disassembly, and write down your findings. Although this technique definitely is a valid way to approach the problem, it is quite tedious and error-prone. It would be hard to fully automate this, because who knows what shenanigans the code could be doing to calculate the right pointer and offset! Sure, Cheat Engine's tutorial is not going to purposedly obfuscate the instructions manipulating our target address. But other programs may be dynamically reading the offset from somewhere.&lt;/p>&lt;p>This technique is also pretty intrusive, because it requires us to attach ourselves as the debugger of the victim program. I hardly have any experience writing debuggers, leave alone writing them in a way that makes them hard to detect! I'm sure it's a very interesting topic, but it's not the current topic at hand, so we'll leave it be. If you know of good resources for this, let me know so I can link them here. Furthermore, we've already gone this route before, so it would be silly to repeat that here, just to end up with a longer version of it.&lt;/p>&lt;p>You may have noticed the "extra" information the tutorial step provides:&lt;/p>&lt;blockquote>&lt;p>Extra: This problem can also be solved using a auto assembler script, or using the pointer scanner.&lt;/p>&lt;/blockquote>&lt;p>We've already done the "auto assembler script" part before (in part 7). I'm not sure how you would approach this problem with that technique. Maybe one could dig until the base pointer, and replace whatever read is happening there with a hardcoded value so that the game thinks that's what it actually read? I'm not sure if it would be possible to solve with injected code without following the entire pointer chain. Or maybe you could instead patch the write to use a fixed value. But anyway, we're not doing that, no manual work will happen on this one. No, we're interested in the &lt;span class="rainbow">pointer scanner&lt;/span>&lt;a href="#fn:1">&lt;sup id="fnref:1">↪1&lt;/sup>&lt;/a>.&lt;/p>&lt;h2 id="pointer-maps">&lt;a href="#pointer-maps">Pointer maps&lt;/a>&lt;/h2>&lt;p>Once you find a value in Cheat Engine, you have the option to "Generate pointermap". This will prompt you to select a file where the generated pointermap will be stored, in &lt;code>.scandata&lt;/code> format (along with its &lt;code>.addresslist&lt;/code>). If you're scanning a lot of memory, you will get to see a progress window (otherwise, it will be pretty much instant), along with some statistics:&lt;/p>&lt;ul>&lt;li>Unique pointervalues in target.&lt;/li>&lt;li>Scan duration.&lt;/li>&lt;li>Paths evaluated.&lt;/li>&lt;li>Paths / seconds.&lt;/li>&lt;li>Static and dynamic queue sizes.&lt;/li>&lt;li>Results found.&lt;/li>&lt;li>Time spent writing.&lt;/li>&lt;li>Lowest known path.&lt;/li>&lt;/ul>&lt;p>My guess for "unique pointervalues" is the set of pointers found so far, and the queues may be used by the way the scan is done, presumably hinting at an implementation detail. The rest of information is pretty much self-explanatory (lowest known path probably is the shortest "pointer path" found so far). When I talk about "pointer paths", I'm referring to a known, static base address that won't change, with a list of offsets that, when followed, arrive at some desired value in memory (for example, your character's health). In essence, it's a path made out of pointers, with a new pointer to follow at each step. The solution found with Cheat Engine for this tutorial step makes for a good example:&lt;/p>&lt;pre>&lt;code class="language-rust">let offsets = [10, 18, 0, 18]; // list of offsets
let mut addr = EXE_BASE_ADDR + 0x00306B00; // current addr (initialized to base addr)

// follow the path:
// addr_at("Tutorial-x86_64.exe"+00306B00) -&amp;gt; 0165F260
// addr_at(10+0165F260) -&amp;gt; 01690000
// addr_at(18+01690000) -&amp;gt; 01677790
// addr_at( 0+01677790) -&amp;gt; 01601A80
//         18+01601A80  -&amp;gt; 01601A98
for offset in offsets {
    addr = process.read_addr_at(addr);
    addr += offset;
}

let value = process.read_desired_value_at(addr);
&lt;/code>&lt;/pre>&lt;p>Let's get back to talking about Cheat Engine's scan. After generating the pointermap, the idea is to force the game to change the pointer path (for example, by closing and re-opening the game again) and find your target value once again. For the tutorial, we can just change the pointer. After we find the value again, we do a "Pointer scan for this address". The "Pointerscanner options" has a checkbox to "Compare results with other saved pointermap(s)". Running this seems to generate a second pointermap, and after some magic, both are compared and the one true pointer path is found&lt;a href="#fn:2">&lt;sup id="fnref:2">↪2&lt;/sup>&lt;/a>.&lt;/p>&lt;p>There's a bunch of files generated:&lt;/p>&lt;ul>&lt;li>&lt;code>.scandata&lt;/code> is a bunch of binary data that I have no idea what could contain.&lt;/li>&lt;li>&lt;code>.scandata.addresslist&lt;/code> seems to contain &lt;code>ADDRESS=DESCRIPTION&lt;/code>, one per line, of the addresses you had "saved" when the first pointermap was made. This seems to be used when performing the pointer scan and comparing results (so that you can choose the address you want to compare it to).&lt;/li>&lt;li>&lt;code>.PTR&lt;/code> is 1201 bytes (such an strange size) and seems to contain a list of the modules loaded by the program&lt;/li>&lt;li>&lt;code>.PTR.results.#&lt;/code>, where &lt;code>#&lt;/code> is a number between 0 and 8, are mostly empty files (except for 4 which is 14 bytes).&lt;/li>&lt;/ul>&lt;p>Now, there's this one option under "advanced" known as "Compress pointerscan file". The long description reads (emphasis mine):&lt;/p>&lt;blockquote>&lt;p>Compresses the generated .PTR files &lt;em>slightly&lt;/em>, so they take less space on the disk and less time writing to disk. Most of the time the bottleneck of a pointerscan is disk writing, so it is recommended to use this option.&lt;/p>&lt;/blockquote>&lt;p>Slightly, huh. Well, for the tutorial, which is using (according to the task manager) 2'364 K, running the scan with the compression disabled generates roughly &lt;em>5 gigabytes&lt;/em> across the nine &lt;code>.PTR.results&lt;/code>. That's… not too shabby for a "slight" compression.&lt;/p>&lt;p>Let's guess what those files are storing. The screen with the results does say it found uh, well you know, the usual, 122'808'639 pointer paths. This is the result of scanning for an address. That's (very) roughly 40 bytes per path, and assuming 8 bytes for each address/offset, equates to 5 hops. I guess the math kind of checks out?&lt;/p>&lt;p>On the other hand, "generate pointermap" just spits out the &lt;code>.scandata&lt;/code> at roughly 60KB. So these two options are definitely doing something very, very different. And I have no idea what either of these are doing. Let's dive into Cheat Engine's "advanced options" for the pointer scan to try and gain some insight. I will be listing all the settings available in the scan form and adding a bit on whether I think they're useful to us or not.&lt;/p>&lt;h1 id="scan-options">&lt;a href="#scan-options">Scan options&lt;/a>&lt;/h1>&lt;p>The &lt;em>Pointerscanner scanoptions&lt;/em> window has plenty of options that are extremely valuable to gain insight of what's going on behind the scenes without having to dig into the code. At the very top we have three modes:&lt;/p>&lt;ul>&lt;li>Scan for address&lt;/li>&lt;li>Scan for addresses with value&lt;/li>&lt;li>Generate pointermap&lt;/li>&lt;/ul>&lt;p>The third option is what we use during the first step, and the first option for the second step.&lt;/p>&lt;p>When using either the first or second mode, you can also check &lt;em>Use saved pointermap&lt;/em> which you can use if you have created a pointermap on a system that runs the game, but you wish to do the scan on another system (or multiple systems).&lt;/p>&lt;p>With the first or second mode, you can also &lt;em>Compare results with other saved pointermap(s)&lt;/em> which, when ticked, lets you add other pointermaps which will be used to verify that the pointers it finds are correct. You do have to fill in the correct address for each pointermap provided, and one should expect at least the size of the game itself in memory for every pointermap used. We know this step is key, but we don't know how that comparison could be possibly done.&lt;/p>&lt;p>The checkbox &lt;em>Include system modules&lt;/em> I presume also scans in system modules and not just game's own modules, which is useful if you suspect the value lives elsewhere. Not helpful for us right now, but good to know this is a possibility.&lt;/p>&lt;p>Apparently, Cheat Engine can improve pointerscan with gathered heap data. The heap is used to figure out the offset sizes, instead of blindly guessing them. This should greatly improve speed and a lot less useless results and give perfect pointers, but if the game allocates gigantic chunks of heap memory, and then divides it up itself, this will give wrong results. If you only allow static and heap addresses in the path, when the address searched isn't a heap address, the scan will return 0 results. I do not really know how Cheat Engine gathers heap data here to improve the pointerscan, but since this mode is unchecked by default, we should be fine without it.&lt;/p>&lt;p>By default, the pointer path may only be inside the region 0000000000000000-7FFFFFFFFFFFFFFF. There's a fancier option to limit scan to specified region file, which presumably enables a more complex, discontinuous region. Or you can filter pointers so that they end with specific offsets&lt;a href="#fn:15">&lt;sup id="fnref:15">↪15&lt;/sup>&lt;/a>. Or you can indicate that the base address must be in specific range, which will only mark the given range as valid base address (this reduces the number of results, and internally makes use of the "Only find paths with a static address" feature by marking the provided range as static only, so it must be enabled).&lt;/p>&lt;p>Pointers with read-only nodes are excluded by default, so the pointerscan will throw away memory that is readonly. When it looks for paths, it won't encounter paths that pass through read only memory blocks. This is often faster and yields less useless results, but if the game decides to mark a pointer as readonly Cheat Engine won't find it.&lt;/p>&lt;p>Only paths with a static address are "found". The pointerscan will only store a path when it starts with a static address (or easily looked up address). It may miss pointers that are accessed through special paths like thread local storage (but even then they'd be useless for Cheat Engine as they will change). When it's disabled, it finds every single pointer path. Now, this bit is interesting, because the checkbox talks about "find", but the description talks about "store", so we can guess there's no trick to only "finding" correct ones. It's going to find a lot of things, and many of them will be discarded. It also mentions thread-local storage and how we probably shouldn't worry about it.&lt;/p>&lt;p>Cheat Engine won't stop traversing a path when a static has been found by default. When the pointerscanner goes through the list of pointervalues with a specific value, this will stop exploring other paths as soon as it encounters a static pointer to that value. By enabling this option, some valid results could be missed. This talks about "pointervalues with a specific value", which is a bit too obscure for me to try and make any sense out of it.&lt;/p>&lt;p>Addresses must be 32-bit alligned. Only pointers that are stored in an address dividable by 4 are looked at. When disabled, it won't bother. It enables fast scans, but "on some horrible designed games that you shouldn't even play it won't find the paths". Values in memory are often aligned, so reducing the search space by 75%&lt;a href="#fn:16">&lt;sup id="fnref:16">↪16&lt;/sup>&lt;/a> is a no-brainer.&lt;/p>&lt;p>Cheat Engine can optionally verify that the first element of pointerstruct must point to module (e.g vtable). Object oriented programming languages tend to implement classobjects by having a pointer in the first element to something that describes the class. With this option enabled, Cheat Engine will check if it's a classobject by checking that rule. If not, it won't see it as a pointer. It should yield a tremendous speed increase and almost perfect pointers, but it doesn't work with runtime generated classes (Java, .NET). Optionally, it can also accept non-module addresses. I have no idea how this is achieved, but since it's disabled by default, we should be able to safely ignore it.&lt;/p>&lt;p>By default, no looping pointers are allowed. This will filter out pointerpaths that ended up in a loop (for example, base-&amp;gt;p1-&amp;gt;p2-&amp;gt;p3-&amp;gt;p1-&amp;gt;p4 since you could just as well do base-&amp;gt;p1-&amp;gt;p4 then, so throw this one away (base-&amp;gt;p1-&amp;gt;p4 will be found another way)). This gives less results so less diskspace used, but slightly slows down the scan as it needs to check for loops every single iteration. The thought of how much data the 5GB scan would generate without this option makes me shiver.&lt;/p>&lt;p>Cheat Engine will allow stack addresses of the first thread(s) to be handled as static, which allows the stack of threads to be seen as static addresses by the pointerscan. The main thread is always a sure bet that it's the first one in the list. And often the second thread created is pretty stable as well. With more there's a bigger chance they get created and destroyed randomly. When a program enters a function and exits it, the stack pointer decreases and increases, and the data there gets written to. The farther the game is inside function calls, the more static the older data will be. With max stack offset you can set the max size that can be deemed as static enough (the max stackoffset to be deemed static enough is 4096 by default). It finds paths otherwise never found, but since there are more results, there's more diskspace.&lt;/p>&lt;p>Cheat Engine by default will look at the stacks of two threads, from oldest to newest. It indicates "the total number of threads that should be allowed to be used as a stack lookup. Thread 1 is usually the main thread of the game, but if that one spawns another thread for game related events, you might want to have that secondary thread as well. More threads is not recommend as they may get created and destroyed on the fly, and are therefore useless as a lookup base, but it depends on the game".&lt;/p>&lt;p>Unfortunately, this option is enabled by default, so it seems pretty important, and we might need to put some work into figuring out how "stacks" are found. However, this would mean that some "base" object (like a &lt;code>Game&lt;/code> instance) is passed down by reference hundreds of calls, which seems pretty annoying just to have access to something that effectively acts like a global, so hopefully games don't make use of this.&lt;/p>&lt;p>This can be taken a step further, and consider stack addresses as ONLY static address, if you wish to only find pointer paths with a stack address. It must be combined with "Only find paths with a static address" (default on) else this option will have no effect. You'll only get paths from the stack, but you don't get get paths from random DLL's or the executable.&lt;/p>&lt;p>The pointerscan file is by default compressed. Cheat Engine Compresses the generated .PTR files slightly so they take less space on the disk and less time writing to disk. Most of the time the bottleneck of a pointerscan is disk writing, so it is recommended to use this option (which was not available in older versions).&lt;/p>&lt;p>Only positive offsets are scanned by default, but Cheat Engine may optionally scan for negative offsets as well (although it can not be used in combination with compressed pointerscan files; this seems to hint that the compression assumes only positive values).&lt;/p>&lt;p>On my machine, 9 threads are scanning by default with a maximum offset value of 4095 and a maximum level (depth) of 7. The maximum different offsets per node are 3. When the pointerscan looks through the list of pointers with a specific value, it goes through every single pointer that has that value. Every time increasing the offset slightly. With this feature enabled the pointerscan will only check the first few pointers with that value. This is extremely fast, and the results have the lowest pointer paths possible, but you'll miss a lot of pointers that might be valid too. I think this description is key, as it clearly says what the pointerscan does and maybe even how it works (although it sounds a bit inefficient, so Cheat Engine probably uses other tricks).&lt;/p>&lt;p>Cheat Engine clearly knows this process is expensive, so it optionally allow scanners to connect at runtime. This opens a port that other systems running the pointerscanner can connect to and help out with the scan. Or it can connect to pointerscan node, which will send a broadcast message on the local network which will tell pointer scanner systems to join this scan if they are set to auto join (or "Setup specific IP's to notify" to notify systems of this scan that are outside of the local network).&lt;/p>&lt;p>And that's all! In summary:&lt;/p>&lt;ul>&lt;li>Assume addresses are 32-bit aligned (maybe even 64-bit).&lt;/li>&lt;li>Discard paths that don't end in a static address (bonus points if the top of the stack for the firsts two threads are also considered).&lt;/li>&lt;li>Ignore read-only memory.&lt;/li>&lt;li>Limit the number of offsets per pointer to something small like 3, and give up after reaching a depth greater than 7.&lt;/li>&lt;li>Limit the offset range to &lt;code>0..4096&lt;/code>.&lt;/li>&lt;li>Use multiple threads.&lt;/li>&lt;/ul>&lt;h2 id="single-threaded-naive-approach">&lt;a href="#single-threaded-naive-approach">Single-threaded naive approach&lt;/a>&lt;/h2>&lt;p>After playing around a bit more with Cheat Engine's scans, I realized the 14 bytes of the &lt;code>.PTR.results.4&lt;/code> is because the process literally finds a single path which it places there. Running the process with compression and no previous scan to compare it to spits out roughly 750MB (so the compression does go from 5GB to 750MB, that's a lot more reasonable).&lt;/p>&lt;p>In any case, we're with the &lt;code>.scandata&lt;/code> now. I really do wonder what could it possibly contain? I really doubt it's the pointer paths found, because then it would be huge. Perhaps it contains the memory regions? That would make some sense, since the sibling &lt;code>.addresslist&lt;/code> &lt;em>is&lt;/em> a list of all the loaded modules. Maybe the &lt;code>.scandata&lt;/code> contains the memory regions for all of those loaded modules.&lt;/p>&lt;p>For the first time in this series, I really don't know how Cheat Engine could be working behind the scenes. Is it really evaluating millions of &lt;em>paths&lt;/em>? That's a lot of memory, no matter how you encode it! I'm really impressed at the processing speed if this is in fact the case. Let's see how a naive approach for that could look like&lt;a href="#fn:3">&lt;sup id="fnref:3">↪3&lt;/sup>&lt;/a>.&lt;/p>&lt;p>We start off with a single address, the address of a particular value we care about in memory (for example, the player's health). This address is an 8-byte number (which for us is an &lt;code>usize&lt;/code>), so we can look for pointer-values (values in memory that look like a pointer to a certain address) that point to this address (or close enough). Let's call this &lt;code>goal_addr&lt;/code>.&lt;/p>&lt;p>For every memory block, and for every pointer value &lt;code>ptr_val&lt;/code> in it, we check if the distance between the &lt;code>ptr_val&lt;/code> and the &lt;code>goal_addr&lt;/code> falls within an arbitrary range, for example:&lt;/p>&lt;pre>&lt;code class="language-rust">let process = Process::open(pid)?;

let mask = winnt::PAGE_EXECUTE_READWRITE
    | winnt::PAGE_EXECUTE_WRITECOPY
    | winnt::PAGE_READWRITE
    | winnt::PAGE_WRITECOPY;

let regions = process
    .memory_regions()
    .into_iter()
    .filter(|p| (p.Protect &amp;amp; mask) != 0) // (1)
    .collect::&amp;lt;Vec&amp;lt;_&amp;gt;&amp;gt;();

let mut candidate_locations = Vec::new();

for region in regions {
    let base = region.BaseAddress as usize;
    let block = match process.read_memory(base, region.RegionSize) {
        Ok(block) =&amp;gt; block,
        Err(_) =&amp;gt; continue, // (2)
    };

    for (offset, chunk) in block.chunks_exact(8).enumerate() { // (3)
        let ptr_val = usize::from_ne_bytes(chunk.try_into().unwrap()); // (4)
        if (0..4096).contains(goal_addr.wrapping_sub(ptr_val)) { // (5)
            let ptr_val_addr = base + offset * 8;
            candidate_locations.push(ptr_val_addr); // (6)
        }
    }
}
&lt;/code>&lt;/pre>&lt;p>There's a lot of things to unpack in this small snippet:&lt;/p>&lt;ol>&lt;li>We're only interested in regions that are both readable and writable, pretty much like Cheat Engine is doing.&lt;/li>&lt;li>If we can't read a memory region, we can just skip it. Our desired address is probably not there. There's a lot of regions anyway so this is probably a good thing as we can reduce the scanning time!&lt;/li>&lt;li>&lt;code>chunks_exact&lt;/code> achieves multiple things:&lt;ul>&lt;li>It's the most concise way to read chunks of 8 bytes in size, the alternative being having a &lt;code>for i in (0..block.len())&lt;/code> and then slicing on &lt;code>&amp;amp;block[i..i+8]&lt;/code>.&lt;/li>&lt;li>It will look on aligned addresses&lt;a href="#fn:4">&lt;sup id="fnref:4">↪4&lt;/sup>&lt;/a> for free (the alternative being &lt;code>.windows(8)&lt;/code>, which would also look for unaligned addresses).&lt;/li>&lt;li>It makes sure the chunk is always 8 bytes in size, which is important&lt;a href="#fn:5">&lt;sup id="fnref:5">↪5&lt;/sup>&lt;/a>, because &lt;code>usize&lt;/code> is also 8 bytes in size on 64-bit machines.&lt;/li>&lt;/ul>&lt;/li>&lt;li>Interpreting 8 bytes of memory as an &lt;code>usize&lt;/code> can be safely (and efficiently!)&lt;a href="#fn:6">&lt;sup id="fnref:6">↪6&lt;/sup>&lt;/a> achieved through &lt;code>usize::from_ne_bytes&lt;/code>, which expects an &lt;code>[u8; mem::size_of::&amp;lt;usize&amp;gt;()]&lt;/code>. Thankfully, we can convert the 8-byte-long slice into an array pretty easily with &lt;code>.try_into()&lt;/code>.&lt;/li>&lt;li>It's important to use &lt;code>wrapping_sub&lt;/code>, because the &lt;code>-&lt;/code> operator would panic on underflow on debug by default&lt;a href="#fn:7">&lt;sup id="fnref:7">↪7&lt;/sup>&lt;/a>. Since we're reading all of the memory in the program, there will be a lot of values, many of which would be less than &lt;code>goal_addr&lt;/code>, causing underflow. Note also how we could interpret the values as &lt;code>isize&lt;/code> instead so that a negative offset could be used in the range. However, a negative offset is much less common&lt;a href="#fn:8">&lt;sup id="fnref:8">↪8&lt;/sup>&lt;/a>, so it's fine to stick with positive offsets.&lt;/li>&lt;li>We have a candidate pointer-value, so we make sure to store its address.&lt;/li>&lt;/ol>&lt;p>At the end of this, &lt;code>candidate_locations&lt;/code> will have &lt;em>many&lt;/em> memory addresses pointing to a different &lt;code>ptr_val&lt;/code> each. This &lt;code>ptr_val&lt;/code> points to &lt;code>goal_addr&lt;/code> minus some offset (which can be calculated at any time by substracting again). These are the pointer-values at depth 0&lt;a href="#fn:9">&lt;sup id="fnref:9">↪9&lt;/sup>&lt;/a>.&lt;/p>&lt;p>Each of these &lt;code>candidate_locations&lt;/code> is in itself the next &lt;code>goal_addr&lt;/code>, and running the process again will produce pointer-values for depth 1. Yes, you've guessed it, this has exponential growth. No wonder Cheat Engine finds millions of paths. And don't forget to somehow save "this address came from this other address", so that you can follow the chain back after you're done!&lt;/p>&lt;p>Note the importance of limiting the depth: not only this growth has to stop at some point, but also think about cyclic paths. The program would get stuck as soon as &lt;code>ptr_val_addr == ptr_val&lt;/code>, looking for itself over and over again! Without actively looking for cycles&lt;a href="#fn:10">&lt;sup id="fnref:10">↪10&lt;/sup>&lt;/a>, and without limiting the depth, the process would never finish.&lt;/p>&lt;p>After the full process completes (having executed multiple iterations of it at multiple depths), we would need to check every path to see if it works for us (that is, if it starts with a "static address"). You will have an obscene amount of paths, many of which won't actually work after restarting the program (it might have been luck that some unrelated component got allocated close to your original &lt;code>goal_addr&lt;/code> but now it's not anymore). So how do we clean this mess up?&lt;/p>&lt;p>We run the process again! Preferably, after the memory has shuffled around enough (for example, again, restarting the program). Once we have the list of paths "before" and "after", we compare them all. The naive approach of checking, for every path in "before", if any of the paths in "after" is the same, would yield a sweet time complexity of &lt;code>O(n²)&lt;/code>, with millions of paths. This ain't gonna cut it. We must do better. I don't know if this is what Cheat Engine is doing (but if it is, I tip my hat to them), but since I can't think of an efficient way to do it, we'll be going a different route.&lt;/p>&lt;h2 id="speeding-up-the-scan">&lt;a href="#speeding-up-the-scan">Speeding up the scan&lt;/a>&lt;/h2>&lt;p>By reading an entire block of memory at a time, we're actually doing pretty okay on that department. It would be very, very wasteful to issue millions of reads of 8 bytes, when we could instead run thousands of reads of several kilobytes (or more!). Of course, we still have to read millions of 8-bytes, but if they're in our memory and don't require a call to the Windows API, it's going to be orders of magnitude faster.&lt;/p>&lt;p>We're only reading aligned pointers, cutting down the amount of reads and checks we perform down to &lt;code>1/8&lt;/code>. A lot of useless results are also discarded this way.&lt;/p>&lt;p>We're only considering positive offsets, and we're limiting how "far" the &lt;code>goal_addr&lt;/code> can be from a possible &lt;code>ptr_val&lt;/code> before we stop considering said &lt;code>ptr_val&lt;/code>. After all, a structure longer than 4096 bytes should hopefully be uncommon. By doing this, we only keep "address-like" values, which have a very high chance of being an actual address, although they could very well not be! We may be finding arbitrary values and think they represent an address when they actually don't.&lt;/p>&lt;p>We're limiting the maximum depth we're willing to go. This depth directly correlates to the maximum length a pointer path can have. If you're confident the path won't be longer than, say, 5 addressses, there's no need to dive any deeper, and you will save on a lot of processing this way.&lt;/p>&lt;p>This code can be made parallel trivially (after making Rust compiler happy, anyway). There is a lot of &lt;code>ptr_val_addr&lt;/code> values to scan for, so if we think of &lt;code>candidate_locations&lt;/code> as a "queue of work", more than one thread can be popping from it and running the scan. This gives a nice boost on multi-core systems. It doesn't entirely scale linearly with the number of cores, but it's close enough to what you would expect.&lt;/p>&lt;p>A pointer path will only be considered if it starts with a static address. This means the last address pushed must be static (the path will have been built backwards, because we started at the end, &lt;code>goal_addr&lt;/code>). This should clean-up a lot of intermediate and uninteresting addresses. If the address isn't static, it's not really interesting to us. Remember, the reason we're doing all of this is so that we can reuse said address in the future, without the need to find &lt;code>goal_addr&lt;/code> manually.&lt;/p>&lt;p>Comparing the pointer paths will result in paths that very likely will work in the future. Not only is this important to reduce the number of paths drastically, but it also provides better guarantees about what is a "good", reliable path to follow to find &lt;code>goal_addr&lt;/code>.&lt;/p>&lt;p>Next up, let's talk about some of the more intrusive optimizations which I actually seeked to reach an acceptable runtime. This will be where I started to code this up.&lt;/p>&lt;h2 id="working-out-a-poc">&lt;a href="#working-out-a-poc">Working out a &lt;abbr title="Proof of Concept">PoC&lt;/abbr>&lt;/a>&lt;/h2>&lt;blockquote>&lt;p>Add a braindump mess enough to find pointerpaths&lt;/p>&lt;/blockquote>&lt;p>This is the commit message that made it possible to complete step 8 on the tutorial (the actual commit message has quite some more lines explaining the commit). Unlike previous entries of this series, I had a hard time making incremental progress. So let's dissect what was done instead.&lt;/p>&lt;blockquote>&lt;p>The approach used in this commit (although really messy), consists on taking two "snapshots" of the memory, and knowing where a desired value is located in both.&lt;/p>&lt;/blockquote>&lt;p>By introducing the concept of "snapshots", we can "freeze" the process' memory at a given point in time, and scan it at our leisure, without having to worry about it changing. Not only this, but it also saves on a lot of calls to &lt;code>ReadProcessMemory&lt;/code>, so it's also more efficient. If memory is an issue, these structures could be saved to disk and streamed instead. I haven't measured how fast this is, but having our own copy of the process' memory lets us run the scan even after the process is closed (and by then we would reclaim some of that memory), so this approach is mostly benefits.&lt;/p>&lt;pre>&lt;code class="language-rust">#[derive(Clone, Debug, PartialEq)]
pub struct Block {
    pub real_addr: usize,
    pub mem_offset: usize,
    pub len: usize,
    pub base: bool, // is this a "base" block (i.e. `real_addr` will be static)?
}

#[derive(Clone, Debug, Default, PartialEq)]
pub struct Snapshot {
    pub memory: Vec&amp;lt;u8&amp;gt;,
    pub blocks: Vec&amp;lt;Block&amp;gt;,
}

impl Snapshot {
    pub fn new(process: &amp;amp;Process, regions: &amp;amp;[winapi::um::winnt::MEMORY_BASIC_INFORMATION]) -&amp;gt; Self {
        // These are used to determine "base" blocks.
        let modules = process.enum_modules().unwrap();

        // Adapt all regions used by the program into our friendlier structure.
        let mut blocks = regions
            .iter()
            .map(|r| Block {
                real_addr: r.BaseAddress as usize,
                mem_offset: 0,
                len: r.RegionSize,
                // "base" blocks are those where they start at the same address
                // as some module, as seen in the sixth entry of this series.
                base: modules.iter().any(|module| {
                    let base = r.AllocationBase as usize;
                    let addr = *module as usize;
                    base == addr
                }),
            })
            .collect::&amp;lt;Vec&amp;lt;_&amp;gt;&amp;gt;();

        // This will come in useful later.
        blocks.sort_by_key(|b| b.real_addr);

        // Put all the memory in a flat vector. The blocks will tell us where each index belongs.
        let mut memory = Vec::new();
        let blocks = blocks
            .into_iter()
            .filter_map(|b| match process.read_memory(b.real_addr, b.len) {
                Ok(mut chunk) =&amp;gt; {
                    let len = chunk.len();
                    let mem_offset = memory.len();
                    memory.append(&amp;amp;mut chunk);
                    Some(Block {
                        real_addr: b.real_addr,
                        mem_offset,
                        len,
                        base: b.base,
                    })
                }
                Err(_) =&amp;gt; None,
            })
            .collect::&amp;lt;Vec&amp;lt;_&amp;gt;&amp;gt;();

        Self {
            memory,
            blocks,
        }
    }
}
&lt;/code>&lt;/pre>&lt;p>Pretty straightforward. A &lt;code>Snapshot&lt;/code> consists of the process' memory along with some metadata for the blocks. This lets us know, given an index into &lt;code>memory&lt;/code>, what its real address (or vice versa):&lt;/p>&lt;pre>&lt;code class="language-rust">fn get_block_idx_from_mem_offset(&amp;amp;self, mem_offset: usize) -&amp;gt; usize {
    match self.blocks.binary_search_by_key(&amp;amp;mem_offset, |b| b.mem_offset) {
        Ok(index) =&amp;gt; index,
        Err(index) =&amp;gt; index - 1,
    }
}

fn get_block_idx_from_addr(&amp;amp;self, addr: usize) -&amp;gt; usize {
    match self.blocks.binary_search_by_key(&amp;amp;addr, |b| b.real_addr) {
        Ok(index) =&amp;gt; index,
        Err(index) =&amp;gt; index - 1,
    }
}
&lt;/code>&lt;/pre>&lt;p>Because we've sorted by &lt;code>real_addr&lt;/code>, and we filled the &lt;code>memory&lt;/code> in order, we can &lt;code>binary_search_by_key&lt;/code> in both cases. &lt;code>Process::read_memory&lt;/code> translates into &lt;code>Snapshot::read_memory&lt;/code> as follows:&lt;/p>&lt;pre>&lt;code class="language-rust">pub fn read_memory(&amp;amp;self, addr: usize, n: usize) -&amp;gt; Option&amp;lt;&amp;amp;[u8]&amp;gt; {
    let block = &amp;amp;self.blocks[self.get_block_idx_from_addr(addr)];
    let delta = addr - block.real_addr;
    if delta + n &amp;gt; block.len {
        None
    } else {
        let offset = block.mem_offset + delta;
        Some(&amp;amp;self.memory[offset..offset + n])
    }
}
&lt;/code>&lt;/pre>&lt;p>Because this time we already own the memory, we can return a slice and avoid allocations&lt;a href="#fn:11">&lt;sup id="fnref:11">↪11&lt;/sup>&lt;/a>. Now that we have two snapshots of the process' memory at different points in time (so the pointer-values to &lt;code>goal_addr&lt;/code> are different), we find &lt;code>goal_addr&lt;/code> in both snapshots (it should be a different pointer-value, unless it so happens to be in static memory already).&lt;/p>&lt;p>Then, the pointer value of the address is searched in the second snapshot (within a certain range, it does not need to be exact). For every value found, a certain offset will have been used. Now, the pointer value minus &lt;em>this exact offset&lt;/em> &lt;strong>must&lt;/strong> be found &lt;em>exactly&lt;/em> on the other snapshot (it does not matter which snapshot you start with&lt;a href="#fn:12">&lt;sup id="fnref:12">↪12&lt;/sup>&lt;/a>). This was my "aha!" moment, and it's a key step, so let's make sure we understand why we're doing this.&lt;/p>&lt;p>Rather than guessing candidate pointer-values which would have a given offset as a standalone step, we merge this with the comparison step, insanely reducing the amount of candidates. Before, any pointer-value close enough to &lt;code>goal_addr&lt;/code> had to be considered, and in a process with megabytes or gigabytes of memory, this is going to be a lot. However, by keeping only the pointer-values (which have a given offset) that &lt;em>also&lt;/em> exist on the alternate snapshot with the &lt;em>exact&lt;/em> value, we're tremendously reducing the number of false positives.&lt;/p>&lt;pre>&lt;code class="language-rust">impl Snapshot {
    // Iterate over (memory address, pointer value at said address)
    pub fn iter_addr(&amp;amp;self) -&amp;gt; impl Iterator&amp;lt;Item = (usize, usize)&amp;gt; + '_ {
        let mut blocks = self.blocks.iter().peekable();
        self.memory
            .chunks_exact(8)
            .enumerate()
            .map(move |(i, chunk)| {
                let mut block = *blocks.peek().unwrap();
                if i * 8 &amp;gt;= block.mem_offset + block.len {
                    // Roll over to the next block.
                    block = blocks.next().unwrap();
                }

                (
                    block.real_addr + (i * 8 - block.mem_offset),
                    usize::from_ne_bytes(chunk.try_into().unwrap()),
                )
            })
    }
}

struct PathFinder {
    first_snap: Snapshot,
    second_snap: Snapshot,
    addresses: std::cell::Cell&amp;lt;Vec&amp;lt;(bool, u8, usize)&amp;gt;&amp;gt;, // (last node?, depth, real address)
}

impl PathFinder {
    fn run(&amp;amp;self, first_addr: usize, second_addr: usize, depth: u8) -&amp;gt; bool {
        // F: first, S: second; RA: Real Address; PV: Pointer Value
        let depth = depth - 1;
        let mut any = false;
        for (sra, spv) in self.second_snap.iter_addr().filter(|(_sra, spv)| {
            if let Some(offset) = second_addr.checked_sub(*spv) {
                offset &amp;lt;= MAX_OFFSET
            } else {
                false
            }
        }) {
            if self.second_snap.is_base_addr(sra) {
                unsafe { &amp;amp;mut *self.addresses.as_ptr() }.push((true, depth + 1, sra));
                any = true;
                continue;
            }
            if depth == 0 {
                continue;
            }
            let offset = second_addr - spv;
            for (fra, _fpv) in self
                .first_snap
                .iter_addr()
                .filter(|(_fra, fpv)| fpv.wrapping_add(offset) == first_addr)
            {
                if self.run(fra, sra, depth) {
                    unsafe { &amp;amp;mut *self.addresses.as_ptr() }.push((false, depth + 1, sra));
                    any = true;
                }
            }
        }

        any
    }
}
&lt;/code>&lt;/pre>&lt;p>&lt;code>Snapshot::iter_addr&lt;/code> is like &lt;code>read_memory&lt;/code>, but better for our needs, because it automatically returns the pointer-values and its corresponding real address efficiently. The &lt;code>PathFinder&lt;/code> is a helper &lt;code>struct&lt;/code> to avoid passing &lt;code>first_snap&lt;/code>, &lt;code>second_snap&lt;/code> and &lt;code>addresses&lt;/code> as parameters on every call.&lt;/p>&lt;p>&lt;code>Snapshot::run&lt;/code> is a recursive method which is called with the &lt;code>goal_addr&lt;/code> in both the first and second snapshot, along with a depth. When this depth reaches 0, the method stops recursing. The method also stops when a base (static) address is found.&lt;/p>&lt;p>The method starts by looking for all pointer-values in the second snapshot where &lt;code>ptr_value + offset = second_addr&lt;/code> for all &lt;code>offset in 0..=MAX_OFFSET&lt;/code>. For every candidate &lt;code>ptr_value&lt;/code> with a given &lt;code>offset&lt;/code>, it looks &lt;strong>exactly&lt;/strong> for &lt;code>first_addr - offset&lt;/code> in the alternate snapshot (the first one). Once found, we have a candidate offset valid in &lt;em>both&lt;/em> snapshots, and then we can recurse to find subsequent offsets on the real addresses of these pointer values themselves. The addresses of these pointer-values are our new &lt;code>goal_addr&lt;/code> in the next depth.&lt;/p>&lt;p>Once &lt;code>run&lt;/code> returns from the top-most depth, we can convert post-process &lt;code>addresses&lt;/code> into something usable, with an algorithm akin to run-length encoding (the real-code abuses the vector's &lt;code>capacity&lt;/code> and &lt;code>len&lt;/code> to determine the &lt;code>depth&lt;/code> and had inaccurate names, so I've rewritten that part for clarity):&lt;/p>&lt;pre>&lt;code class="language-rust">struct Path {
    addresses: Vec&amp;lt;usize&amp;gt;,
    depth: u8,
}

let mut paths = Vec::new();

for (base, depth, addr) in pf.addresses.into_inner() {
    if base {
        paths.push(Path { addresses: Vec::new(), depth });
    }
    for path in paths.iter_mut() {
        if path.depth == depth {
            path.addresses.push(addr);
            // remember PathFinder started at the highest depth and ended at
            // base with the lowest depth, so "going up" is "the way out".
            path.depth += 1;
        }
    }
}

// `second_addr` wasn't pushed by `PathFinder::run` as it was the starting
// point, so push it now.
for path in paths.iter_mut() {
    path.addresses.push(second_addr);
}
&lt;/code>&lt;/pre>&lt;p>Note how this process can form a tree. Any given depth can have any amount of children. For example, if the address finding yields the following addresses (where the hundreds' also represent the depth):&lt;/p>&lt;pre>400, 300, 450, 300, 200, 100
&lt;/pre>&lt;p>Then this represents the following call-stack tree:&lt;/p>&lt;pre>   100
    |
   200
    |
   300
   / \
400   450

// or

(100
    (200
        (300
            (400, 450))))
&lt;/pre>&lt;p>Once the many paths have been cleaned up into a separate vector each, we can turn these addresses into offsets:&lt;/p>&lt;pre>&lt;code class="language-rust">paths.into_iter().map(|path| {
    let mut offsets = path.addresses;
    for i in (1..offs.len()).rev() {
        let prev_addr = offs[i - 1];
        let ptr_value = pf.second_snap.read_memory(prev_addr, mem::size_of::&amp;lt;usize&amp;gt;()).unwrap();
        let ptr_value = usize::from_ne_bytes(ptr_value.try_into().unwrap());
        offs[i] -= ptr_value;
    }
    offsets
}).collect::&amp;lt;Vec&amp;lt;usize&amp;gt;&amp;gt;()
&lt;/code>&lt;/pre>&lt;p>For the example above, the result would be:&lt;/p>&lt;pre>100, 100, 100, 100
100, 100, 100, 150
&lt;/pre>&lt;p>In order to reach &lt;code>address[i]&lt;/code>, we have to read the &lt;code>ptr_value&lt;/code> from &lt;code>address[i - 1]&lt;/code> and add a given &lt;code>offset&lt;/code>. This &lt;code>offset&lt;/code> is given by &lt;code>address[i] - ptr_value&lt;/code>. By iterating the list of addresses in reverse, we can neatly turn them into offsets substracting this &lt;code>ptr_value&lt;/code>. Now we're done! We can persist this list of &lt;code>offsets&lt;/code> and it will work at any point in the future to get back to our original &lt;code>goal_addr&lt;/code>. In pseudo-code:&lt;/p>&lt;pre>&lt;code class="language-rust">base = base addr
for offset in offsets[..-1] {
    base = *(base + offset)
}
goal_addr = base + offsets[-1]
value = *goal_addr
&lt;/code>&lt;/pre>&lt;p>By the way, sometimes the scan will take horribly long and find thousands of path, and sometimes it will be blazingly fast. I don't know why this is the case, but if that happens, you can try restarting the tutorial. And do not forget to run on &lt;code>--release&lt;/code> mode, or you will definitely be waiting a long, long time.&lt;/p>&lt;h2 id="doing-more-for-better-runtime-speed">&lt;a href="#doing-more-for-better-runtime-speed">Doing more for better runtime speed&lt;/a>&lt;/h2>&lt;p>The recursive &lt;code>PathFinder&lt;/code> implements a fairly elegant solution. Unfortunately, this is hard to parallelize, as it all runs on the same thread and there is no clean way to introduce threads here&lt;a href="#fn:13">&lt;sup id="fnref:13">↪13&lt;/sup>&lt;/a>. We will rewrite this version to use a queue instead, with the idea that multiple threads will be taking work from it. In order to do this, let's introduce two new concepts:&lt;/p>&lt;pre>&lt;code class="language-rust">#[derive(Clone)]
struct CandidateNode {
    parent: Option&amp;lt;usize&amp;gt;,
    addr: usize,
}

#[derive(Clone)]
struct FutureNode {
    node_idx: usize,
    first_addr: usize,
    second_addr: usize,
    depth: u8,
}
&lt;/code>&lt;/pre>&lt;p>The &lt;code>CandidateNode&lt;/code> should be as small as possible, because there will be one &lt;code>CandidateNode&lt;/code> for every address of the candidate pointer-values. Without doing anything fancy, we'll need an optional &lt;code>usize&lt;/code> to build a "linked list" of the path, and the address of the pointer-value. With the &lt;code>parent&lt;/code> field, we can trace all of the parent candidate nodes all the way back up to the root node.&lt;/p>&lt;p>The &lt;code>FutureNode&lt;/code> will hold temporary values, until a thread picks it up and carries on, so there's no need to over-optimize this. For a thread to continue, it needs to know the pointer-value address and its parent (that is, the candidate node it will work on), along with the first and second goal address for a given depth.&lt;/p>&lt;p>After the process completes (a base or static address is found), it's enough to remember the candidate node, as we'll later be able to follow the chain. Thus, the &lt;code>PathFinder&lt;/code> needs to hold the following values:&lt;/p>&lt;pre>&lt;code class="language-rust">struct QueuePathFinder {
    first_snap: Snapshot,
    second_snap: Snapshot,
    /// Indices of `nodes_walked` which are "good" (i.e. have reached a base address).
    good_finds: Vec&amp;lt;usize&amp;gt;,
    /// Shared "tree" of nodes we've walked over, so all threads can access and reference them.
    nodes_walked: Vec&amp;lt;CandidateNode&amp;gt;,
    /// Nodes to be used in the future, where the `FutureNode::node_idx` references `Self::nodes_walked`.
    new_work: Vec&amp;lt;FutureNode&amp;gt;,
}

impl QueuePathFinder {
    pub fn run(&amp;amp;mut self, first_addr: usize, second_addr: usize, depth: u8) {
        self.add_work(None, first_addr, second_addr, depth);
        while self.step() {}
    }

    // Returns false to signal there's no more work.
    fn step(&amp;amp;mut self) -&amp;gt; bool {
        // Instead of getting the `goal_addr` from input parameters, we get it through the queue.
        let future_node = if let Some(future_node) = self.new_work.pop() {
            future_node
        } else {
            return false;
        };

        // The same scan as `PathFinder::run` is carried away, with 2 differences.
        let first_snap = std::mem::take(&amp;amp;mut self.first_snap);
        let second_snap = std::mem::take(&amp;amp;mut self.second_snap);
        for (sra, spv) in second_snap.iter_addr().filter(|(_sra, spv)| {
            if let Some(offset) = future_node.second_addr.checked_sub(*spv) {
                offset &amp;lt;= MAX_OFFSET
            } else {
                false
            }
        }) {
            if second_snap.is_base_addr(sra) {
                // (1) rather than simply pushing the address (here, a `CandidateNode`),
                // we also store its index (because the candidate nodes themselves don't
                // have any flag saying "I'm the bottommost one").
                self.good_finds.push(self.nodes_walked.len());
                self.nodes_walked.push(CandidateNode {
                    parent: Some(future_node.node_idx),
                    addr: sra,
                });
                continue;
            }
            if future_node.depth == 0 {
                continue;
            }
            let offset = future_node.second_addr - spv;
            for (fra, _fpv) in first_snap
                .iter_addr()
                .filter(|(_fra, fpv)| fpv.wrapping_add(offset) == future_node.first_addr)
            {
                // (2) rather than recursing, we add work to the queue.
                self.add_work(Some(future_node.node_idx), fra, sra, future_node.depth - 1);
            }
        }

        self.first_snap = first_snap;
        self.second_snap = second_snap;
        true
    }

    fn add_work(
        &amp;amp;mut self,
        parent: Option&amp;lt;usize&amp;gt;,
        first_addr: usize,
        second_addr: usize,
        depth: u8,
    ) {
        // Adding work consists on registering the `CandidateNode` and adding a `FutureNode`.
        self.new_work.push(FutureNode {
            node_idx: self.nodes_walked.len(),
            first_addr,
            second_addr,
            depth,
        });
        self.nodes_walked.push(CandidateNode {
            parent,
            addr: second_addr,
        });
    }
}
&lt;/code>&lt;/pre>&lt;p>This version probably uses more memory, as we need to remember all &lt;code>CandidateNode&lt;/code> because any live &lt;code>FutureNode&lt;/code> may be referencing them, and a &lt;code>CandidateNode&lt;/code> itself has parents. It should be possible to prune them if it gets too large, although a lot of indices would need to be adjusted, so for now, we don't worry about pruning that tree (which we store as a &lt;code>Vec&lt;/code> and the references to the parent are indirect through the use of indices). However, this version can use threads much more easily. It's enough to wrap all the &lt;code>Vec&lt;/code> inside a &lt;code>Mutex&lt;/code>.&lt;/p>&lt;p>And what's more, it is now trivial to perform the search breadth-first instead! With the recursive version, we were stuck performing a depth-first search, which is unfortunate, because the first valid paths which would be found would be the deepest. But now that we have our own work queue, if we keep it sorted by depth, we can easily switch to running breadth-first. Shorter paths feel better, because there's less hops to go through, and less things that could go wrong:&lt;/p>&lt;pre>&lt;code class="language-rust">#[derive(Clone, PartialEq, Eq, PartialOrd, Ord)] // &amp;lt;- now it's comparable
struct FutureNode {
    depth: u8, // &amp;lt;- this used to be last but we want to sort by depth first
    node_idx: usize,
    first_addr: usize,
    second_addr: usize,
}

struct QueuePathFinder {
    ...
    new_work: BinaryHeap&amp;lt;FutureNode&amp;gt;,
    //        ^^^^^^^^^^ this used to be a Vec
}
&lt;/code>&lt;/pre>&lt;p>Thanks to Rust's wrong decision of making &lt;code>BinaryHeap&lt;/code> be max-heaps&lt;a href="#fn:14">&lt;sup id="fnref:14">↪14&lt;/sup>&lt;/a>, and our use of a decreasing depth as we get deeper, the ordering just works out! Next up, threads should be introduced for the next big-boost in runtime performance. This isn't too tricky, but I would recommend you introduce &lt;code>serde&lt;/code> by now and persist both &lt;code>Snapshot&lt;/code> and &lt;code>goal_addr&lt;/code> so that you can easily debug this. Running the program on Cheat Engine's tutorial gets boring fast. I'll leave both of these as an exercise to the reader. Just make sure the threads don't end prematurely, because even if there is no work &lt;em>now&lt;/em>, it doesn't mean there won't be a few milliseconds later. Else you will be back at single-threaded execution!&lt;/p>&lt;p>After adding threads, I kept poking around the program and seeing how seemingly-innocent changes made runtime performance a fair bit worse. Here's some of the insights I got:&lt;/p>&lt;ul>&lt;li>Using &lt;code>filter&lt;/code> or not (by placing the inverted condition inside the loop with a &lt;code>continue&lt;/code>) can both help or hurt performance.&lt;/li>&lt;li>Hoisting certain conditions, like &lt;code>if depth == 0&lt;/code>, and duplicating the entire loop body rather than running it every time, can hurt performance.&lt;/li>&lt;li>The moments when you should wake up threads matters (if your approach works in a way where this matters).&lt;/li>&lt;li>Changing the order in which you compute certain values and then use them can matter.&lt;/li>&lt;li>&lt;code>Option&lt;/code> introduces a fair bit of overhead due to alignment concerns, and &lt;code>CandidateNode&lt;/code> can easily be reduced from 24 bytes to 16 by getting rid of the &lt;code>Option&lt;/code> and instead using a special value to signal "no-parent".&lt;/li>&lt;li>Atomics are neat, but a bit annoying to use. Crates like &lt;a href="https://crates.io/crates/crossbeam-utils">&lt;code>crossbeam-utils&lt;/code>&lt;/a> make them easier to use while still not using locks if possible.&lt;/li>&lt;li>You can beat Rust's functional-style iterators performance by writing your own custom iterator, but it isn't trivial to do so.&lt;/li>&lt;li>Messing with larger (such as changing &lt;code>depth&lt;/code> for &lt;code>usize&lt;/code>) or smaller (such as changing &lt;code>node_idx&lt;/code> for &lt;code>u32&lt;/code>) types can hurt performance.&lt;/li>&lt;/ul>&lt;p>It turns out &lt;code>step&lt;/code> isn't called a lot while analyzing Cheat Engine's tutorial, so it better be fast. And one way to go fast is to do less!&lt;/p>&lt;h2 id="doing-less-for-better-runtime-speed">&lt;a href="#doing-less-for-better-runtime-speed">Doing less for better runtime speed&lt;/a>&lt;/h2>&lt;p>For every future node, we have to read and compare an entire snapshot of the process' memory against a value. For 8MiB worth of memory, that's over a million comparisons! Using threads can only scale as far as the amounnt of cores you have before degrading quickly. A lot of those comparisons won't be useful at all, and if the method runs a hundred times, there can easily be 6MiB that you could avoid scanning at all, a hundred times.&lt;/p>&lt;p>What if, instead, we run some sort of "pre-scan" that tells us "don't bother looking around here, you will not find anything useful"? We totally can, and the good news is, it does improve the runtime quite a bit!&lt;/p>&lt;p>In order to do this, we need another way of instructing the program where to look. We can do this by adding additional information to each block (either directly or indirectly) that tells us "which other blocks have pointer-values that point into us?":&lt;/p>&lt;pre>&lt;code class="language-rust">struct Block {
    ...,
    // Indices of the blocks that have pointer-values which point inside self.
    pointed_from: Vec&amp;lt;usize&amp;gt;,
}

pub fn prepare_optimized_scan(snap: &amp;amp;mut Snapshot) {
    let mut block_idx_pointed_from = (0..snap.blocks.len())
        .map(|_| std::collections::HashSet::new())
        .collect::&amp;lt;Vec&amp;lt;_&amp;gt;&amp;gt;();

    // For each block...
    for (i, block) in snap.blocks.iter().enumerate() {
        // ...scan all the pointer-values...
        for (ra, pv) in snap.iter_addr() {
            // ...and if any of the pointer-values points inside this block...
            if let Some(delta) = pv.checked_sub(block.real_addr) {
                if delta &amp;lt; block.len {
                    // ...then we know that the block with this pointer-value points to our original block.
                    block_idx_pointed_from[i].insert(snap.get_block_idx_from_addr(ra));
                }
            }
        }
    }

    // Convert sets into sorted vectors and save them inside the blocks.
    block_idx_pointed_from
        .into_iter()
        .zip(snap.blocks.iter_mut())
        .for_each(|(set, block)| {
            block.pointed_from = set.into_iter().collect::&amp;lt;Vec&amp;lt;_&amp;gt;&amp;gt;();
            block.pointed_from.sort();
        });
}
&lt;/code>&lt;/pre>&lt;p>When running the scan (via &lt;code>Snapshot::step&lt;/code>), instead of running &lt;code>iter_addr&lt;/code> over &lt;em>all&lt;/em> addresses, we determine the block where the current &lt;code>goal_addr&lt;/code> falls in and scan only on the blocks indicated by &lt;code>block.pointed_from&lt;/code>. I did some math, and on the tutorial step, rather than scanning 95 blocks, we scan an average of 3.145 blocks (median 2, standard deviation 6.12), which greatly reduces the amount of work that needs to be done on a snapshot which is roughly 10 MiB.&lt;/p>&lt;p>There's a chance that the block we're scanning just so happens to be very "busy" and have a lot of blocks pointing into it (which would make sense, as that's probably an indication that the interesting things occur there). However, it is definitely possible to improve on the heuristics, all with different trade-offs.&lt;/p>&lt;p>The simplest heuristic is "assume every block can point to any other block" (which we were doing before). A slightly better one is "determine which blocks have a chance of pointing into other blocks". You could even narrow down the "scan area" within blocks to make them "smaller", for example, by finding the bounding addresses of "interest" and trimming the block size. You could sort the blocks differently, perhaps prioritizing when a block points into itself, or add additional exit conditions. But this is plenty fast, even more so if you use threads for &lt;code>prepare_optimized_scan&lt;/code> as well!&lt;/p>&lt;p>Another idea would be dropping some blocks entirely (although this is partially mitigated thanks to &lt;code>Block::pointed_from&lt;/code>). If a base block (i.e. it starts where a module does) doesn't belong to the program in question (for example, it belongs to a system DLL), we could drop it, and don't even consider it in &lt;code>prepare_optimized_scan&lt;/code>. This is probably what Cheat Engine is doing with "Include system modules", although I haven't experimented much with that option. The downside is, if it just so happens the offsets follow a path through that block, it won't be found. But it shouldn't be a big deal when plenty of paths are found.&lt;/p>&lt;p>In order to ignore system DLLs, it should be possible to find the module names and then where are they located (pretty much emulating the &lt;a href="https://docs.microsoft.com/en-us/windows/win32/dlls/dynamic-link-library-search-order">Dynamic-Link Library Search Order&lt;/a>). If it falls within system directories, then we would ignore it.&lt;/p>&lt;p>If we want to reduce the search-space even more, we could specify a range of addresses. When any address falls outside this range, it is ignored. I believe Cheat Engine's default 0000000000000000-7FFFFFFFFFFFFFFF range is pretty much "scan all of it", as we're doing, but with more knowledge of the program at hand, you could definitely narrow this down.&lt;/p>&lt;p>Because we're not directly working with offsets (they are calculated after, and not before finding a candidate), I'm not sure how we could accurately implement Cheat Engine's option for "maximum offsets per node". Perhaps by building a temporary &lt;code>HashSet&lt;/code>, sorting them in descending order, and only considering the first few smallest ones? More testing would be necessary to see if this is worthwhile. Beyond this last optimization, I can't think of any other worthwhile implementing though. We should be getting pretty close to somewhere optimal.&lt;/p>&lt;p>Anyway, let's finish this tutorial step, shall we?:&lt;/p>&lt;pre>&lt;code class="language-rust">let addr = offset_list
    .iter()
    .take(offset_list.len() - 1)
    .fold(0, |base, offset| {
        usize::from_ne_bytes(
            process
                .read_memory(base + offset, 8)
                .unwrap()
                .try_into()
                .unwrap(),
        )
    })
    + offset_list.last().unwrap();

// Ta-dah!
process.write_memory(addr, 5000).unwrap();
&lt;/code>&lt;/pre>&lt;h2 id="retrospective">&lt;a href="#retrospective">Retrospective&lt;/a>&lt;/h2>&lt;span class="dim">&lt;em>This section was added in a later edit.&lt;/em>&lt;/span>&lt;p>After letting this post settle down on me, I realized we probably managed to re-invent the way Cheat Engine works, or at least most of it, something I'm quite proud of! If you want to have this idea "click" in your head by yourself, you can skip this section. But really, there's an awful lot of similarities, and even matching terminology to some extent. Recall back in the &lt;a href="#scan-options">scan options&lt;/a> section, the two primary modes were &lt;em>Scan for address&lt;/em> and &lt;em>Generate pointermap&lt;/em>.&lt;/p>&lt;p>Scanning for an address with the setting "Compare results with other saved pointermap(s)" straight up sounds like the solution we came up with. We take two snapshots (the older one being equivalent to Cheat Engine's "saved pointermap") and perform a scan for the desired address, while comparing our intermediate results with the other pointermap to make sure it is still valid. Its job is to find all candidate paths, and if you were not comparing it to anything, obviously this would lead to a lot of false positives, which is why Cheat Engine advices against it.&lt;/p>&lt;p>Remember when we talked about "the pointerscanner goes through the list of pointervalues with a specific value"? This sounds a lot like our queue, too. The scan settings even mention "Static and dynamic queue sizes", possibly hinting at this implementation detail (as opposed to using unbounded recursion).&lt;/p>&lt;p>And what could a pointermap be other than… a mapping between pointers? This sounds like an awful lot to our "pre-scan" which scanned all the regions to find out "which regions could contain valid pointers into which other regions". That's a mapping of regions as determined by the pointers contained within them, and perhaps Cheat Engine only cares to store worthwhile snapshots of the memory and the corresponding regions. Maybe this is what Cheat Engine means by limiting the scan only to certain regions!&lt;/p>&lt;h2 id="finale">&lt;a href="#finale">Finale&lt;/a>&lt;/h2>&lt;p>And this my dear readers concludes my ambitions with the project! I think the program is pretty useful by now, even if it can only do a small fraction of what Cheat Engine can (I don't think I'm ready to write a form designer GUI yet… wait why was this part of Cheat Engine again?). &lt;del>Despite the length of this entry, we didn't even figure out how Cheat Engine's pointer scanner works. Maybe it really is finding millions of possible paths, perhaps storing the offsets in some compact way&lt;/del>. Although we can't know for sure what Cheat Engine is doing behind the scenes without studying its source code, we came pretty darn close to it. Let's recap what we do have learnt:&lt;/p>&lt;ul>&lt;li>We're experts in pointers by now! Seven layers of indirection? Easy peasy.&lt;/li>&lt;li>There's a lot of configuration available for pointer scans: search depth, search breadth, search order, memory ranges, memory maps…&lt;/li>&lt;li>One way to turn exponential problems into something more approachable is either finding an algorithm without the exponential growth, or trimming the amount of work to be done by &lt;em>a lot&lt;/em>. And sometimes the former alternative is impossible.&lt;/li>&lt;/ul>&lt;p>The &lt;a href="https://github.com/lonami/memo">code for this post&lt;/a> is available over at my GitHub. You can run &lt;code>git checkout step8&lt;/code> after cloning the repository to get the right version of the code. If you're feeling up for a challenge, try to find a different, faster way (as in, less computationally-expensive) in which you can complete this tutorial step. Although ways to cut down the amount of work that needs to be done are definitely welcome, I'm looking for an entirely different approach, which can, for the most part, side-step the "there's too much work" issue.&lt;/p>&lt;p>In the next post, we'll tackle the ninth step of the tutorial: Shared code. I'm hoping it won't be too difficult, although there will be some learning that needs to be done. After that, I'll probably conclude the series. Maybe there could be some bonus episode in the future, or some other form of progress update. Until next time!&lt;/p>&lt;h3 id="footnotes">&lt;a href="#footnotes">Footnotes&lt;/a>&lt;/h3>&lt;p id="fn:1" class="footnote-definition">&lt;span>1&lt;/span> I spent a good chunk of time figuring out how to get this effect on the text (and borrowing code from several sites), but I'm extremely satisfied with the result. You do need a "modern" browser to see what I mean, though. I also lost it after the fact and had to redo it. Oh well.&amp;nbsp;&lt;a href="#fnref:1">↩&lt;/a>&lt;/p>&lt;p id="fn:2" class="footnote-definition">&lt;span>2&lt;/span> Actually, over a couple hundred are often found. But there's a high chance most of them would work just fine.&amp;nbsp;&lt;a href="#fnref:2">↩&lt;/a>&lt;/p>&lt;p id="fn:3" class="footnote-definition">&lt;span>3&lt;/span> I've gone through a lot of iterations for this post, with a fair amount of messy code, so this time I'll be explaining my thought process with new code rather than embedding what I've actually ended up writing.&amp;nbsp;&lt;a href="#fnref:3">↩&lt;/a>&lt;/p>&lt;p id="fn:4" class="footnote-definition">&lt;span>4&lt;/span> Only if &lt;code>base&lt;/code> starts off as an aligned address, of course. But I think memory regions must start at multiples of the page size, which is a (relatively) large power of two, so it's safe to assume &lt;code>base&lt;/code> is divisible by 8. You could throw in an &lt;code>assert_eq!(base % 8, 0)&lt;/code> if you wanted to be extra sure.&amp;nbsp;&lt;a href="#fnref:4">↩&lt;/a>&lt;/p>&lt;p id="fn:5" class="footnote-definition">&lt;span>5&lt;/span> Although, just like we assume &lt;code>base&lt;/code> is a multiple of 8, the &lt;code>RegionSize&lt;/code> probably is as well.&amp;nbsp;&lt;a href="#fnref:5">↩&lt;/a>&lt;/p>&lt;p id="fn:6" class="footnote-definition">&lt;span>6&lt;/span> We could &lt;code>mem::transmute&lt;/code> from &lt;code>*const u8&lt;/code> to &lt;code>*const usize&lt;/code> and dereference, but then we need to be careful about alignment, and &lt;code>from_ne_bytes&lt;/code> seems to be plenty fast already.&amp;nbsp;&lt;a href="#fnref:6">↩&lt;/a>&lt;/p>&lt;p id="fn:7" class="footnote-definition">&lt;span>7&lt;/span> Not that we actually care about debug builds, as they run several orders of magnitude slower. But still, &lt;code>wrapping_sub&lt;/code> has the right semantics here.&amp;nbsp;&lt;a href="#fnref:7">↩&lt;/a>&lt;/p>&lt;p id="fn:8" class="footnote-definition">&lt;span>8&lt;/span> Most of the time pointers point to the beginning of some structure, not its end, so accessing this structure's fields is done by adding, and not substracting, an offset from the pointer-value. For example:&amp;nbsp;&lt;a href="#fnref:8">↩&lt;/a>&lt;/p>&lt;pre>&lt;code class="language-rust">#[repr(C)]
struct Vector {
    x: i32,
    y: i32,
}

let vec = Vector { x: 1, y: 1 };

let vec_ref = &amp;amp;vec;
let y_ref = &amp;amp;vec_ref.y;

let vec_ptr_val = vec_ref as *const _ as usize;
let y_ptr_val = y_ref as *const _ as usize;

assert_eq!(vec_ptr_val + 4, y_ptr_val);
&lt;/code>&lt;/pre>&lt;p id="fn:9" class="footnote-definition">&lt;span>9&lt;/span> Or the top-depth, however you want to see it. I personally prefer starting at the highest depth so that when zero is reached, we know we're at the end.&amp;nbsp;&lt;a href="#fnref:9">↩&lt;/a>&lt;/p>&lt;p id="fn:10" class="footnote-definition">&lt;span>10&lt;/span> Which really, I don't think is worth it at all. If Cheat Engine is finding millions of &lt;em>entire paths&lt;/em>, what kind of magic is it using to find cycles at any two depths???&amp;nbsp;&lt;a href="#fnref:10">↩&lt;/a>&lt;/p>&lt;p id="fn:11" class="footnote-definition">&lt;span>11&lt;/span> Yes, &lt;code>Process::read_memory&lt;/code> could be changed to take in a buffer as input instead, so that it can be reused. Or it could even have an internal buffer. But we won't be using this method much anyway.&amp;nbsp;&lt;a href="#fnref:11">↩&lt;/a>&lt;/p>&lt;p id="fn:12" class="footnote-definition">&lt;span>12&lt;/span> I prefer starting on the second snapshot because it feels more "fresh", as it's the latest one, although it doesn't really matter, because the path we're looking for must be valid in both anyway.&amp;nbsp;&lt;a href="#fnref:12">↩&lt;/a>&lt;/p>&lt;p id="fn:13" class="footnote-definition">&lt;span>13&lt;/span> Maybe the recursive &lt;code>run&lt;/code> could run in a pool of threads?&amp;nbsp;&lt;a href="#fnref:13">↩&lt;/a>&lt;/p>&lt;p id="fn:14" class="footnote-definition">&lt;span>14&lt;/span> Most heaps tend to be min-heaps, and it's not uncommon for the use of &lt;code>BinaryHeap&lt;/code> in Rust to need &lt;code>std::cmp::Reverse&lt;/code> in order to get &lt;a href="https://doc.rust-lang.org/stable/std/collections/struct.BinaryHeap.html#min-heap">min-heap behaviour&lt;/a>. There's been some discussion on internals about this, such as &lt;a href="https://internals.rust-lang.org/t/why-is-std-binaryheap-a-max-heap/11498">Why is std::collections::BinaryHeap a max-heap?&lt;/a> and more recently &lt;a href="https://internals.rust-lang.org/t/specializing-binaryheap-to-maxheap-and-minheap/15115">Specializing BinaryHeap to MaxHeap and MinHeap&lt;/a> where @matklad laments:&amp;nbsp;&lt;a href="#fnref:14">↩&lt;/a>&lt;/p>&lt;blockquote>&lt;p>I feel like our heap accumulated a bunch of problems (wrong default order, slow into-sorted, wrong into-iter, confusing naming, slow-perf due to being binary).&lt;/p>&lt;/blockquote>&lt;p id="fn:15" class="footnote-definition">&lt;span>15&lt;/span> This sounds like it would be most useful when you've already put the work before, and is now time for a re-scan. In this scenario, you already know that there's probably some golden "offset" into the structure you care about.&amp;nbsp;&lt;a href="#fnref:15">↩&lt;/a>&lt;/p>&lt;p id="fn:16" class="footnote-definition">&lt;span>16&lt;/span> 87.5% for us, thanks to having 8-byte sized pointers!&amp;nbsp;&lt;a href="#fnref:16">↩&lt;/a>&lt;/p></content></entry><entry xml:lang="en"><title>Writing our own Cheat Engine: Code Injection</title><published>2021-05-08T00:00:00+00:00</published><updated>2021-05-08T00:00:00+00:00</updated><link href="https://lonami.dev/blog/woce-7/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/woce-7/</id><content type="html">&lt;p>This is part 7 on the &lt;em>Writing our own Cheat Engine&lt;/em> series:&lt;/p>&lt;ul>&lt;li>&lt;a href="/blog/woce-1">Part 1: Introduction&lt;/a> (start here if you're new to the series!)&lt;/li>&lt;li>&lt;a href="/blog/woce-2">Part 2: Exact Value scanning&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-3">Part 3: Unknown initial value&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-4">Part 4: Floating points&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-5">Part 5: Code finder&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-6">Part 6: Pointers&lt;/a>&lt;/li>&lt;li>Part 7: Code Injection&lt;/li>&lt;li>&lt;a href="/blog/woce-8">Part 8: Multilevel pointers&lt;/a>&lt;/li>&lt;/ul>&lt;p>In part 6 we ended up spending most of the time in upgrading our breakpoint support to have a proper implementation, rather than using some hardcoded constants. We then made use of the new and improved breakpoint support to find what code accessed an specific memory address our very own debugger. To complete the tutorial, we read and understood the surrounding assembly around the code accessing our address and figured out what pointer to look for. In the end, we were left with a base address that we can rely on and follow to reach the target memory address, without having to scan for it every time.&lt;/p>&lt;p>In this post, we will take a look at the different techniques Cheat Engine uses to patch instructions with as many other instructions as we need.&lt;/p>&lt;h2 id="code-injection">&lt;a href="#code-injection">Code Injection&lt;/a>&lt;/h2>&lt;details open>&lt;summary>Cheat Engine Tutorial: Step 7&lt;/summary>&lt;blockquote>&lt;p>Code injection is a technique where you inject a piece of code into the target process, and then reroute the execution of code to go through your own written code.&lt;/p>&lt;p>In this tutorial you'll have a health value and a button that will decrease your health by 1 each time you click it. Your task is to use code injection to make the button increase your health by 2 each time it is clicked.&lt;/p>&lt;p>Start with finding the address and then find what writes to it. Then when you've found the code that decreases it browse to that address in the disassembler, and open the auto assembler window (ctrl+a). There click on template and then code injection, and give it the address that decreases health (if it isn't already filled in correctly). That will generate a basic auto assembler injection framework you can use for your code.&lt;/p>&lt;p>Notice the alloc, that will allocate a block of memory for your code cave, in the past, in the pre windows 2000 systems, people had to find code caves in the memory (regions of memory unused by the game), but that's luckily a thing of the past since windows 2000, and will these days cause errors when trying to be used, due to SP2 of XP and the NX bit of new CPU's&lt;/p>&lt;p>Also notice the line &lt;code>newmem:&lt;/code> and &lt;code>originalcode:&lt;/code> and the text "Place your code here". As you guessed it, write your code here that will increase the health with 2. An usefull assembler instruction in this case is the "ADD instruction". Here are a few examples:&lt;/p>&lt;ul>&lt;li>"ADD [00901234],9" to increase the address at 00901234 with 9&lt;/li>&lt;li>"ADD [ESP+4],9" to increase the address pointed to by ESP+4 with 9&lt;/li>&lt;/ul>&lt;p>In this case, you'll have to use the same thing between the brackets as the original code has that decreases your health&lt;/p>&lt;p>Notice: It is recommended to delete the line that decreases your health from the original code section, else you'll have to increase your health with 3 (you increase with 3, the original code decreases with 1, so the end result is increase with 2), which might become confusing. But it's all up to you and your programming.&lt;/p>&lt;p>Notice 2: In some games the original code can exist out of multiple instructions, and sometimes, not always, it might happen that a code at another place jumps into your jump instruction end will then cause unknown behavior. If that happens, you should usually look near that instruction and see the jumps and fix it, or perhaps even choose to use a different address to do the code injection from. As long as you're able to figure out the address to change from inside your injected code.&lt;/p>&lt;/blockquote>&lt;/details>&lt;h2 id="injection-techniques">&lt;a href="#injection-techniques">Injection techniques&lt;/a>&lt;/h2>&lt;p>The Instruction Set Architecture (ISA) a typical desktop computer is able to interpret uses a variable-length encoding for the instructions (do correct me if this is phrased incorrectly; it's not my area of expertise). That means we can't go and blindly replace a instruction with the code we need. We need to be careful, and still hope that no code dynamically jumps to this very specific location. Otherwise we may end up executing &lt;a href="https://github.com/preames/public-notes/blob/master/unintended-instructions.rst">Unintended Instructions&lt;/a>!&lt;/p>&lt;p>The way Cheat Engine gets around this is by replacing the instruction with a jump. After the offending code is found, you can use a "template" that prompts "On what address do you want the jump?". After accepting the "code inject template", a window with the following code shows:&lt;/p>&lt;pre>&lt;code class="language-asm">alloc(newmem,2048,"Tutorial-x86_64.exe"+2D4F7)
label(returnhere)
label(originalcode)
label(exit)

newmem: //this is allocated memory, you have read,write,execute access
//place your code here

originalcode:
sub dword ptr [rsi+000007E0],01

exit:
jmp returnhere

"Tutorial-x86_64.exe"+2D4F7:
jmp newmem
nop 2
returnhere:
&lt;/code>&lt;/pre>&lt;p>It seems Cheat Engine has its own mini-language that extends assembly using Intel-syntax. It has &lt;code>directive(arguments)&lt;/code> which do… well, stuff.&lt;/p>&lt;p>&lt;code>alloc(label, size, address)&lt;/code> seems to allocate &lt;code>size&lt;/code> bytes at some address and assign &lt;code>label&lt;/code> to it. &lt;code>address&lt;/code> is where the jump to the newly-allocated memory will be inserted.&lt;/p>&lt;p>&lt;code>label(label)&lt;/code> seems to be used to define a label. Unlike your usual assembler, it appears we need to define the labels beforehand.&lt;/p>&lt;p>A label may also be an address directly, in this case, &lt;code>"Tutorial-x86_64.exe"+2D4F7&lt;/code>. Cheat Engine will overwrite code from this address onwards.&lt;/p>&lt;p>Executing Cheat Engine's assembler will greet you with the following message, provided everything went okay:&lt;/p>&lt;blockquote>&lt;p>&lt;strong>Information&lt;/strong>&lt;/p>&lt;p>The code injection was successfull&lt;br>newmem=FFFF0000&lt;br>Go to FFFF0000?&lt;/p>&lt;p>&lt;kbd>Yes&lt;/kbd> &lt;kbd>No&lt;/kbd>&lt;/p>&lt;/blockquote>&lt;p>If we navigate to the address, we find the following:&lt;/p>&lt;pre>...
FFFEFFFE -                       - ??
FFFEFFFF -                       - ??
FFFF0000 - 83 AE E0070000 01     - sub dword ptr [rsi+000007E0],01
FFFF0007 - E9 F2D40300           - jmp Tutorial-x86_64.exe+2D4FE
FFFF000C - 00 00                 - add [rax],al
...
FFFF0FFF - 00 00                 - add [rax],al
...
FFFF1001 -                       - ??
...
&lt;/pre>&lt;p>So, before this address we don't know what's in there. At the address, our newly inserted code is present, and after the code, a lot of zero values (which happen to be interpreted as &lt;code>add [rax], al&lt;/code>). After the allocated region (in our case, 2048 bytes), more unknown memory follows.&lt;/p>&lt;p>The old code was replaced with the jump:&lt;/p>&lt;pre>Tutorial-x86_64.exe+2D4F7 - E9 042BFCFF           - jmp FFFF0000
Tutorial-x86_64.exe+2D4FC - 66 90                 - nop 2
&lt;/pre>&lt;p>Note how the &lt;code>sub&lt;/code> instruction (&lt;code>83 AE E0070000 01&lt;/code>, 7 bytes) was replaced with both a &lt;code>jmp&lt;/code> (&lt;code>E9 042BFCFF&lt;/code>, 5 bytes) and a &lt;code>nop&lt;/code> (&lt;code>66 90&lt;/code>, 2 bytes), both occupying 7 bytes. Because the size was respected, any old jumps will still fall in the same locations. But we were lucky to be working with 7 whole bytes to ourselves. What happens if we try to do the same on, say, a &lt;code>nop&lt;/code> which is only 1 byte long?&lt;/p>&lt;pre>&lt;code class="language-asm">alloc(newmem,2048,"Tutorial-x86_64.exe"+2D4F0)
newmem:
nop
mov ebx,[rsi+000007E0]
jmp returnhere

"Tutorial-x86_64.exe"+2D4F0:
jmp newmem
nop 2
returnhere:
&lt;/code>&lt;/pre>&lt;p>Interesting! A single byte is obviously not enough, so Cheat Engine goes ahead and replaces &lt;em>two&lt;/em> instructions with the jump, even though we only intended to replace one. Note the old code at &lt;code>newmem&lt;/code>, it contains the &lt;code>nop&lt;/code> and the next instruction (this was just before the code we are meant to replace, so I picked it as the example).&lt;/p>&lt;p>Cheat Engine is obviously careful to both pick as many instructions as it needs to fit a &lt;code>jmp&lt;/code>, and the template pads the &lt;code>jmp&lt;/code> with as many &lt;code>nop&lt;/code> bytes as it needs to respect the old size.&lt;/p>&lt;p>If you attempt to assemble a longer instruction to replace a smaller one inline (as opposed to use the assembler with templates), Cheat Engine will warn you:&lt;/p>&lt;blockquote>&lt;p>&lt;strong>Confirmation&lt;/strong>&lt;/p>&lt;p>The generated code is 6 byte(s) long, but the selected opcode is 1 byte(s) long! Do you want to replace the incomplete opcode(s) with NOP's?&lt;/p>&lt;p>&lt;kbd>Yes&lt;/kbd> &lt;kbd>No&lt;/kbd> &lt;kbd>Cancel&lt;/kbd>&lt;/p>&lt;/blockquote>&lt;p>Selecting "No" will leave the incomplete bytes as they were before (in the case you replace a long instruction with a short one), which is very likely to leave garbage instructions behind and mess up with even more instructions.&lt;/p>&lt;h2 id="allocating-remote-memory">&lt;a href="#allocating-remote-memory">Allocating remote memory&lt;/a>&lt;/h2>&lt;p>When we initialize a new &lt;code>Vec&lt;/code> via &lt;code>Vec::with_capacity(2048)&lt;/code>, Rust will allocate enough space for 2048 items in a memory region that will belong to us. But we need this memory to belong to a different process, so that the remote process is the one with full Read, Write and eXecute access.&lt;/p>&lt;p>There's quite a few ways to allocate memory: &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-globalalloc">&lt;code>GlobalAlloc&lt;/code>&lt;/a>, &lt;a href="https://docs.microsoft.com/en-us/windows/desktop/api/WinBase/nf-winbase-localalloc">&lt;code>LocalAlloc&lt;/code>&lt;/a>, &lt;a href="https://docs.microsoft.com/en-us/windows/desktop/api/HeapApi/nf-heapapi-heapalloc">&lt;code>HeapAlloc&lt;/code>&lt;/a>, &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/memoryapi/nf-memoryapi-virtualalloc">&lt;code>VirtualAlloc&lt;/code>&lt;/a>… just to name a few! A process may even embed its own allocator which works on top of any of these. Each of these functions has its own purpose, with different tradeoffs, but the &lt;a href="https://docs.microsoft.com/en-us/windows/win32/memory/comparing-memory-allocation-methods">comparison on allocation methods&lt;/a> notes:&lt;/p>&lt;blockquote>&lt;p>Starting with 32-bit Windows, &lt;code>GlobalAlloc&lt;/code> and &lt;code>LocalAlloc&lt;/code> are implemented as wrapper functions that call &lt;code>HeapAlloc&lt;/code> using a handle to the process's default heap.&lt;/p>&lt;/blockquote>&lt;p>Cool! That's two down. &lt;code>CoTaskMemAlloc&lt;/code> seems to be useful in COM-based applications, which we don't care about, and &lt;code>VirtualAlloc&lt;/code>:&lt;/p>&lt;blockquote>&lt;p>[…] allows you to specify additional options for memory allocation. However, its allocations use a page granularity, so using &lt;code>VirtualAlloc&lt;/code> can result in higher memory usage.&lt;/p>&lt;/blockquote>&lt;p>…which we don't care about, either. Since &lt;code>HeapAlloc&lt;/code> requires "A handle to the heap from which the memory will be allocated", and as far as I can tell, there is no easy way to do this for a different process, we'll turn our attention back to &lt;code>VirtualAlloc&lt;/code>. The &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/memoryapi/nf-memoryapi-virtualalloc">documentation&lt;/a> reads:&lt;/p>&lt;blockquote>&lt;p>To allocate memory in the address space of another process, use the &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/memoryapi/nf-memoryapi-virtualallocex">&lt;code>VirtualAllocEx&lt;/code>&lt;/a> function.&lt;/p>&lt;/blockquote>&lt;p>There's our function! But before we can use it, we should figure out how the memory allocated by Cheat Engine looks like. I'll be using this code:&lt;/p>&lt;pre>&lt;code class="language-rust">let before = process.memory_regions();
std::thread::sleep(std::time::Duration::from_secs(10));
let after = process.memory_regions();

before.iter().for_each(|pre| {
    if let Some(post) = after.iter().find(|post| post.BaseAddress == pre.BaseAddress) {
        if post.RegionSize != pre.RegionSize {
            println!("region {:?} size changed: {:x} -&amp;gt; {:x}", pre.BaseAddress, pre.RegionSize, post.RegionSize);
        }
        if post.Protect != pre.Protect {
            println!("region {:?} prot changed: {:x} -&amp;gt; {:x}", pre.BaseAddress, pre.Protect, post.Protect);
        }
    } else {
        println!("region {:?} lost", pre.BaseAddress);
    }
});

after.iter().for_each(|post| {
    if !before.iter().any(|pre| pre.BaseAddress == post.BaseAddress) {
        println!("region {:?} came to life (size {:x}, prot {:x})", post.BaseAddress, post.RegionSize, post.Protect);
    }
});
&lt;/code>&lt;/pre>&lt;p>The results:&lt;/p>&lt;pre>region 0x7ffe3000 size changed: 8001d000 -&amp;gt; 8000d000
region 0xffff0000 came to life (size 1000, prot 40)
region 0xffff1000 came to life (size f000, prot 1)
&lt;/pre>&lt;p>So far, so good. This matches the address Cheat Engine was telling us about. It appears region 0x7ffe3000 was split to accomodate for region 0xffff0000, and the remaining had to become region 0xffff1000. The protection level for the region we care about is 40, which, according to the &lt;a href="https://docs.microsoft.com/en-us/windows/win32/memory/memory-protection-constants">documentation&lt;/a> is &lt;code>PAGE_EXECUTE_READWRITE&lt;/code>. It "Enables execute, read-only, or read/write access to the committed region of pages". Let's implement that in &lt;code>Process&lt;/code>:&lt;/p>&lt;pre>&lt;code class="language-rust">pub fn alloc(&amp;amp;self, addr: usize, size: usize) -&amp;gt; io::Result&amp;lt;usize&amp;gt; {
    let res = unsafe {
        winapi::um::memoryapi::VirtualAllocEx(
            self.handle.as_ptr(),
            addr as _,
            size,
            winnt::MEM_COMMIT | winnt::MEM_RESERVE,
            winnt::PAGE_EXECUTE_READWRITE,
        )
    };
    if res == ptr::null_mut() {
        Err(io::Error::last_os_error())
    } else {
        Ok(res as _)
    }
}

pub fn dealloc(&amp;amp;self, addr: usize) -&amp;gt; io::Result&amp;lt;()&amp;gt; {
    if unsafe {
        winapi::um::memoryapi::VirtualFreeEx(
            self.handle.as_ptr(),
            addr as _,
            0,
            winnt::MEM_RELEASE,
        )
    } == FALSE
    {
        Err(io::Error::last_os_error())
    } else {
        Ok(())
    }
}
&lt;/code>&lt;/pre>&lt;p>&lt;code>VirtualAllocEx&lt;/code> will also zero-initialize the remote memory, although we don't care much about that. To us, all the memory is initialized, because we work through &lt;code>ReadProcessMemory&lt;/code> which is the one responsible for filling our buffers. The only fun remark is that we also saw zero-bytes when we did the process with Cheat Engine, and not random garbage, so that may be an indicator that we're on the right track.&lt;/p>&lt;p>We also provide &lt;code>dealloc&lt;/code>, so that the user can free memory if they want to. Otherwise, they're causing a memory leak in a remote process.&lt;/p>&lt;h2 id="finding-the-right-spot">&lt;a href="#finding-the-right-spot">Finding the right spot&lt;/a>&lt;/h2>&lt;p>Before we go and allocate memory, we need to determine &lt;em>where&lt;/em> it should be allocated. Remember the &lt;code>jmp&lt;/code> instruction Cheat Engine added?:&lt;/p>&lt;pre>Tutorial-x86_64.exe+2D4F7 - E9 042BFCFF           - jmp FFFF0000
&lt;/pre>&lt;p>It's 5 bytes long, and the "address" is 4 bytes long. However, memory addresses are 8 bytes long! And also, the argument (&lt;code>042BFCFF&lt;/code>) to the jump (&lt;code>E9&lt;/code>) is backwards. Our machines are little endian, so the actual value is &lt;code>FFFC2B04&lt;/code> instead. I wonder what happens if…&lt;/p>&lt;pre>&lt;code class="language-python">&amp;gt;&amp;gt;&amp;gt; hex(0xFFFC2B04 + 0x2D4F7 + 5)
'0xffff0000'
&lt;/code>&lt;/pre>&lt;p>Aha! So the argument to the jump location is actually encoded &lt;em>relative&lt;/em> to the current instruction pointer &lt;em>after&lt;/em> reading the instruction (that's the plus five). In this case, all we need to do is find a memory region which is not yet reserved and is close enough to the offending instruction, so that we can make sure the relative offset will fit in 4 bytes:&lt;/p>&lt;pre>&lt;code class="language-rust">let regions = process
    .memory_regions()
    .into_iter()
    .filter(|p| (p.State &amp;amp; winnt::MEM_FREE) != 0)
    .collect::&amp;lt;Vec&amp;lt;_&amp;gt;&amp;gt;();

println!("{} regions free", regions.len());
&lt;/code>&lt;/pre>&lt;pre>68 regions free
&lt;/pre>&lt;p>Sure enough, there's still free regions available to us. Because &lt;code>memory_regions&lt;/code> is sorted by &lt;code>BaseAddress&lt;/code>, we can look for the first free region after the address we want to patch:&lt;/p>&lt;pre>&lt;code class="language-rust">let region = process
    .memory_regions()
    .into_iter()
    .find(|p| (p.State &amp;amp; winnt::MEM_FREE) != 0 &amp;amp;&amp;amp; p.BaseAddress as usize &amp;gt; addr)
    .unwrap();

println!("Found free region at {:?}", region.BaseAddress);
&lt;/code>&lt;/pre>&lt;pre>Do you want to simply inject NOPs replacing the old code at 10002d4fe (y/n)?: n
Found free region at 0x100321000
&lt;/pre>&lt;p>There we go! 0x2f3b02 bytes away of 0x10002d4fe, we have a free memory region at 0x100321000 where we can allocate memory to. Alas, trying to allocate memory here fails:&lt;/p>&lt;pre>&lt;code class="language-rust">Os { code: 487, kind: Other, message: "Attempt to access invalid address." }
&lt;/code>&lt;/pre>&lt;p>Well, to be fair, that's not the region Cheat Engine is finding. Here's what the memory looks like around the region Cheat Engine does use &lt;em>before&lt;/em> injecting the code:&lt;/p>&lt;pre>Region:
    BaseAddress: 0x7ffe6000
    AllocationBase: 0x0
    AllocationProtect: 0
    RegionSize: 8001a000
    State: 10000
    Protect: 1
    Type: 0
Region:
    BaseAddress: 0x100000000
    AllocationBase: 0x100000000
    AllocationProtect: 80
    RegionSize: 1000
    State: 1000
    Protect: 2
    Type: 1000000
&lt;/pre>&lt;p>And here is the after:&lt;/p>&lt;pre>Region:
    BaseAddress: 0x7ffe6000
    AllocationBase: 0x0
    AllocationProtect: 0
    RegionSize: 8000a000
    State: 10000
    Protect: 1
    Type: 0
Region:
    BaseAddress: 0xffff0000
    AllocationBase: 0xffff0000
    AllocationProtect: 40
    RegionSize: 1000
    State: 1000
    Protect: 40
    Type: 20000
Region:
    BaseAddress: 0xffff1000
    AllocationBase: 0x0
    AllocationProtect: 0
    RegionSize: f000
    State: 10000
    Protect: 1
    Type: 0
Region:
    BaseAddress: 0x100000000
    AllocationBase: 0x100000000
    AllocationProtect: 80
    RegionSize: 1000
    State: 1000
    Protect: 2
    Type: 1000000
&lt;/pre>&lt;p>Notice how the region it picked was 0x7ffe_6000, not 0x1_0000_0000. The offending instruction is at 0x1_0002_d4fe. So the jumps can go backwards just fine. But this doesn't really explain why the allocation at 0x1_0032_1000 failed, because it has the same state (&lt;code>MEM_FREE&lt;/code>) and protection level (&lt;code>PAGE_NOACCESS&lt;/code>) as the page at 0x7ffe_6000. I can't really explain why this is the case, but I can change the code to pick a free memory region before and not after the offending instruction:&lt;/p>&lt;pre>&lt;code class="language-rust">let region = process
    .memory_regions()
    .into_iter()
    .rev() // &amp;lt;- new                                               flipped v
    .find(|p| (p.State &amp;amp; winnt::MEM_FREE) != 0 &amp;amp;&amp;amp; (p.BaseAddress as usize) &amp;lt; addr)
    .unwrap();
&lt;/code>&lt;/pre>&lt;pre>Found free region at 0x7ffe6000
thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: Os { code: 487, kind: Other, message: "Attempt to access invalid address." }', src\main.rs:151:74
&lt;/pre>&lt;p>Perhaps the two regions aren't so different after all? At least we're picking the same region as Cheat Engine now. But why is the allocation failing? I'll be honest, I have no idea. We do have the required &lt;code>PROCESS_VM_OPERATION&lt;/code> permission. I do not think the error is caused by enclaves (and I don't even know what those are):&lt;/p>&lt;blockquote>&lt;p>If the address in within an enclave that you initialized, then the allocation operation fails with the &lt;code>ERROR_INVALID_ADDRESS&lt;/code> error.&lt;/p>&lt;/blockquote>&lt;p>It also does not seem to be an issue with reserve and commit:&lt;/p>&lt;blockquote>&lt;p>Attempting to commit a specific address range by specifying &lt;code>MEM_COMMIT&lt;/code> without &lt;code>MEM_RESERVE&lt;/code> and a non-&lt;code>NULL&lt;/code> &lt;code>lpAddress&lt;/code> fails unless the entire range has already been reserved. The resulting error code is &lt;code>ERROR_INVALID_ADDRESS&lt;/code>.&lt;/p>&lt;/blockquote>&lt;p>We are using both &lt;code>MEM_COMMIT&lt;/code> and &lt;code>MEM_RESERVE&lt;/code>, and our &lt;code>lpAddress&lt;/code> is not null.&lt;/p>&lt;p>Let's try reserving a memory region, but this time, from the end of the region (instead of from the beginning):&lt;/p>&lt;pre>&lt;code class="language-rust">let addr = (region.BaseAddress as usize + region.RegionSize) - 2048;
match process.alloc(addr, 2048) {
    Ok(addr) =&amp;gt; {
        println!("Bingo: {:x}", addr);
        process.dealloc(addr);
    }
    Err(_) =&amp;gt; {
        println!("Nope");
    }
}
&lt;/code>&lt;/pre>&lt;pre>Bingo: ffff0000
&lt;/pre>&lt;p>Hey, that's… the same value Cheat Engine writes to! At the very last&lt;a href="#fn:1">&lt;sup id="fnref:1">↪1&lt;/sup>&lt;/a>, we can allocate memory where we can inject our assembled code.&lt;/p>&lt;h2 id="code-injection">&lt;a href="#code-injection">Code injection&lt;/a>&lt;/h2>&lt;p>Now, we could go as far as getting our hands on some assembler, such as &lt;a href="https://nasm.us/index.php">NASM&lt;/a>, and invoke it on the input the user wishes to replace. Then we could read the output bytes of the assembled file, and write it to the desired memory location. However… that's just a lot of tedious work that won't teach us much (the Rust documentation already does an excellent job at teaching us how to work with files and invoke an external process). So I am going to cheat and hardcode the right bytes to complete this step of the tutorial.&lt;/p>&lt;p>Here's what Cheat Engine says the area we're going to patch with the jump looks like:&lt;/p>&lt;pre>Tutorial-x86_64.exe+2D4F0 - 90                    - nop
Tutorial-x86_64.exe+2D4F1 - 8B 9E E0070000        - mov ebx,[rsi+000007E0]
Tutorial-x86_64.exe+2D4F7 - 83 AE E0070000 01     - sub dword ptr [rsi+000007E0],01
Tutorial-x86_64.exe+2D4FE - 48 8D 4D F8           - lea rcx,[rbp-08]
Tutorial-x86_64.exe+2D502 - E8 19B9FDFF           - call Tutorial-x86_64.exe+8E20
&lt;/pre>&lt;p>Here's the after:&lt;/p>&lt;pre>Tutorial-x86_64.exe+2D4F0 - 90                    - nop
Tutorial-x86_64.exe+2D4F1 - 8B 9E E0070000        - mov ebx,[rsi+000007E0]
Tutorial-x86_64.exe+2D4F7 - E9 042BFCFF           - jmp FFFF0000
Tutorial-x86_64.exe+2D4FC - 66 90                 - nop 2
Tutorial-x86_64.exe+2D4FE - 48 8D 4D F8           - lea rcx,[rbp-08]
Tutorial-x86_64.exe+2D502 - E8 19B9FDFF           - call Tutorial-x86_64.exe+8E20
&lt;/pre>&lt;pre>FFFF0000 - 83 86 E0070000 02     - add dword ptr [rsi+000007E0],02
FFFF0007 - E9 F2D40300           - jmp Tutorial-x86_64.exe+2D4FE
&lt;/pre>&lt;p>Let's finish up this tutorial step. Don't worry though, the addresses will still be correctly calculated. It's just the opcodes for the ADD instruction and NOP, mostly:&lt;/p>&lt;pre>&lt;code class="language-rust">let region = process
    .memory_regions()
    .into_iter()
    .rev()
    .find(|p| (p.State &amp;amp; winnt::MEM_FREE) != 0 &amp;amp;&amp;amp; (p.BaseAddress as usize) &amp;lt; addr)
    .unwrap();

let target_addr = process.alloc(region.BaseAddress as usize + region.RegionSize - 2048, 2048).unwrap();

// The relative JMP itself are 5 bytes, the last 2 are NOP (hence the -2 in delta calculation).
// Relative jumps add to the instruction pointer when it *ends* executing the instruction (like JMP).
//   jmp target_addr
//   nop 2
let mut jmp = [0xE9, 0, 0, 0, 0, 0x66, 0x90];
jmp[1..5].copy_from_slice(&amp;amp;((target_addr as isize - (addr - 2) as isize) as i32).to_le_bytes());
process.write_memory(addr - jmp.len(), &amp;amp;jmp).unwrap();

// addr is already where the old instruction ended, no need to re-skip our previously written jump.
// By the end of the execution of this jump, the instruction pointer will be at (base + code len).
//   add dword ptr [rsi+000007E0], 2
//   jmp addr
let mut injection = [0x83, 0x86, 0xE0, 0x07, 0x00, 0x00, 0x02, 0xE9, 0, 0, 0, 0];
let inj_len = injection.len();
injection[8..12].copy_from_slice(&amp;amp;((addr as isize - (target_addr + inj_len) as isize) as i32).to_le_bytes());
process.write_memory(target_addr, &amp;amp;injection).unwrap();

println!("Replaced the SUB 1 at {:x} with ADD 2 at {:x} successfully!", addr, target_addr);
&lt;/code>&lt;/pre>&lt;p>So there we have it! The code calculates the correct relative address to jump to, depending on wherever the breakpoint was hit and wherever we ended up allocating memory. It also places in the ADD instruction, and this is enough to complete this tutorial step!&lt;/p>&lt;h2 id="other-code-injection-techniques">&lt;a href="#other-code-injection-techniques">Other code injection techniques&lt;/a>&lt;/h2>&lt;p>We have seen one way to inject more than enough code for most needs (just allocate as much as you need!), through the use of watchpoints to figure out where the offending code we want to patch is. But this is not the only way!&lt;/p>&lt;p>There are things known as "Windows hooks" which allow us to inject entire DLLs (Dynamic Loaded Libraries). We could also try mapping an existing program into the address space of the victim thread. Or we could create a remote thread which loads the library. Here's the more detailed &lt;a href="https://www.codeproject.com/Articles/4610/Three-Ways-to-Inject-Your-Code-into-Another-Proces">Three Ways to Inject Your Code into Another Process&lt;/a> article.&lt;/p>&lt;p>When writing this post, I discovered other things, such as &lt;a href="https://duckduckgo.com/?t=ffcm&amp;q=SE_DEBUG_NAME&amp;ia=web">what the &lt;code>SE_DEBUG_NAME&lt;/code>&lt;/a> was and if I needed it, &lt;a href="https://forum.exetools.com/showthread.php?t=8963">why &lt;code>VirtualAlloc&lt;/code> was failing&lt;/a> or &lt;a href="https://stackoverflow.com/a/21683133/">why could it be failing&lt;/a>, &lt;a href="https://social.msdn.microsoft.com/Forums/en-US/4ccf4dd8-eb43-4f5e-8860-c588d6a4f880/virtualallocex-memreserve-pagereadwrite-has-failed-with-system-error-code-487">what the error code meant&lt;/a>, among a couple other things. So there is definitely a lot to learn about this topic&lt;a href="#fn:2">&lt;sup id="fnref:2">↪2&lt;/sup>&lt;/a>.&lt;/p>&lt;h2 id="finale">&lt;a href="#finale">Finale&lt;/a>&lt;/h2>&lt;p>This post was a bit bittersweet for me! One takeaway definitely is the need to be a bit more creative when it comes down to studying how a different program works, but after all, if Cheat Engine can do it, so can we. There are still some unknowns left, and some shortcuts which we could've avoided, but regardless, we've seen how we can make it work. Making it ergonomic or more customizable comes later. Really, sometimes you just need to &lt;a href="https://jacobian.org/2021/apr/7/embrace-the-grind/">embrace the grind&lt;/a> and get a first working version out. Don't obsess with making it perfect or cleaner at first, it's such a waste of time (if you &lt;em>are&lt;/em> going to clean it up in the end, plan ahead, estimate how long it would take, and put aside your changes until the cleaning is done).&lt;/p>&lt;p>The &lt;a href="https://github.com/lonami/memo">code for this post&lt;/a> is available over at my GitHub. You can run &lt;code>git checkout step7&lt;/code> after cloning the repository to get the right version of the code. Again, only the code necessary to complete the step is included at the &lt;code>step7&lt;/code> tag.&lt;/p>&lt;p>In the next post, we'll tackle the eighth step of the tutorial: Multilevel pointers. This step is what actually got me inspired into starting this entire series, which is why you may have felt this entry a bit more rushed. It is fairly more complicated than &lt;a href="/blog/woce-6">part 6&lt;/a> with a single pointer, because there's some ingenious work that needs to be done in order to efficiently, and automatically, solve it. I didn't manage to figure it out before starting the series, but maybe we're prepared now?&lt;/p>&lt;p>The &lt;a href="/blog/woce-8">next post&lt;/a> will also be the second-to-last entry in this series (the last step looks pretty tough as well!). After that, there are bonus levels of an actual graphical game, but as far as I can tell, it's there to gain a bit more experience with something more "serious", which I will probably leave as an exercise to the reader.&lt;/p>&lt;h3 id="footnotes">&lt;a href="#footnotes">Footnotes&lt;/a>&lt;/h3>&lt;p id="fn:1" class="footnote-definition">&lt;span>1&lt;/span> That "little" hiccup of me trying to figure out how Cheat Engine was finding that precise working location is what put an end to my one-blog-per-week streak. Ah well, sometimes taking a break from something and coming back to it later on just makes the problem obvious (or in this case, a new simple idea which happened to work).&amp;nbsp;&lt;a href="#fnref:1">↩&lt;/a>&lt;/p>&lt;p id="fn:2" class="footnote-definition">&lt;span>2&lt;/span> I'm still not sure why we could not allocate near the first bytes of the free region, but we could do so just fine near the end.&amp;nbsp;&lt;a href="#fnref:2">↩&lt;/a>&lt;/p></content></entry><entry xml:lang="en"><title>Writing our own Cheat Engine: Pointers</title><published>2021-03-13T00:00:00+00:00</published><updated>2021-03-13T00:00:00+00:00</updated><link href="https://lonami.dev/blog/woce-6/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/woce-6/</id><content type="html">&lt;p>This is part 6 on the &lt;em>Writing our own Cheat Engine&lt;/em> series:&lt;/p>&lt;ul>&lt;li>&lt;a href="/blog/woce-1">Part 1: Introduction&lt;/a> (start here if you're new to the series!)&lt;/li>&lt;li>&lt;a href="/blog/woce-2">Part 2: Exact Value scanning&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-3">Part 3: Unknown initial value&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-4">Part 4: Floating points&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-5">Part 5: Code finder&lt;/a>&lt;/li>&lt;li>Part 6: Pointers&lt;/li>&lt;li>&lt;a href="/blog/woce-7">Part 7: Code Injection&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-8">Part 8: Multilevel pointers&lt;/a>&lt;/li>&lt;/ul>&lt;p>In part 5 we wrote our very own debugger. We learnt that Cheat Engine is using hardware breakpoints to watch memory change, and how to do the same ourselves. We also learnt that hardware points are not the only way to achieve the effect of watchpoints, although they certainly are the fastest and cleanest approach.&lt;/p>&lt;p>In this post, we will be reusing some of that knowledge to find out a closely related value, the &lt;em>pointer&lt;/em> that points to the real value&lt;a href="#fn:1">&lt;sup id="fnref:1">↪1&lt;/sup>&lt;/a>. As a quick reminder, a pointer is nothing but an &lt;code>usize&lt;/code>&lt;a href="#fn:2">&lt;sup id="fnref:2">↪2&lt;/sup>&lt;/a> representing the address of another portion of memory, in this case, the actual value we will be scanning for. A pointer is a value that, well, points elsewhere. In Rust we normally use reference instead, which are safer (typed and their lifetime is tracked) than pointers, but in the end we can achieve the same with both.&lt;/p>&lt;p>Why care about pointers? It turns out that things, such as your current health in-game, are very unlikely to end up in the same memory position when you restart the game (or even change to another level, or even during gameplay). So, if you perform a scan and find that the address where your health is stored is &lt;code>0x73AABABE&lt;/code>, you might be tempted to save it and reuse it next time you launch the game. Now you don't need to scan for it again! Alas, as soon as you restart the game, the health is now stored at &lt;code>0x5AADBEEF&lt;/code>.&lt;/p>&lt;p>Not all hope is lost! The game must &lt;em>somehow&lt;/em> have a way to reliably find this value, and the way it's done is with pointers. There will always be some base address that holds a pointer, and the game code knows where to find this pointer. If we are also able to find the pointer at said base address, and follow it ourselves ("dereferencing" it), we can perform the same steps the game is doing, and reliably find the health no matter how much we restart the game&lt;a href="#fn:3">&lt;sup id="fnref:3">↪3&lt;/sup>&lt;/a>.&lt;/p>&lt;h2 id="pointers">&lt;a href="#pointers">Pointers&lt;/a>&lt;/h2>&lt;details open>&lt;summary>Cheat Engine Tutorial: Step 6&lt;/summary>&lt;blockquote>&lt;p>In the previous step I explained how to use the Code finder to handle changing locations. But that method alone makes it difficult to find the address to set the values you want. That's why there are pointers:&lt;/p>&lt;p>At the bottom you'll find 2 buttons. One will change the value, and the other changes the value AND the location of the value. For this step you don't really need to know assembler, but it helps a lot if you do.&lt;/p>&lt;p>First find the address of the value. When you've found it use the function to find out what accesses this address.&lt;/p>&lt;p>Change the value again, and a item will show in the list. Double click that item. (or select and click on more info) and a new window will open with detailed information on what happened when the instruction ran.&lt;/p>&lt;p>If the assembler instruction doesn't have anything between a '[' and ']' then use another item in the list. If it does it will say what it think will be the value of the pointer you need.&lt;/p>&lt;p>Go back to the main cheat engine window (you can keep this extra info window open if you want, but if you close it, remember what is between the [ and ]) and do a 4 byte scan in hexadecimal for the value the extra info told you. When done scanning it may return 1 or a few hundred addresses. Most of the time the address you need will be the smallest one. Now click on manually add and select the pointer checkbox.&lt;/p>&lt;p>The window will change and allow you to type in the address of a pointer and a offset. Fill in as address the address you just found. If the assembler instruction has a calculation (e.g: [esi+12]) at the end then type the value in that's at the end. else leave it 0. If it was a more complicated instruction look at the calculation.&lt;/p>&lt;p>Example of a more complicated instruction:&lt;/p>&lt;p>[EAX*2+EDX+00000310] eax=4C and edx=00801234.&lt;/p>&lt;p>In this case EDX would be the value the pointer has, and EAX*2+00000310 the offset, so the offset you'd fill in would be 2*4C+00000310=3A8. (this is all in hex, use calc.exe from windows in scientific mode to calculate).&lt;/p>&lt;p>Back to the tutorial, click OK and the address will be added, If all went right the address will show P-&amp;gt;xxxxxxx, with xxxxxxx being the address of the value you found. If thats not right, you've done something wrong. Now, change the value using the pointer you added in 5000 and freeze it. Then click Change pointer, and if all went right the next button will become visible.&lt;/p>&lt;p>&lt;em>extra&lt;/em>: And you could also use the pointer scanner to find the pointer to this address.&lt;/p>&lt;/blockquote>&lt;/details>&lt;h2 id="on-access-watchpoints">&lt;a href="#on-access-watchpoints">On-access watchpoints&lt;/a>&lt;/h2>&lt;p>Last time we managed to learn how hardware breakpoints were being set by observing Cheat Engine's behaviour. I think it's now time to handle this properly instead. We'll check out the &lt;a href="https://wiki.osdev.org/CPU_Registers_x86#Debug_Registers">CPU Registers x86 page on OSDev&lt;/a> to learn about it:&lt;/p>&lt;ul>&lt;li>DR0, DR1, DR2 and DR3 can hold a memory address each. This address will be used by the breakpoint.&lt;/li>&lt;li>DR4 is actually an &lt;a href="https://en.wikipedia.org/wiki/X86_debug_register">obsolete synonym&lt;/a> for DR6.&lt;/li>&lt;li>DR5 is another obsolete synonym, this time for DR7.&lt;/li>&lt;li>DR6 is debug status. The four lowest bits indicate which breakpoint was hit, and the four highest bits contain additional information. We should make sure to clear this ourselves when a breakpoint is hit.&lt;/li>&lt;li>DR7 is debug control, which we need to study more carefully.&lt;/li>&lt;/ul>&lt;p>Each debug register DR0 through DR3 has two corresponding bits in DR7, starting from the lowest-order bit, to indicate whether the corresponding register is a &lt;strong>L&lt;/strong>ocal or &lt;strong>G&lt;/strong>lobal breakpoint. So it looks like this:&lt;/p>&lt;pre>  Meaning: [ .. .. | G3 | L3 | G2 | L2 | G1 | L1 | G0 | L0 ]
Bit-index:   31-08 | 07 | 06 | 05 | 04 | 03 | 02 | 01 | 00
&lt;/pre>&lt;p>Cheat Engine was using local breakpoints, because the zeroth bit was set. Probably because we don't want these breakpoints to infect other programs! Because we were using only one breakpoint, only the lowermost bit was being set. The local 1st, 2nd and 3rd bits were unset.&lt;/p>&lt;p>Now, each debug register DR0 through DR4 has four additional bits in DR7, two for the &lt;strong>C&lt;/strong>ondition and another two for the &lt;strong>S&lt;/strong>ize:&lt;/p>&lt;pre>  Meaning: [   S3  |   C3  |   S2  |   C2  |   S1  |   C1  |   S0  |   C0  | .. .. ]
Bit-index:   31 30 | 29 28 | 27 26 | 25 24 | 23 22 | 21 20 | 19 18 | 17 16 | 15-00
&lt;/pre>&lt;p>The two bits of the condition mean the following:&lt;/p>&lt;ul>&lt;li>&lt;code>00&lt;/code> execution breakpoint.&lt;/li>&lt;li>&lt;code>01&lt;/code> write watchpoint.&lt;/li>&lt;li>&lt;code>11&lt;/code> read/write watchpoint.&lt;/li>&lt;li>&lt;code>10&lt;/code> unsupported I/O read/write.&lt;/li>&lt;/ul>&lt;p>When we were using Cheat Engine to add write watchpoints, the bits 17 and 16 were indeed set to &lt;code>01&lt;/code>, and the bits 19 and 18 were set to &lt;code>11&lt;/code>. Hm, but &lt;em>11&lt;sub>2&lt;/sub>&amp;nbsp;=&amp;nbsp;3&lt;sub>10&lt;/sub>&lt;/em>&amp;nbsp;, and yet, we were watching writes to 4 bytes. So what's up with this? Is there a different mapping for the size which isn't documented at the time of writing? Seems we need to learn from Cheat Engine's behaviour one more time.&lt;/p>&lt;p>For reference, this is what DR7 looked like when we added a single write watchpoint:&lt;/p>&lt;pre>hex: 000d_0001
bin: 00000000_00001101_00000000_00000001
&lt;/pre>&lt;p>And this is the code I will be using to check the breakpoints of different sizes:&lt;/p>&lt;pre>thread::enum_threads(pid)
    .unwrap()
    .into_iter()
    .for_each(|tid| {
        let thread = thread::Thread::open(tid).unwrap();
        let ctx = thread.get_context().unwrap();
        eprintln!("hex: {:08x}", ctx.Dr7);
        eprintln!("bin: {:032b}", ctx.Dr7);
    });
&lt;/pre>&lt;p>Let's compare this to watchpoints for sizes 1, 2, 4 and 8 bytes:&lt;/p>&lt;pre>1 byte
hex: 0001_0401
bin: 00000000_00000001_00000100_00000001

2 bytes
hex: 0005_0401
bin: 00000000_00000101_00000100_00000001

4 bytes
hex: 000d_0401
bin: 00000000_00001101_00000100_00000001

8 bytes
hex: 0009_0401
bin: 00000000_00001001_00000100_00000001
                            ^ wut?
&lt;/pre>&lt;p>I have no idea what's up with that stray tenth bit. Its use does not seem documented, and things worked fine without it, so we'll ignore it. The lowest bit is set to indicate we're using DR0, bits 17 and 16 represent the write watchpoint, and the size seems to be as follows:&lt;/p>&lt;ul>&lt;li>&lt;code>00&lt;/code> for a single byte.&lt;/li>&lt;li>&lt;code>01&lt;/code> for two bytes (a "word").&lt;/li>&lt;li>&lt;code>11&lt;/code> for four bytes (a "double word").&lt;/li>&lt;li>&lt;code>10&lt;/code> for eight bytes (a "quadruple word").&lt;/li>&lt;/ul>&lt;p>Doesn't make much sense if you ask me, but we'll roll with it. Just to confirm, this is what the "on-access" breakpoint looks like according to Cheat Engine:&lt;/p>&lt;pre>hex: 000f_0401
bin: 00000000_00001111_00000100_00000001
&lt;/pre>&lt;p>So it all checks out! The bit pattern is &lt;code>11&lt;/code> for read/write (technically, a write is also an access). Let's implement this!&lt;/p>&lt;h2 id="proper-breakpoint-handling">&lt;a href="#proper-breakpoint-handling">Proper breakpoint handling&lt;/a>&lt;/h2>&lt;p>The first thing we need to do is represent the possible breakpoint conditions:&lt;/p>&lt;pre>&lt;code class="language-rust">#[repr(u8)]
pub enum Condition {
    Execute = 0b00,
    Write = 0b01,
    Access = 0b11,
}
&lt;/code>&lt;/pre>&lt;p>And also the legal breakpoint sizes:&lt;/p>&lt;pre>&lt;code class="language-rust">#[repr(u8)]
pub enum Size {
    Byte = 0b00,
    Word = 0b01,
    DoubleWord = 0b11,
    QuadWord = 0b10,
}
&lt;/code>&lt;/pre>&lt;p>We are using &lt;code>#[repr(u8)]&lt;/code> so that we can convert a given variant into the corresponding bit pattern. With the right types defined in order to set a breakpoint, we can start implementing the method that will set them (inside &lt;code>impl Thread&lt;/code>):&lt;/p>&lt;pre>&lt;code class="language-rust">pub fn add_breakpoint(&amp;amp;self, addr: usize, cond: Condition, size: Size) -&amp;gt; io::Result&amp;lt;Breakpoint&amp;gt; {
    let mut context = self.get_context()?;
    todo!()
}
&lt;/code>&lt;/pre>&lt;p>First, let's try finding an "open spot" where we could set our breakpoint. We will "slide" a the &lt;code>0b11&lt;/code> bitmask over the lowest eight bits, and if and only if both the local and global bits are unset, then we're free to set a breakpoint at this index&lt;a href="#fn:4">&lt;sup id="fnref:4">↪4&lt;/sup>&lt;/a>:&lt;/p>&lt;pre>&lt;code class="language-rust">let index = (0..4)
    .find_map(|i| ((context.Dr7 &amp;amp; (0b11 &amp;lt;&amp;lt; (i * 2))) == 0).then(|| i))
    .ok_or_else(|| io::Error::new(io::ErrorKind::Other, "no debug register available"))?;
&lt;/code>&lt;/pre>&lt;p>Once an &lt;code>index&lt;/code> is found, we can set the address we want to watch in the corresponding register and update the debug control bits:&lt;/p>&lt;pre>&lt;code class="language-rust">let addr = addr as u64;
match index {
    0 =&amp;gt; context.Dr0 = addr,
    1 =&amp;gt; context.Dr1 = addr,
    2 =&amp;gt; context.Dr2 = addr,
    3 =&amp;gt; context.Dr3 = addr,
    _ =&amp;gt; unreachable!(),
}

let clear_mask = !((0b1111 &amp;lt;&amp;lt; (16 + index * 4)) | (0b11 &amp;lt;&amp;lt; (index * 2)));
context.Dr7 &amp;amp;= clear_mask;

context.Dr7 |= 1 &amp;lt;&amp;lt; (index * 2);

let sc = (((size as u8) &amp;lt;&amp;lt; 2) | (cond as u8)) as u64;
context.Dr7 |= sc &amp;lt;&amp;lt; (16 + index * 4);

self.set_context(&amp;amp;context)?;
Ok(Breakpoint {
    thread: self,
    clear_mask,
})
&lt;/code>&lt;/pre>&lt;p>Note that we're first creating a "clear mask". We switch on all the bits that we may use for this breakpoint, and then negate. Effectively, &lt;code>Dr7 &amp;amp; clear_mask&lt;/code> will make sure we don't leave any bit high on accident. We apply the mask before OR-ing the rest of bits to also clear any potential garbage on the size and condition bits. Next, we set the bit to enable the new local breakpoint, and also store the size and condition bits at the right location.&lt;/p>&lt;p>With the context updated, we can set it back and return the &lt;code>Breakpoint&lt;/code>. It stores the &lt;code>thread&lt;/code> and the &lt;code>clear_mask&lt;/code> so that it can clean up on &lt;code>Drop&lt;/code>. We are technically relying on &lt;code>Drop&lt;/code> to run behaviour here, but the cleanup is done on a best-effort basis. If the user intentionally forgets the &lt;code>Breakpoint&lt;/code>, maybe they want the &lt;code>Breakpoint&lt;/code> to forever be set.&lt;/p>&lt;p>This logic is begging for a testcase though; I'll split it into a new &lt;code>Breakpoint::update_dbg_control&lt;/code> method and test that out:&lt;/p>&lt;pre>&lt;code class="language-rust">
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn brk_add_one() {
        // DR7 starts with garbage which should be respected.
        let (clear_mask, dr, dr7) =
            Breakpoint::update_dbg_control(0x1700, Condition::Write, Size::DoubleWord).unwrap();

        assert_eq!(clear_mask, 0xffff_ffff_fff0_fffc);
        assert_eq!(dr, DebugRegister::Dr0);
        assert_eq!(dr7, 0x0000_0000_000d_1701);
    }

    #[test]
    fn brk_add_two() {
        let (clear_mask, dr, dr7) = Breakpoint::update_dbg_control(
            0x0000_0000_000d_0001,
            Condition::Write,
            Size::DoubleWord,
        )
        .unwrap();

        assert_eq!(clear_mask, 0xffff_ffff_ff0f_fff3);
        assert_eq!(dr, DebugRegister::Dr1);
        assert_eq!(dr7, 0x0000_0000_00dd_0005);
    }

    #[test]
    fn brk_try_add_when_max() {
        assert!(Breakpoint::update_dbg_control(
            0x0000_0000_dddd_0055,
            Condition::Write,
            Size::DoubleWord
        )
        .is_none());
    }
}
&lt;/code>&lt;/pre>&lt;pre>running 3 tests
test thread::tests::brk_add_one ... ok
test thread::tests::brk_add_two ... ok
test thread::tests::brk_try_add_when_max ... ok
&lt;/pre>&lt;p>Very good! With proper breakpoint handling usable, we can continue.&lt;/p>&lt;h2 id="inferring-the-pointer-value">&lt;a href="#inferring-the-pointer-value">Inferring the pointer value&lt;/a>&lt;/h2>&lt;p>After scanning memory for the location we're looking for (say, our current health), we then add an access watchpoint, and wait for an exception to occur. As a reminder, here's the page with the &lt;a href="https://docs.microsoft.com/en-us/windows/win32/debug/debugging-events">Debugging Events&lt;/a>:&lt;/p>&lt;pre>&lt;code class="language-rust">let addr = ...;
let mut threads = ...;

let _watchpoints = threads
    .iter_mut()
    .map(|thread| {
        thread
            .add_breakpoint(addr, thread::Condition::Access, thread::Size::DoubleWord)
            .unwrap()
    })
    .collect::&amp;lt;Vec&amp;lt;_&amp;gt;&amp;gt;();

loop {
    let event = debugger.wait_event(None).unwrap();
    if event.dwDebugEventCode == winapi::um::minwinbase::EXCEPTION_DEBUG_EVENT {
        let exc = unsafe { event.u.Exception() };
        if exc.ExceptionRecord.ExceptionCode == winapi::um::minwinbase::EXCEPTION_SINGLE_STEP {
            todo!();
        }
    }
    debugger.cont(event, true).unwrap();
}
&lt;/code>&lt;/pre>&lt;p>Now, inside the &lt;code>todo!()&lt;/code> we will want to do a few things, namely printing out the instructions "around this location" and dumping the entire thread context on screen. To print the instructions, we need to import &lt;code>iced_x86&lt;/code> again, iterate over all memory regions to find the region where the exception happened, read the corresponding bytes, decode the instructions, and when we find the one with a corresponding instruction pointer, print "around it":&lt;/p>&lt;pre>&lt;code class="language-rust">use iced_x86::{Decoder, DecoderOptions, Formatter, Instruction, NasmFormatter};

let addr = exc.ExceptionRecord.ExceptionAddress as usize;
let region = process
    .memory_regions()
    .into_iter()
    .find(|region| {
        let base = region.BaseAddress as usize;
        base &amp;lt;= addr &amp;amp;&amp;amp; addr &amp;lt; base + region.RegionSize
    })
    .unwrap();

let bytes = process
    .read_memory(region.BaseAddress as usize, region.RegionSize)
    .unwrap();

let mut decoder = Decoder::new(64, &amp;amp;bytes, DecoderOptions::NONE);
decoder.set_ip(region.BaseAddress as _);

let mut formatter = NasmFormatter::new();
let mut output = String::new();

let instructions = decoder.into_iter().collect::&amp;lt;Vec&amp;lt;_&amp;gt;&amp;gt;();
for (i, ins) in instructions.iter().enumerate() {
    if ins.next_ip() as usize == addr {
        let low = i.saturating_sub(5);
        let high = (i + 5).min(instructions.len());
        for j in low..high {
            let ins = &amp;amp;instructions[j];
            print!("{} {:016X} ", if j == i { "&amp;gt;&amp;gt;&amp;gt;" } else { "   " }, ins.ip());
            let k = (ins.ip() - region.BaseAddress as usize as u64) as usize;
            let instr_bytes = &amp;amp;bytes[k..k + ins.len()];
            for b in instr_bytes.iter() {
                print!("{:02X}", b);
            }
            if instr_bytes.len() &amp;lt; 10 {
                for _ in 0..10usize.saturating_sub(instr_bytes.len()) {
                    print!("  ");
                }
            }

            output.clear();
            formatter.format(ins, &amp;amp;mut output);
            println!(" {}", output);
        }
        break;
    }
}
debugger.cont(event, true).unwrap();
break;
&lt;/code>&lt;/pre>&lt;p>The result is pretty fancy:&lt;/p>&lt;pre>    000000010002CAAC 48894DF0             mov [rbp-10h],rcx
    000000010002CAB0 488955F8             mov [rbp-8],rdx
    000000010002CAB4 48C745D800000000     mov qword [rbp-28h],0
    000000010002CABC 90                   nop
    000000010002CABD 488B050CA02D00       mov rax,[rel 100306AD0h]
&amp;gt;&amp;gt;&amp;gt; 000000010002CAC4 8B00                 mov eax,[rax]
    000000010002CAC6 8945EC               mov [rbp-14h],eax
    000000010002CAC9 B9E8030000           mov ecx,3E8h
    000000010002CACE E88D2FFEFF           call 000000010000FA60h
    000000010002CAD3 8945E8               mov [rbp-18h],eax
&lt;/pre>&lt;p>Cool! So &lt;code>rax&lt;/code> is holding an address, meaning it's a pointer, and the value it reads (dereferences) is stored back into &lt;code>eax&lt;/code> (because it does not need &lt;code>rax&lt;/code> anymore). Alas, the current thread context has the register state &lt;em>after&lt;/em> the instruction was executed, and &lt;code>rax&lt;/code> no longer contains the address at this point. However, notice how the previous instruction writes a fixed value to &lt;code>rax&lt;/code>, and then that value is used to access memory, like so:&lt;/p>&lt;pre>&lt;code class="language-rust">let eax = memory[memory[0x100306AD0]];
&lt;/code>&lt;/pre>&lt;p>The value at &lt;code>memory[0x100306AD0]&lt;/code> &lt;em>is&lt;/em> the pointer! No offsets are used, because nothing is added to the pointer after it's read. This means that, if we simply scan for the address we were looking for, we should find out where the pointer is stored:&lt;/p>&lt;pre>&lt;code class="language-rust">let addr = ...;
let scan = process.scan_regions(&amp;amp;regions, Scan::Exact(addr as u64));

scan.into_iter().for_each(|region| {
    region.locations.iter().for_each(|ptr_addr| {
        println!("[{:x}] = {:x}", ptr_addr, addr);
    });
});
&lt;/code>&lt;/pre>&lt;p>And just like that:&lt;/p>&lt;pre>[100306ad0] = 15de9f0
&lt;/pre>&lt;p>Notice how the pointer address found matches with the offset used by the instructions:&lt;/p>&lt;pre>    000000010002CABD 488B050CA02D00       mov rax,[rel 100306AD0h]
           this is the same as the value we just found ^^^^^^^^^^
&lt;/pre>&lt;p>Very interesting indeed. We were actually very lucky to have only found a single memory location containing the pointer value, &lt;code>0x15de9f0&lt;/code>. Cheat Engine somehow knows that this value is always stored at &lt;code>0x100306ad0&lt;/code> (or rather, at &lt;code>Tutorial-x86_64.exe+306AD0&lt;/code>), because the address shows green. How does it do this?&lt;/p>&lt;h2 id="base-addresses">&lt;a href="#base-addresses">Base addresses&lt;/a>&lt;/h2>&lt;p>Remember back in &lt;a href="/blog/woce-2">part 2&lt;/a> when we introduced the memory regions? They're making a comeback! A memory region contains both the current memory protection option &lt;em>and&lt;/em> the protection level when the region was created. If we try printing out the protection levels for both the memory region containing the value, and the memory region containing the pointer, this is what we get (the addresses differ from the ones previously because I restarted the tutorial):&lt;/p>&lt;pre>Region holding the value:
    BaseAddress: 0xb0000
    AllocationBase: 0xb0000
    AllocationProtect: 0x4
    RegionSize: 1007616
    State: 4096
    Protect: 4
    Type: 0x20000

Region holding the pointer:
    BaseAddress: 0x100304000
    AllocationBase: 0x100000000
    AllocationProtect: 0x80
    RegionSize: 28672
    State: 4096
    Protect: 4
    Type: 0x1000000
&lt;/pre>&lt;p>Interesting! According to the &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/winnt/ns-winnt-memory_basic_information">&lt;code>MEMORY_BASIC_INFORMATION&lt;/code> page&lt;/a>, the type for the first region is &lt;code>MEM_PRIVATE&lt;/code>, and the type for the second region is &lt;code>MEM_IMAGE&lt;/code> which:&lt;/p>&lt;blockquote>&lt;p>Indicates that the memory pages within the region are mapped into the view of an image section.&lt;/p>&lt;/blockquote>&lt;p>The protection also changes from &lt;code>PAGE_EXECUTE_WRITECOPY&lt;/code> to simply &lt;code>PAGE_READWRITE&lt;/code>, but I don't think it's relevant. Neither the type seems to be much more relevant. In &lt;a href="/blog/woce-2">part 2&lt;/a> we also mentioned the concept of "base address", but decided against using it, because starting to look for regions at address zero seemed to work fine. However, it would make sense that fixed "addresses" start at some known "base". Let's try getting the &lt;a href="https://stackoverflow.com/a/26573045/4759433">base address for all loaded modules&lt;/a>. Currently, we only get the address for the base module, in order to retrieve its name, but now we need them all:&lt;/p>&lt;pre>&lt;code class="language-rust">pub fn enum_modules(&amp;amp;self) -&amp;gt; io::Result&amp;lt;Vec&amp;lt;winapi::shared::minwindef::HMODULE&amp;gt;&amp;gt; {
    let mut size = 0;
    if unsafe {
        winapi::um::psapi::EnumProcessModules(
            self.handle.as_ptr(),
            ptr::null_mut(),
            0,
            &amp;amp;mut size,
        )
    } == FALSE
    {
        return Err(io::Error::last_os_error());
    }

    let mut modules = Vec::with_capacity(size as usize / mem::size_of::&amp;lt;HMODULE&amp;gt;());
    if unsafe {
        winapi::um::psapi::EnumProcessModules(
            self.handle.as_ptr(),
            modules.as_mut_ptr(),
            (modules.capacity() * mem::size_of::&amp;lt;HMODULE&amp;gt;()) as u32,
            &amp;amp;mut size,
        )
    } == FALSE
    {
        return Err(io::Error::last_os_error());
    }

    unsafe {
        modules.set_len(size as usize / mem::size_of::&amp;lt;HMODULE&amp;gt;());
    }

    Ok(modules)
}
&lt;/code>&lt;/pre>&lt;p>The first call is used to retrieve the correct &lt;code>size&lt;/code>, then we allocate just enough, and make the second call. The returned type are pretty much memory addresses, so let's see if we can find regions that contain them:&lt;/p>&lt;pre>&lt;code class="language-rust">let mut bases = 0;
let modules = process.enum_modules().unwrap();
let regions = process.memory_regions();
regions.iter().for_each(|region| {
    if modules.iter().any(|module| {
        let base = region.AllocationBase as usize;
        let addr = *module as usize;
        base &amp;lt;= addr &amp;amp;&amp;amp; addr &amp;lt; base + region.RegionSize
    }) {
        bases += 1;
    }
});

println!(
    "{}/{} regions have a module address within them",
    bases,
    regions.len()
);
&lt;/code>&lt;/pre>&lt;pre>41/353 regions have a module address within them
&lt;/pre>&lt;p>Exciting stuff! It appears &lt;code>base == addr&lt;/code> also does the trick&lt;a href="#fn:5">&lt;sup id="fnref:5">↪5&lt;/sup>&lt;/a>, so now we could build a &lt;code>bases: HashSet&amp;lt;usize&amp;gt;&lt;/code> and simply check if &lt;code>bases.contains(&amp;amp;region.AllocationBase as usize)&lt;/code> to determine whether &lt;code>region&lt;/code> is a base address or not&lt;a href="#fn:6">&lt;sup id="fnref:6">↪6&lt;/sup>&lt;/a>. So there we have it! The address holding the pointer value does fall within one of these "base regions". You can also get the name from one of these module addresses, and print it in the same way as Cheat Engine does it (such as &lt;code>Tutorial-x86_64.exe+306AD0&lt;/code>).&lt;/p>&lt;h2 id="finale">&lt;a href="#finale">Finale&lt;/a>&lt;/h2>&lt;p>So, there's no "automated" solution to all of this? That's the end? Well, yes, once you have a pointer you can dereference it once and then write to the given address to complete the tutorial step! I can understand how this would feel a bit underwhelming, but in all fairness, we were required to pretty-print assembly to guess what pointer address we could potentially need to look for. There is an &lt;a href="https://www.intel.com/content/www/us/en/architecture-and-technology/64-ia-32-architectures-software-developer-vol-2a-manual.html">stupidly large amount of instructions&lt;/a>, and I'm sure a lot of them can access memory, so automating that would be rough. We were lucky that the instructions right before the one that hit the breakpoint were changing the memory address, but you could imagine this value coming from somewhere completely different. It could also be using a myriad of different techniques to apply the offset. I would argue manual intervention is a must here&lt;a href="#fn:7">&lt;sup id="fnref:7">↪7&lt;/sup>&lt;/a>.&lt;/p>&lt;p>We have learnt how to pretty-print instructions, and had a very gentle introduction to figuring out what we may need to look for. The code to retrieve the loaded modules, and their corresponding regions, will come in handy later on. Having access to this information lets us know when to stop looking for additional pointers. As soon as a pointer is found within a memory region corresponding to a base module, we're done! Also, I know the title doesn't really much the contents of this entry (sorry about that), but I'm just following the convention of calling it whatever the Cheat Engine tutorial calls them.&lt;/p>&lt;p>The &lt;a href="https://github.com/lonami/memo">code for this post&lt;/a> is available over at my GitHub. You can run &lt;code>git checkout step6&lt;/code> after cloning the repository to get the right version of the code, although you will have to &lt;code>checkout&lt;/code> to individual commits if you want to review, for example, how the instructions were printed out. Only the code necessary to complete the step is included at the &lt;code>step6&lt;/code> tag.&lt;/p>&lt;p>In the &lt;a href="/blog/woce-7">next post&lt;/a>, we'll tackle the seventh step of the tutorial: Code Injection. This will be pretty similar to part 5, but instead of writing out a simple NOP instruction, we will have to get a bit more creative.&lt;/p>&lt;h3 id="footnotes">&lt;a href="#footnotes">Footnotes&lt;/a>&lt;/h3>&lt;p id="fn:1" class="footnote-definition">&lt;span>1&lt;/span> This will only be a gentle introduction to pointers. Part 8 of this series will have to rely on more advanced techniques.&amp;nbsp;&lt;a href="#fnref:1">↩&lt;/a>&lt;/p>&lt;p id="fn:2" class="footnote-definition">&lt;span>2&lt;/span> Kind of. The size of a pointer isn't necessarily the size as &lt;code>usize&lt;/code>, although &lt;code>usize&lt;/code> is guaranteed to be able of representing every possible address. For our purposes, we can assume a pointer is as big as &lt;code>usize&lt;/code>.&amp;nbsp;&lt;a href="#fnref:2">↩&lt;/a>&lt;/p>&lt;p id="fn:3" class="footnote-definition">&lt;span>3&lt;/span> Game updates are likely to pull more code and shuffle stuff around. This is unfortunately a difficult problem to solve. But storing a pointer which is usable across restarts for as long as the game doesn't update is still a pretty darn big improvement over having to constantly scan for the locations we care about. Although if you're smart enough to look for certain unique patterns, even if the code is changed, finding those patterns will give you the new updated address, so it's not &lt;em>impossible&lt;/em>.&amp;nbsp;&lt;a href="#fnref:3">↩&lt;/a>&lt;/p>&lt;p id="fn:4" class="footnote-definition">&lt;span>4&lt;/span>&lt;code>bool::then&lt;/code> is a pretty recent addition at the time of writing (1.50.0), so make sure you &lt;code>rustup update&lt;/code> if it's erroring out!&amp;nbsp;&lt;a href="#fnref:4">↩&lt;/a>&lt;/p>&lt;p id="fn:5" class="footnote-definition">&lt;span>5&lt;/span> I wasn't sure if there would be some metadata before the module base address but within the region, so I went with the range check. What &lt;em>is&lt;/em> important however is using &lt;code>AllocationBase&lt;/code>, not &lt;code>BaseAddress&lt;/code>. They're different, and this did bite me.&amp;nbsp;&lt;a href="#fnref:5">↩&lt;/a>&lt;/p>&lt;p id="fn:6" class="footnote-definition">&lt;span>6&lt;/span> As usual, I have no idea if this is how Cheat Engine is doing it, but it seems reasonable.&amp;nbsp;&lt;a href="#fnref:6">↩&lt;/a>&lt;/p>&lt;p id="fn:6" class="footnote-definition">&lt;span>6&lt;/span> But nothing's stopping you from implementing some heuristics to get the job done for you. If you run some algorithm in your head to find what the pointer value could be, you can program it in Rust as well, although I don't think it's worth the effort.&amp;nbsp;&lt;a href="#fnref:6">↩&lt;/a>&lt;/p></content></entry><entry xml:lang="en"><title>Writing our own Cheat Engine: Code finder</title><published>2021-03-06T00:00:00+00:00</published><updated>2021-03-06T00:00:00+00:00</updated><link href="https://lonami.dev/blog/woce-5/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/woce-5/</id><content type="html">&lt;p>This is part 5 on the &lt;em>Writing our own Cheat Engine&lt;/em> series:&lt;/p>&lt;ul>&lt;li>&lt;a href="/blog/woce-1">Part 1: Introduction&lt;/a> (start here if you're new to the series!)&lt;/li>&lt;li>&lt;a href="/blog/woce-2">Part 2: Exact Value scanning&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-3">Part 3: Unknown initial value&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-4">Part 4: Floating points&lt;/a>&lt;/li>&lt;li>Part 5: Code finder&lt;/li>&lt;li>&lt;a href="/blog/woce-6">Part 6: Pointers&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-7">Part 7: Code Injection&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-8">Part 8: Multilevel pointers&lt;/a>&lt;/li>&lt;/ul>&lt;p>In part 4 we spent a good deal of time trying to make our scans generic, and now we have something that works&lt;a href="#fn:1">&lt;sup id="fnref:1">↪1&lt;/sup>&lt;/a>! Now that the scanning is fairly powerful and all covered, the Cheat Engine tutorial shifts focus into slightly more advanced techniques that you will most certainly need in anything bigger than a toy program.&lt;/p>&lt;p>It's time to write our very own &lt;strong>debugger&lt;/strong> in Rust!&lt;/p>&lt;h2 id="code-finder">&lt;a href="#code-finder">Code finder&lt;/a>&lt;/h2>&lt;details open>&lt;summary>Cheat Engine Tutorial: Step 5&lt;/summary>&lt;blockquote>&lt;p>Sometimes the location something is stored at changes when you restart the game, or even while you're playing… In that case you can use 2 things to still make a table that works. In this step I'll try to describe how to use the Code Finder function.&lt;/p>&lt;p>The value down here will be at a different location each time you start the tutorial, so a normal entry in the address list wouldn't work. First try to find the address. (You've got to this point so I assume you know how to.)&lt;/p>&lt;p>When you've found the address, right-click the address in Cheat Engine and choose "Find out what writes to this address". A window will pop up with an empty list.&lt;/p>&lt;p>Then click on the Change value button in this tutorial, and go back to Cheat Engine. If everything went right there should be an address with assembler code there now.&lt;/p>&lt;p>Click it and choose the replace option to replace it with code that does nothing. That will also add the code address to the code list in the advanced options window. (Which gets saved if you save your table.)&lt;/p>&lt;p>Click on stop, so the game will start running normal again, and close to close the window. Now, click on Change value, and if everything went right the Next button should become enabled.&lt;/p>&lt;p>Note: When you're freezing the address with a high enough speed it may happen that next becomes visible anyhow&lt;/p>&lt;/blockquote>&lt;/details>&lt;h2 id="baby-steps-to-debugging">&lt;a href="#baby-steps-to-debugging">Baby steps to debugging&lt;/a>&lt;/h2>&lt;p>Although I have used debuggers before, I have never had a need to write one myself so it's time for some research.&lt;/p>&lt;p>Searching on DuckDuckGo, I can find entire series to &lt;a href="http://system.joekain.com/debugger/">Writing a Debugger&lt;/a>. We would be done by now if only that series wasn't written for Linux. The Windows documentation contains a section called &lt;a href="https://docs.microsoft.com/en-us/windows/win32/debug/creating-a-basic-debugger">Creating a Basic Debugger&lt;/a>, but as far as I can tell, it only teaches you the &lt;a href="https://docs.microsoft.com/en-us/windows/win32/debug/debugging-functions">functions&lt;/a> needed to configure the debugging loop. Which mind you, we will need, but in due time.&lt;/p>&lt;p>According to &lt;a href="https://www.gironsec.com/blog/2013/12/writing-your-own-debugger-windows-in-c/">Writing your own windows debugger in C&lt;/a>, the steps needed to write a debugger are:&lt;/p>&lt;ul>&lt;li>&lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-suspendthread">&lt;code>SuspendThread(proc)&lt;/code>&lt;/a>. It makes sense that we need to pause all the threads&lt;a href="#fn:2">&lt;sup id="fnref:2">↪2&lt;/sup>&lt;/a> before messing around with the code the program is executing, or things are very prone to go wrong.&lt;/li>&lt;li>&lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-getthreadcontext">&lt;code>GetThreadContext(proc)&lt;/code>&lt;/a>. This function retrieves the appropriate context of the specified thread and is highly processor specific. It basically takes a snapshot of all the registers. Think of registers like extremely fast, but also extremely limited, memory the processor uses.&lt;/li>&lt;li>&lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-debugbreakprocess">&lt;code>DebugBreakProcess&lt;/code>&lt;/a>. Essentially &lt;a href="https://docs.microsoft.com/en-us/windows-hardware/drivers/debugger/x86-instructions#miscellaneous">writes out the 0xCC opcode&lt;/a>, &lt;code>int 3&lt;/code> in assembly, also known as software breakpoint. It's written wherever the Register Instruction Pointer (RIP&lt;a href="#fn:3">&lt;sup id="fnref:3">↪3&lt;/sup>&lt;/a>) currently points to, so in essence, when the thread resumes, it will immediately &lt;a href="https://stackoverflow.com/q/3915511/">trigger the breakpoint&lt;/a>.&lt;/li>&lt;li>&lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/debugapi/nf-debugapi-continuedebugevent">&lt;code>ContinueDebugEvent&lt;/code>&lt;/a>. Presumably continues debugging.&lt;/li>&lt;/ul>&lt;p>There are pages documenting &lt;a href="https://docs.microsoft.com/en-us/windows/win32/debug/debugging-events">all of the debug events&lt;/a> that our debugger will be able to handle.&lt;/p>&lt;p>Okay, nice! Software breakpoints seem to be done by writing out memory to the region where the program is reading instructions from. We know how to write memory, as that's what all the previous posts have been doing to complete the corresponding tutorial steps. After the breakpoint is executed, all we need to do is &lt;a href="https://stackoverflow.com/q/3747852/">restore the original memory back&lt;/a> so that the next time the program executes the code it sees no difference.&lt;/p>&lt;p>But a software breakpoint will halt execution when the code executes the interrupt instruction. This step of the tutorial wants us to find &lt;em>what writes to a memory location&lt;/em>. Where should we place the breakpoint to detect such location? Writing out the instruction to the memory we want to break in won't do; it's not an instruction, it's just data.&lt;/p>&lt;p>The name may have given it away. If we're talking about software breakpoints, it makes sense that there would exist such a thing as &lt;a href="https://en.wikipedia.org/wiki/Breakpoint#Hardware">&lt;em>hardware&lt;/em> breakpoints&lt;/a>. Because they're tied to the hardware, they're highly processor-specific, but luckily for us, the processor on your usual desktop computer probably has them! Even the &lt;a href="https://interrupt.memfault.com/blog/cortex-m-breakpoints">cortex-m&lt;/a> does. The wikipedia page also tells us the name of the thing we're looking for, watchpoints:&lt;/p>&lt;blockquote>&lt;p>Other kinds of conditions can also be used, such as the reading, writing, or modification of a specific location in an area of memory. This is often referred to as a conditional breakpoint, a data breakpoint, or a watchpoint.&lt;/p>&lt;/blockquote>&lt;p>A breakpoint that triggers when a specific memory location is written to is exactly what we need, and &lt;a href="https://stackoverflow.com/a/19109153/">x86 has debug registers D0 to D3 to track memory addresses&lt;/a>. As far as I can tell, there is no API in specific to mess with the registers. But we don't need any of that! We can just go ahead and &lt;a href="https://doc.rust-lang.org/stable/unstable-book/library-features/asm.html">write some assembly by hand&lt;/a> to access these registers. At the time of writing, inline assembly is unstable, so we need a nightly compiler. Run &lt;code>rustup toolchain install nightly&lt;/code> if you haven't yet, and execute the following code with &lt;code>cargo +nightly run&lt;/code>:&lt;/p>&lt;pre>&lt;code class="language-rust">#![feature(asm)] // top of the file

fn main() {
    let x: u64 = 123;
    unsafe {
        asm!("mov dr7, {}", in(reg) x);
    }
}

&lt;/code>&lt;/pre>&lt;p>&lt;code>dr7&lt;/code> stands is the &lt;a href="https://en.wikipedia.org/wiki/X86_debug_register">debug control register&lt;/a>, and running this we get…&lt;/p>&lt;pre>&amp;gt;cargo +nightly run
   Compiling memo v0.1.0
    Finished dev [unoptimized + debuginfo] target(s) in 0.74s
     Running `target\debug\memo.exe`
error: process didn't exit successfully: `target\debug\memo.exe` (exit code: 0xc0000096, STATUS_PRIVILEGED_INSTRUCTION)
&lt;/pre>&lt;p>…an exception! In all fairness, I have no idea what that code would have done. So maybe the &lt;code>STATUS_PRIVILEGED_INSTRUCTION&lt;/code> is just trying to protect us. Can we read from the register instead, and see it's default value?&lt;/p>&lt;pre>&lt;code class="language-rust">let x: u64;
unsafe {
    asm!("mov {}, dr7", out(reg) x);
}
assert_eq!(x, 5);
&lt;/code>&lt;/pre>&lt;pre>&amp;gt;cargo +nightly run
...
error: process didn't exit successfully: `target\debug\memo.exe` (exit code: 0xc0000096, STATUS_PRIVILEGED_INSTRUCTION)
&lt;/pre>&lt;p>Nope. Okay, it seems directly reading from or writing to the debug register is a ring-0 thing. Surely there's a way around this. But first we should figure out how to enumerate and pause all the threads.&lt;/p>&lt;h2 id="pausing-all-the-threads">&lt;a href="#pausing-all-the-threads">Pausing all the threads&lt;/a>&lt;/h2>&lt;p>It seems there is no straightforward way to enumerate the threads. One has to &lt;a href="https://stackoverflow.com/a/1206915/">create a "toolhelp"&lt;/a> and poll the entries. I won't bore you with the details. Let's add &lt;code>tlhelp32&lt;/code> to the crate features of &lt;code>winapi&lt;/code> and try it out:&lt;/p>&lt;pre>&lt;code class="language-rust">
#[derive(Debug)]
pub struct Toolhelp {
    handle: winapi::um::winnt::HANDLE,
}

impl Drop for Toolhelp {
    fn drop(&amp;amp;mut self) {
        unsafe { winapi::um::handleapi::CloseHandle(self.handle) };
    }
}

pub fn enum_threads(pid: u32) -&amp;gt; io::Result&amp;lt;Vec&amp;lt;u32&amp;gt;&amp;gt; {
    const ENTRY_SIZE: u32 = mem::size_of::&amp;lt;winapi::um::tlhelp32::THREADENTRY32&amp;gt;() as u32;

    // size_of(dwSize + cntUsage + th32ThreadID + th32OwnerProcessID)
    const NEEDED_ENTRY_SIZE: u32 = 4 * mem::size_of::&amp;lt;DWORD&amp;gt;() as u32;

    // SAFETY: it is always safe to attempt to call this function.
    let handle = unsafe {
        winapi::um::tlhelp32::CreateToolhelp32Snapshot(winapi::um::tlhelp32::TH32CS_SNAPTHREAD, 0)
    };
    if handle == winapi::um::handleapi::INVALID_HANDLE_VALUE {
        return Err(io::Error::last_os_error());
    }
    let toolhelp = Toolhelp { handle };

    let mut result = Vec::new();
    let mut entry = winapi::um::tlhelp32::THREADENTRY32 {
        dwSize: ENTRY_SIZE,
        cntUsage: 0,
        th32ThreadID: 0,
        th32OwnerProcessID: 0,
        tpBasePri: 0,
        tpDeltaPri: 0,
        dwFlags: 0,
    };

    // SAFETY: we have a valid handle, and point to memory we own with the right size.
    if unsafe { winapi::um::tlhelp32::Thread32First(toolhelp.handle, &amp;amp;mut entry) } != FALSE {
        loop {
            if entry.dwSize &amp;gt;= NEEDED_ENTRY_SIZE &amp;amp;&amp;amp; entry.th32OwnerProcessID == pid {
                result.push(entry.th32ThreadID);
            }

            entry.dwSize = ENTRY_SIZE;
            // SAFETY: we have a valid handle, and point to memory we own with the right size.
            if unsafe { winapi::um::tlhelp32::Thread32Next(toolhelp.handle, &amp;amp;mut entry) } == FALSE {
                break;
            }
        }
    }

    Ok(result)
}
&lt;/code>&lt;/pre>&lt;p>Annoyingly, invalid handles returned by &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/tlhelp32/nf-tlhelp32-createtoolhelp32snapshot">&lt;code>CreateToolhelp32Snapshot&lt;/code>&lt;/a>, are &lt;code>INVALID_HANDLE_VALUE&lt;/code> (which is -1), not null. But that's not a big deal, we simply can't use &lt;code>NonNull&lt;/code> here. The function ignores the process identifier when using &lt;code>TH32CS_SNAPTHREAD&lt;/code>, used to include all threads, and we need to compare the process identifier ourselves.&lt;/p>&lt;p>In summary, we create a "toolhelp" (wrapped in a helper &lt;code>struct&lt;/code> so that whatever happens, &lt;code>Drop&lt;/code> will clean it up), initialize a thread enntry (with everything but the structure size to zero) and call &lt;code>Thread32First&lt;/code> the first time, &lt;code>Thread32Next&lt;/code> subsequent times. It seems to work all fine!&lt;/p>&lt;pre>&lt;code class="language-rust">dbg!(process::enum_threads(pid));
&lt;/code>&lt;/pre>&lt;pre>[src\main.rs:46] process::enum_threads(pid) = Ok(
    [
        10560,
    ],
)
&lt;/pre>&lt;p>According to this, the Cheat Engine tutorial is only using one thread. Good to know. Much like processes, threads need to be opened before we can use them, with &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-openthread">&lt;code>OpenThread&lt;/code>&lt;/a>:&lt;/p>&lt;pre>&lt;code class="language-rust">pub struct Thread {
    tid: u32,
    handle: NonNull&amp;lt;c_void&amp;gt;,
}

impl Thread {
    pub fn open(tid: u32) -&amp;gt; io::Result&amp;lt;Self&amp;gt; {
        // SAFETY: the call doesn't have dangerous side-effects
        NonNull::new(unsafe {
            winapi::um::processthreadsapi::OpenThread(
                winapi::um::winnt::THREAD_SUSPEND_RESUME,
                FALSE,
                tid,
            )
        })
        .map(|handle| Self { tid, handle })
        .ok_or_else(io::Error::last_os_error)
    }

    pub fn tid(&amp;amp;self) -&amp;gt; u32 {
        self.tid
    }
}

impl Drop for Thread {
    fn drop(&amp;amp;mut self) {
        unsafe { winapi::um::handleapi::CloseHandle(self.handle.as_mut()) };
    }
}
&lt;/code>&lt;/pre>&lt;p>Just your usual RAII pattern. The thread is opened with permission to suspend and resume it. Let's try to pause the handles with &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-suspendthread">&lt;code>SuspendThread&lt;/code>&lt;/a> to make sure that this thread is actually the one we're looking for:&lt;/p>&lt;pre>&lt;code class="language-rust">pub fn suspend(&amp;amp;mut self) -&amp;gt; io::Result&amp;lt;usize&amp;gt; {
    // SAFETY: the handle is valid.
    let ret = unsafe {
        winapi::um::processthreadsapi::SuspendThread(self.handle.as_ptr())
    };
    if ret == -1i32 as u32 {
        Err(io::Error::last_os_error())
    } else {
        Ok(ret as usize)
    }
}

pub fn resume(&amp;amp;mut self) -&amp;gt; io::Result&amp;lt;usize&amp;gt; {
    // SAFETY: the handle is valid.
    let ret = unsafe {
        winapi::um::processthreadsapi::ResumeThread(self.handle.as_ptr())
    };
    if ret == -1i32 as u32 {
        Err(io::Error::last_os_error())
    } else {
        Ok(ret as usize)
    }
}
&lt;/code>&lt;/pre>&lt;p>Both suspend and resume return the previous "suspend count". It's kind of like a barrier or semaphore where the thread only runs if the suspend count is zero. Trying it out:&lt;/p>&lt;pre>&lt;code class="language-rust">let mut threads = thread::enum_threads(pid)
    .unwrap()
    .into_iter()
    .map(Thread::open)
    .collect::&amp;lt;Result&amp;lt;Vec&amp;lt;_&amp;gt;, _&amp;gt;&amp;gt;()
    .unwrap();

threads
    .iter_mut()
    .for_each(|thread| {
        println!("Pausing thread {} for 10 seconds…", thread.tid());
        thread.suspend().unwrap();

        std::thread::sleep(std::time::Duration::from_secs(10));

        println!("Wake up, {}!", thread.tid());
        thread.resume().unwrap();
    });
&lt;/code>&lt;/pre>&lt;p>If you run this code with the process ID of the Cheat Engine tutorial, you will see that the tutorial window freezes for ten seconds! Because the main and only thread is paused, it cannot process any window events, so it becomes unresponsive. It is now "safe" to mess around with the thread context.&lt;/p>&lt;h2 id="setting-hardware-breakpoints">&lt;a href="#setting-hardware-breakpoints">Setting hardware breakpoints&lt;/a>&lt;/h2>&lt;p>I'm definitely not the first person to wonder &lt;a href="https://social.msdn.microsoft.com/Forums/en-US/0cb3360d-3747-42a7-bc0e-668c5d9ee1ee/how-to-set-a-hardware-breakpoint">How to set a hardware breakpoint?&lt;/a>. This is great, because it means I don't need to ask that question myself. It appears we need to change the debug register &lt;em>via the thread context&lt;/em>.&lt;/p>&lt;p>One has to be careful to use the right context structure. Confusingly enough, &lt;a href="https://stackoverflow.com/q/17504174/">&lt;code>WOW64_CONTEXT&lt;/code>&lt;/a> is 32 bits, not 64. &lt;code>CONTEXT&lt;/code> alone seems to be the right one:&lt;/p>&lt;pre>&lt;code class="language-rust">pub fn get_context(&amp;amp;self) -&amp;gt; io::Result&amp;lt;winapi::um::winnt::CONTEXT&amp;gt; {
    let context = MaybeUninit::&amp;lt;winapi::um::winnt::CONTEXT&amp;gt;::zeroed();
    // SAFETY: it's a C struct, and all-zero is a valid bit-pattern for the type.
    let mut context = unsafe { context.assume_init() };
    context.ContextFlags = winapi::um::winnt::CONTEXT_ALL;

    // SAFETY: the handle is valid and structure points to valid memory.
    if unsafe {
        winapi::um::processthreadsapi::GetThreadContext(self.handle.as_ptr(), &amp;amp;mut context)
    } == FALSE
    {
        Err(io::Error::last_os_error())
    } else {
        Ok(context)
    }
}
&lt;/code>&lt;/pre>&lt;p>Trying it out:&lt;/p>&lt;pre>&lt;code class="language-rust">thread.suspend().unwrap();

let context = thread.get_context().unwrap();
println!("Dr0: {:016x}", context.Dr0);
println!("Dr7: {:016x}", context.Dr7);
println!("Dr6: {:016x}", context.Dr6);
println!("Rax: {:016x}", context.Rax);
println!("Rbx: {:016x}", context.Rbx);
println!("Rcx: {:016x}", context.Rcx);
println!("Rip: {:016x}", context.Rip);
&lt;/code>&lt;/pre>&lt;pre>Dr0: 0000000000000000
Dr7: 0000000000000000
Dr6: 0000000000000000
Rax: 0000000000001446
Rbx: 0000000000000000
Rcx: 0000000000000000
Rip: 00007ffda4259904
&lt;/pre>&lt;p>Looks about right! Hm, I wonder what happens if I use Cheat Engine to add the watchpoint on the memory location we care about?&lt;/p>&lt;pre>Dr0: 000000000157e650
Dr7: 00000000000d0001
&lt;/pre>&lt;p>Look at that! The debug registers changed! DR0 contains the location we want to watch for writes, and the debug control register DR7 changed. Cheat Engine sets the same values on all threads (for some reason I now see more than one thread printed for the tutorial, not sure what's up with that; maybe the single-thread is the weird one out).&lt;/p>&lt;p>Hmm, what happens if I watch for access instead of write?&lt;/p>&lt;pre>Dr0: 000000000157e650
Dr7: 00000000000f0001
&lt;/pre>&lt;p>What if I set both?&lt;/p>&lt;pre>Dr0: 000000000157e650
Dr7: 0000000000fd0005
&lt;/pre>&lt;p>Most intriguing! This was done by telling Cheat Engine to find "what writes" to the address, then "what accesses" the address. I wonder if the order matters?&lt;/p>&lt;pre>Dr0: 000000000157e650
Dr7: 0000000000df0005
&lt;/pre>&lt;p>"What accesses" and then "what writes" does change it. Very well! We're only concerned in a single breakpoint, so we won't worry about this, but it's good to know that we can inspect what Cheat Engine is doing. It's also interesting to see how Cheat Engine is using hardware breakpoints and not software breakpoints.&lt;/p>&lt;p>For simplicity, our code is going to assume that we're the only ones messing around with the debug registers, and that there will only be a single debug register in use. Make sure to add &lt;code>THREAD_SET_CONTEXT&lt;/code> to the permissions when opening the thread handle:&lt;/p>&lt;pre>&lt;code class="language-rust">pub fn set_context(&amp;amp;self, context: &amp;amp;winapi::um::winnt::CONTEXT) -&amp;gt; io::Result&amp;lt;()&amp;gt; {
    // SAFETY: the handle is valid and structure points to valid memory.
    if unsafe {
        winapi::um::processthreadsapi::SetThreadContext(self.handle.as_ptr(), context)
    } == FALSE
    {
        Err(io::Error::last_os_error())
    } else {
        Ok(())
    }
}

pub fn watch_memory_write(&amp;amp;self, addr: usize) -&amp;gt; io::Result&amp;lt;()&amp;gt; {
    let mut context = self.get_context()?;
    context.Dr0 = addr as u64;
    context.Dr7 = 0x00000000000d0001;
    self.set_context(&amp;amp;context)?;
    todo!()
}
&lt;/code>&lt;/pre>&lt;p>If we do this (and temporarily get rid of the &lt;code>todo!()&lt;/code>), trying to change the value in the Cheat Engine tutorial will greet us with a warm message:&lt;/p>&lt;blockquote>&lt;p>&lt;strong>Tutorial-x86_64&lt;/strong>&lt;/p>&lt;p>External exception 80000004.&lt;/p>&lt;p>Press OK to ignore and risk data corruption.&lt;br>Press Abort to kill the program.&lt;/p>&lt;p>&lt;kbd>OK&lt;/kbd> &lt;kbd>Abort&lt;/kbd>&lt;/p>&lt;/blockquote>&lt;p>There is no debugger attached yet that could possibly handle this exception, so the exception just propagates. Let's fix that.&lt;/p>&lt;h2 id="handling-debug-events">&lt;a href="#handling-debug-events">Handling debug events&lt;/a>&lt;/h2>&lt;p>Now that we've succeeded on setting breakpoints, we can actually follow the steps described in &lt;a href="https://docs.microsoft.com/en-us/windows/win32/debug/creating-a-basic-debugger">Creating a Basic Debugger&lt;/a>. It starts by saying that we should use &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/debugapi/nf-debugapi-debugactiveprocess">&lt;code>DebugActiveProcess&lt;/code>&lt;/a> to attach our processor, the debugger, to the process we want to debug, the debuggee. This function lives under the &lt;code>debugapi&lt;/code> header, so add it to &lt;code>winapi&lt;/code> features:&lt;/p>&lt;pre>&lt;code class="language-rust">pub struct DebugToken {
    pid: u32,
}

pub fn debug(pid: u32) -&amp;gt; io::Result&amp;lt;DebugToken&amp;gt; {
    if unsafe { winapi::um::debugapi::DebugActiveProcess(pid) } == FALSE {
        return Err(io::Error::last_os_error());
    };
    let token = DebugToken { pid };
    if unsafe { winapi::um::winbase::DebugSetProcessKillOnExit(FALSE) } == FALSE {
        return Err(io::Error::last_os_error());
    };
    Ok(token)
}

impl Drop for DebugToken {
    fn drop(&amp;amp;mut self) {
        unsafe { winapi::um::debugapi::DebugActiveProcessStop(self.pid) };
    }
}
&lt;/code>&lt;/pre>&lt;p>Once again, we create a wrapper &lt;code>struct&lt;/code> with &lt;code>Drop&lt;/code> to stop debugging the process once the token is dropped. The call to &lt;code>DebugSetProcessKillOnExit&lt;/code> in our &lt;code>debug&lt;/code> method ensures that, if our process (the debugger) dies, the process we're debugging (the debuggee) stays alive. We don't want to be restarting the entire Cheat Engine tutorial every time our Rust code crashes!&lt;/p>&lt;p>With the debugger attached, we can wait for debug events. We will put this method inside of &lt;code>impl DebugToken&lt;/code>, so that the only way you can call it is if you successfully attached to another process:&lt;/p>&lt;pre>&lt;code class="language-rust">impl DebugToken {
    pub fn wait_event(
        &amp;amp;self,
        timeout: Option&amp;lt;Duration&amp;gt;,
    ) -&amp;gt; io::Result&amp;lt;winapi::um::minwinbase::DEBUG_EVENT&amp;gt; {
        let mut result = MaybeUninit::uninit();
        let timeout = timeout
            .map(|d| d.as_millis().try_into().ok())
            .flatten()
            .unwrap_or(winapi::um::winbase::INFINITE);

        // SAFETY: can only wait for events with a token, so the debugger is active.
        if unsafe { winapi::um::debugapi::WaitForDebugEvent(result.as_mut_ptr(), timeout) } == FALSE
        {
            Err(io::Error::last_os_error())
        } else {
            // SAFETY: the call returned non-zero, so the structure is initialized.
            Ok(unsafe { result.assume_init() })
        }
    }
}
&lt;/code>&lt;/pre>&lt;p>&lt;code>WaitForDebugEvent&lt;/code> wants a timeout in milliseconds, so our function lets the user pass the more Rusty &lt;code>Duration&lt;/code> type. &lt;code>None&lt;/code> will indicate "there is no timeout", i.e., it's infinite. If the duration is too large to fit in the &lt;code>u32&lt;/code> (&lt;code>try_into&lt;/code> fails), it will also be infinite.&lt;/p>&lt;p>If we attach the debugger, set the hardware watchpoint, and modify the memory location from the tutorial, an event with &lt;code>dwDebugEventCode = 3&lt;/code> will be returned! Now, back to the page with the &lt;a href="https://docs.microsoft.com/en-us/windows/win32/debug/debugging-events">Debugging Events&lt;/a>… Gah! It only has the name of the constants, not the values. Well, good thing &lt;a href="https://docs.rs/">docs.rs&lt;/a> has a source view! We can just check the values in the &lt;a href="https://docs.rs/winapi/0.3.9/src/winapi/um/minwinbase.rs.html#203-211">source code for &lt;code>winapi&lt;/code>&lt;/a>:&lt;/p>&lt;pre>&lt;code class="language-rust">pub const EXCEPTION_DEBUG_EVENT: DWORD = 1;
pub const CREATE_THREAD_DEBUG_EVENT: DWORD = 2;
pub const CREATE_PROCESS_DEBUG_EVENT: DWORD = 3;
pub const EXIT_THREAD_DEBUG_EVENT: DWORD = 4;
pub const EXIT_PROCESS_DEBUG_EVENT: DWORD = 5;
pub const LOAD_DLL_DEBUG_EVENT: DWORD = 6;
pub const UNLOAD_DLL_DEBUG_EVENT: DWORD = 7;
pub const OUTPUT_DEBUG_STRING_EVENT: DWORD = 8;
pub const RIP_EVENT: DWORD = 9;
&lt;/code>&lt;/pre>&lt;p>So, we've got a &lt;code>CREATE_PROCESS_DEBUG_EVENT&lt;/code>:&lt;/p>&lt;blockquote>&lt;p>Generated whenever a new process is created in a process being debugged or whenever the debugger begins debugging an already active process. The system generates this debugging event before the process begins to execute in user mode and before the system generates any other debugging events for the new process.&lt;/p>&lt;/blockquote>&lt;p>It makes sense that this is our first event. By the way, if you were trying this out with a &lt;code>sleep&lt;/code> lying around in your code, you may have noticed that the window froze until the debugger terminated. That's because:&lt;/p>&lt;blockquote>&lt;p>When the system notifies the debugger of a debugging event, it also suspends all threads in the affected process. The threads do not resume execution until the debugger continues the debugging event by using &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/debugapi/nf-debugapi-continuedebugevent">&lt;code>ContinueDebugEvent&lt;/code>&lt;/a>.&lt;/p>&lt;/blockquote>&lt;p>Let's call &lt;code>ContinueDebugMethod&lt;/code> but also wait on more than one event and see what happens:&lt;/p>&lt;pre>&lt;code class="language-rust">for _ in 0..10 {
    let event = debugger.wait_event(None).unwrap();
    println!("Got {}", event.dwDebugEventCode);
    debugger.cont(event, true).unwrap();
}
&lt;/code>&lt;/pre>&lt;pre>Got 3
Got 6
Got 6
Got 6
Got 6
Got 6
Got 6
Got 6
Got 6
Got 6
&lt;/pre>&lt;p>That's a lot of &lt;code>LOAD_DLL_DEBUG_EVENT&lt;/code>. Pumping it up to one hundred and also showing the index we get the following:&lt;/p>&lt;pre>0. Got 3
1. Got 6
...
40. Got 6
41. Got 2
42. Got 1
43. Got 4
&lt;/pre>&lt;p>In order, we got:&lt;/p>&lt;ul>&lt;li>One &lt;code>CREATE_PROCESS_DEBUG_EVENT&lt;/code>.&lt;/li>&lt;li>Forty &lt;code>LOAD_DLL_DEBUG_EVENT&lt;/code>.&lt;/li>&lt;li>One &lt;code>CREATE_THREAD_DEBUG_EVENT&lt;/code>.&lt;/li>&lt;li>One &lt;code>EXCEPTION_DEBUG_EVENT&lt;/code>.&lt;/li>&lt;li>One &lt;code>EXIT_THREAD_DEBUG_EVENT&lt;/code>.&lt;/li>&lt;/ul>&lt;p>And, if after all this, you change the value in the Cheat Engine tutorial (thus triggering our watch point), we get &lt;code>EXCEPTION_DEBUG_EVENT&lt;/code>!&lt;/p>&lt;blockquote>&lt;p>Generated whenever an exception occurs in the process being debugged. Possible exceptions include attempting to access inaccessible memory, executing breakpoint instructions, attempting to divide by zero, or any other exception noted in Structured Exception Handling.&lt;/p>&lt;/blockquote>&lt;p>If we print out all the fields in the &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/minwinbase/ns-minwinbase-exception_debug_info">&lt;code>EXCEPTION_DEBUG_INFO&lt;/code>&lt;/a> structure:&lt;/p>&lt;pre>Watching writes to 10e3a0 for 10s
First chance: 1
ExceptionCode: 2147483652
ExceptionFlags: 0
ExceptionRecord: 0x0
ExceptionAddress: 0x10002c5ba
NumberParameters: 0
ExceptionInformation: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
&lt;/pre>&lt;p>The &lt;code>ExceptionCode&lt;/code>, which is &lt;code>0x80000004&lt;/code>, corresponds with &lt;code>EXCEPTION_SINGLE_STEP&lt;/code>:&lt;/p>&lt;blockquote>&lt;p>A trace trap or other single-instruction mechanism signaled that one instruction has been executed.&lt;/p>&lt;/blockquote>&lt;p>The &lt;code>ExceptionAddress&lt;/code> is supposed to be "the address where the exception occurred". Very well! I have already completed this step of the tutorial, and I know the instruction is &lt;code>mov [rax],edx&lt;/code> (or, as Cheat Engine shows, the bytes &lt;code>89 10&lt;/code> in hexadecimal). The opcode for the &lt;code>nop&lt;/code> instruction is &lt;code>90&lt;/code> in hexadecimal, so if we replace two bytes at this address, we should be able to complete the tutorial.&lt;/p>&lt;p>Note that we also need to flush the instruction cache, as noted in the Windows documentation:&lt;/p>&lt;blockquote>&lt;p>Debuggers frequently read the memory of the process being debugged and write the memory that contains instructions to the instruction cache. After the instructions are written, the debugger calls the &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-flushinstructioncache">&lt;code>FlushInstructionCache&lt;/code>&lt;/a> function to execute the cached instructions.&lt;/p>&lt;/blockquote>&lt;p>So we add a new method to &lt;code>impl Process&lt;/code>:&lt;/p>&lt;pre>&lt;code class="language-rust">/// Flushes the instruction cache.
///
/// Should be called when writing to memory regions that contain code.
pub fn flush_instruction_cache(&amp;amp;self) -&amp;gt; io::Result&amp;lt;()&amp;gt; {
    // SAFETY: the call doesn't have dangerous side-effects.
    if unsafe {
        winapi::um::processthreadsapi::FlushInstructionCache(
            self.handle.as_ptr(),
            ptr::null(),
            0,
        )
    } == FALSE
    {
        Err(io::Error::last_os_error())
    } else {
        Ok(())
    }
}
&lt;/code>&lt;/pre>&lt;p>And write some quick and dirty code to get this done:&lt;/p>&lt;pre>&lt;code class="language-rust">let addr = ...;
println!("Watching writes to {:x} for 10s", addr);
threads.iter_mut().for_each(|thread| {
    thread.watch_memory_write(addr).unwrap();
});
loop {
    let event = debugger.wait_event(None).unwrap();
    if event.dwDebugEventCode == 1 {
        let exc = unsafe { event.u.Exception() };
        if exc.ExceptionRecord.ExceptionCode == 2147483652 {
            let addr = exc.ExceptionRecord.ExceptionAddress as usize;
            match process.write_memory(addr, &amp;amp;[0x90, 0x90]) {
                Ok(_) =&amp;gt; eprintln!("Patched [{:x}] with NOP", addr),
                Err(e) =&amp;gt; eprintln!("Failed to patch [{:x}] with NOP: {}", addr, e),
            };
            process.flush_instruction_cache().unwrap();
            debugger.cont(event, true).unwrap();
            break;
        }
    }
    debugger.cont(event, true).unwrap();
}
&lt;/code>&lt;/pre>&lt;p>Although it seems to work:&lt;/p>&lt;pre>Watching writes to 15103f0 for 10s
Patched [10002c5ba] with NOP
&lt;/pre>&lt;p>It really doesn't:&lt;/p>&lt;blockquote>&lt;p>&lt;strong>Tutorial-x86_64&lt;/strong>&lt;/p>&lt;p>Access violation.&lt;/p>&lt;p>Press OK to ignore and risk data corruption.&lt;br>Press Abort to kill the program.&lt;/p>&lt;p>&lt;kbd>OK&lt;/kbd> &lt;kbd>Abort&lt;/kbd>&lt;/p>&lt;/blockquote>&lt;p>Did we write memory somewhere we shouldn't? The documentation does mention "segment-relative" and "linear virtual addresses":&lt;/p>&lt;blockquote>&lt;p>&lt;code>GetThreadSelectorEntry&lt;/code> returns the descriptor table entry for a specified selector and thread. Debuggers use the descriptor table entry to convert a segment-relative address to a linear virtual address. The &lt;code>ReadProcessMemory&lt;/code> and &lt;code>WriteProcessMemory&lt;/code> functions require linear virtual addresses.&lt;/p>&lt;/blockquote>&lt;p>But nope! This isn't the problem. The problem is that the &lt;code>ExceptionRecord.ExceptionAddress&lt;/code> is &lt;em>after&lt;/em> the execution happened, so it's already 2 bytes beyond where it should be. We were accidentally writing out the first half of the next instruction, which, yeah, could not end good.&lt;/p>&lt;p>So does it work if I do this instead?:&lt;/p>&lt;pre>&lt;code class="language-rust">process.write_memory(addr - 2, &amp;amp;[0x90, 0x90])
//                        ^^^ new
&lt;/code>&lt;/pre>&lt;p>This totally does work. Step 5: complete 🎉&lt;/p>&lt;h2 id="properly-patching-instructions">&lt;a href="#properly-patching-instructions">Properly patching instructions&lt;/a>&lt;/h2>&lt;p>You may not be satisfied at all with our solution. Not only are we hardcoding some magic constants to set hardware watchpoints, we're also relying on knowledge specific to the Cheat Engine tutorial (insofar that we're replacing two bytes worth of instruction with NOPs).&lt;/p>&lt;p>Properly supporting more than one hardware breakpoint, along with supporting different types of breakpoints, is definitely doable. The meaning of the bits for the debug registers is well defined, and you can definitely study that to come up with &lt;a href="https://github.com/mmorearty/hardware-breakpoints">something more sophisticated&lt;/a> and support multiple different breakpoints. But for now, that's out of the scope of this series. The tutorial only wants us to use an on-write watchpoint, and our solution is fine and portable for that use case.&lt;/p>&lt;p>However, relying on the size of the instructions is pretty bad. The instructions x86 executes are of variable length, so we can't possibly just look back until we find the previous instruction, or even naively determine its length. A lot of unrelated sequences of bytes are very likely instructions themselves. We need a disassembler. No, we're not writing our own&lt;a href="#fn:4">&lt;sup id="fnref:4">↪4&lt;/sup>&lt;/a>.&lt;/p>&lt;p>Searching on &lt;a href="https://crates.io">crates.io&lt;/a> for "disassembler" yields a few results, and the first one I've found is &lt;a href="https://crates.io/crates/iced-x86">iced-x86&lt;/a>. I like the name, it has a decent amount of GitHub stars, and it was last updated less than a month ago. I don't know about you, but I think we've just hit a jackpot!&lt;/p>&lt;p>It's quite heavy though, so I will add it behind a feature gate, and users that want it may opt into it:&lt;/p>&lt;pre>&lt;code class="language-toml">[features]
patch-nops = ["iced-x86"]

[dependencies]
iced-x86 = { version = "1.10.3", optional = true }
&lt;/code>&lt;/pre>&lt;p>You can make use of it with &lt;code>cargo run --features=patch-nops&lt;/code>. I don't want to turn this blog post into a tutorial for &lt;code>iced-x86&lt;/code>, but in essence, we need to make use of its &lt;code>Decoder&lt;/code>. Here's the plan:&lt;/p>&lt;ol>&lt;li>Find the memory region corresponding to the address we want to patch.&lt;/li>&lt;li>Read the entire region.&lt;/li>&lt;li>Decode the read bytes until the instruction pointer reaches our address.&lt;/li>&lt;li>Because we just parsed the previous instruction, we know its length, and can be replaced with NOPs.&lt;/li>&lt;/ol>&lt;pre>&lt;code class="language-rust">#[cfg(feature = "patch-nops")]
pub fn nop_last_instruction(&amp;amp;self, addr: usize) -&amp;gt; io::Result&amp;lt;()&amp;gt; {
    use iced_x86::{Decoder, DecoderOptions, Formatter, Instruction, NasmFormatter};

    let region = self
        .memory_regions()
        .into_iter()
        .find(|region| {
            let base = region.BaseAddress as usize;
            base &amp;lt;= addr &amp;amp;&amp;amp; addr &amp;lt; base + region.RegionSize
        })
        .ok_or_else(|| io::Error::new(io::ErrorKind::Other, "no matching region found"))?;

    let bytes = self.read_memory(region.BaseAddress as usize, region.RegionSize)?;

    let mut decoder = Decoder::new(64, &amp;amp;bytes, DecoderOptions::NONE);
    decoder.set_ip(region.BaseAddress as _);

    let mut instruction = Instruction::default();
    while decoder.can_decode() {
        decoder.decode_out(&amp;amp;mut instruction);
        if instruction.next_ip() as usize == addr {
            return self
                .write_memory(instruction.ip() as usize, &amp;amp;vec![0x90; instruction.len()])
                .map(drop);
        }
    }

    Err(io::Error::new(
        io::ErrorKind::Other,
        "no matching instruction found",
    ))
}
&lt;/code>&lt;/pre>&lt;p>Pretty straightforward! We can set the "instruction pointer" of the decoder so that it matches with the address we're reading from. The &lt;code>next_ip&lt;/code> method comes in really handy. Overall, it's a bit inefficient, because we could reuse the regions retrieved previously, but other than that, there is not much room for improvement.&lt;/p>&lt;p>With this, we are no longer hardcoding the instruction size or guessing which instruction is doing what. You may wonder, what if the region does not start with valid executable code? It could be possible that the instructions are in some memory region with garbage except for a very specific location with real code. I don't know how Cheat Engine handles this, but I think it's reasonable to assume that the region starts with valid code.&lt;/p>&lt;p>As far as I can tell (after having asked a bit around), the encoding is usually self synchronizing (similar to UTF-8), so eventually we should end up with correct instructions. But someone can still intentionally write real code between garbage data which we would then disassemble incorrectly. This is a problem on all variable-length ISAs. Half a solution is to &lt;a href="https://stackoverflow.com/q/3983735/">start at the entry point&lt;/a>, decode all instructions, and follow the jumps. The other half would be correctly identifying jumps created just to trip a disassembler up, and jumps pointing to dynamically-calculated addresses!&lt;/p>&lt;h2 id="finale">&lt;a href="#finale">Finale&lt;/a>&lt;/h2>&lt;p>That was quite a deep dive! We have learnt about the existence of the various breakpoint types (software, hardware, and even behaviour, such as watchpoints), how to debug a separate process, and how to correctly update the code other process is running on-the-fly. The &lt;a href="https://github.com/lonami/memo">code for this post&lt;/a> is available over at my GitHub. You can run &lt;code>git checkout step5&lt;/code> after cloning the repository to get the right version of the code.&lt;/p>&lt;p>Although we've only talked about &lt;em>setting&lt;/em> breakpoints, there are of course &lt;a href="https://reverseengineering.stackexchange.com/a/16547">ways of detecting them&lt;/a>. There's &lt;a href="https://www.codeproject.com/Articles/30815/An-Anti-Reverse-Engineering-Guide">entire guides about it&lt;/a>. Again, we currently hardcode the fact we want to add a single watchpoint using the first debug register. A proper solution here would be to actually calculate the needs that need to be set, as well as keeping track of how many breakpoints have been added so far.&lt;/p>&lt;p>Hardware breakpoints are also limited, since they're simply a bunch of registers, and our machine does not have infinite registers. How are other debuggers like &lt;code>gdb&lt;/code> able to create a seemingly unlimited amount of breakpoints? Well, the GDB wiki actually has a page on &lt;a href="https://sourceware.org/gdb/wiki/Internals%20Watchpoints">Internals Watchpoints&lt;/a>, and it's really interesting! &lt;code>gdb&lt;/code> essentially single-steps through the entire program and tests the expressions after every instruction:&lt;/p>&lt;blockquote>&lt;p>Software watchpoints are very slow, since GDB needs to single-step the program being debugged and test the value of the watched expression(s) after each instruction.&lt;/p>&lt;/blockquote>&lt;p>However, that's not the only way. One could &lt;a href="https://stackoverflow.com/a/7805842/">change the protection level&lt;/a> of the region of interest (for example, remove the write permission), and when the program tries to write there, it will fail! In any case, the GDB wiki is actually a pretty nice resource. It also has a section on &lt;a href="https://sourceware.org/gdb/wiki/Internals/Breakpoint%20Handling">Breakpoint Handling&lt;/a>, which contains some additional insight.&lt;/p>&lt;p>With regards to code improvements, &lt;code>DebugToken::wait_event&lt;/code> could definitely be both nicer and safer to use, with a custom &lt;code>enum&lt;/code>, so the user does not need to rely on magic constants or having to resort to &lt;code>unsafe&lt;/code> access to get the right &lt;code>union&lt;/code> variant.&lt;/p>&lt;p>In the &lt;a href="/blog/woce-6">next post&lt;/a>, we'll tackle the sixth step of the tutorial: Pointers. It reuses the debugging techniques presented here to backtrack where the pointer for our desired value is coming from, so here we will need to actually &lt;em>understand&lt;/em> what the instructions are doing, not just patching them out!&lt;/p>&lt;h3 id="footnotes">&lt;a href="#footnotes">Footnotes&lt;/a>&lt;/h3>&lt;p id="fn:1" class="footnote-definition">&lt;span>1&lt;/span> I'm not super happy about the design of it all, but we won't actually need anything beyond scanning for integers for the rest of the steps so it doesn't really matter.&amp;nbsp;&lt;a href="#fnref:1">↩&lt;/a>&lt;/p>&lt;p id="fn:2" class="footnote-definition">&lt;span>2&lt;/span> There seems to be a way to pause the entire process in one go, with the &lt;a href="https://stackoverflow.com/a/4062698/">undocumented &lt;code>NtSuspendProcess&lt;/code>&lt;/a> function!&amp;nbsp;&lt;a href="#fnref:2">↩&lt;/a>&lt;/p>&lt;p id="fn:3" class="footnote-definition">&lt;span>3&lt;/span> It really is called that. The naming went from "IP" (instruction pointer, 16 bits), to "EIP" (extended instruction pointer, 32 bits) and currently "RIP" (64 bits). The naming convention for upgraded registers is the same (RAX, RBX, RCX, and so on). The &lt;a href="https://wiki.osdev.org/CPU_Registers_x86_64">OS Dev wiki&lt;/a> is a great resource for this kind of stuff.&amp;nbsp;&lt;a href="#fnref:3">↩&lt;/a>&lt;/p>&lt;p id="fn:4" class="footnote-definition">&lt;span>4&lt;/span> Well, we don't need an entire disassembler. Knowing the length of each instruction is enough, but that on its own is also a lot of work.&amp;nbsp;&lt;a href="#fnref:4">↩&lt;/a>&lt;/p></content></entry><entry xml:lang="en"><title>Writing our own Cheat Engine: Floating points</title><published>2021-02-28T00:00:00+00:00</published><updated>2021-02-28T00:00:00+00:00</updated><link href="https://lonami.dev/blog/woce-4/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/woce-4/</id><content type="html">&lt;p>This is part 4 on the &lt;em>Writing our own Cheat Engine&lt;/em> series:&lt;/p>&lt;ul>&lt;li>&lt;a href="/blog/woce-1">Part 1: Introduction&lt;/a> (start here if you're new to the series!)&lt;/li>&lt;li>&lt;a href="/blog/woce-2">Part 2: Exact Value scanning&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-3">Part 3: Unknown initial value&lt;/a>&lt;/li>&lt;li>Part 4: Floating points&lt;/li>&lt;li>&lt;a href="/blog/woce-5">Part 5: Code finder&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-6">Part 6: Pointers&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-7">Part 7: Code Injection&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-8">Part 8: Multilevel pointers&lt;/a>&lt;/li>&lt;/ul>&lt;p>In part 3 we did a fair amount of plumbing in order to support scan modes beyond the trivial "exact value scan". As a result, we have abstracted away the &lt;code>Scan&lt;/code>, &lt;code>CandidateLocations&lt;/code> and &lt;code>Value&lt;/code> types as a separate &lt;code>enum&lt;/code> each. Scanning for changed memory regions in an opened process can now be achieved with three lines of code:&lt;/p>&lt;pre>&lt;code class="language-rust">let regions = process.memory_regions();
let first_scan = process.scan_regions(&amp;amp;regions, Scan::InRange(0, 500));
let second_scan = process.rescan_regions(&amp;amp;first_scan, Scan::DecreasedBy(7));
&lt;/code>&lt;/pre>&lt;p>How's that for programmability? No need to fire up Cheat Engine's GUI anymore!&lt;/p>&lt;p>The &lt;code>first_scan&lt;/code> in the example above remembers all the found &lt;code>Value&lt;/code> within the range specified by &lt;code>Scan&lt;/code>. Up until now, we have only worked with &lt;code>i32&lt;/code>, so that's the type the scans expect and what they work with.&lt;/p>&lt;p>Now it's time to introduce support for different types, like &lt;code>f32&lt;/code>, &lt;code>i64&lt;/code>, or even more atypical ones, like arbitrary sequences of bytes (think of strings) or even numbers in big-endian.&lt;/p>&lt;p>Tighten your belt, because this post is quite the ride. Let's get right into it!&lt;/p>&lt;h2 id="floating-points">&lt;a href="#floating-points">Floating points&lt;/a>&lt;/h2>&lt;details open>&lt;summary>Cheat Engine Tutorial: Step 4&lt;/summary>&lt;blockquote>&lt;p>In the previous tutorial we used bytes to scan, but some games store information in so called 'floating point' notations. (probably to prevent simple memory scanners from finding it the easy way). A floating point is a value with some digits behind the point. (like 5.12 or 11321.1)&lt;/p>&lt;p>Below you see your health and ammo. Both are stored as Floating point notations, but health is stored as a float and ammo is stored as a double. Click on hit me to lose some health, and on shoot to decrease your ammo with 0.5&lt;/p>&lt;p>You have to set BOTH values to 5000 or higher to proceed.&lt;/p>&lt;p>Exact value scan will work fine here, but you may want to experiment with other types too.&lt;/p>&lt;p>Hint: It is recommended to disable "Fast Scan" for type double&lt;/p>&lt;/blockquote>&lt;/details>&lt;h2 id="generic-values">&lt;a href="#generic-values">Generic values&lt;/a>&lt;/h2>&lt;p>The &lt;code>Value&lt;/code> enumeration holds scanned values, and is currently hardcoded to store &lt;code>i32&lt;/code>. The &lt;code>Scan&lt;/code> type also holds a value, the value we want to scan for. Changing it to support other types is trivial:&lt;/p>&lt;pre>&lt;code class="language-rust">pub enum Scan&amp;lt;T&amp;gt; {
    Exact(T),
    Unknown,
    Decreased,
    // ...other variants...
}

pub enum Value&amp;lt;T&amp;gt; {
    Exact(T),
    AnyWithin(Vec&amp;lt;u8&amp;gt;),
}
&lt;/code>&lt;/pre>&lt;p>&lt;code>AnyWithin&lt;/code> is the raw memory, and &lt;code>T&lt;/code> can be interpreted from any sequence of bytes thanks to our friend &lt;a href="https://doc.rust-lang.org/stable/std/mem/fn.transmute.html">&lt;code>mem::transmute&lt;/code>&lt;/a>. This change alone is enough to store an arbitrary &lt;code>T&lt;/code>! So we're done now? Not really, no.&lt;/p>&lt;p>First of all, we need to update all the places where &lt;code>Scan&lt;/code> or &lt;code>Value&lt;/code> are used. Our first stop is the scanned &lt;code>Region&lt;/code>, which holds the found &lt;code>Value&lt;/code>:&lt;/p>&lt;pre>&lt;code class="language-rust">pub struct Region&amp;lt;T&amp;gt; {
    pub info: MEMORY_BASIC_INFORMATION,
    pub locations: CandidateLocations,
    pub value: Value&amp;lt;T&amp;gt;,
}
&lt;/code>&lt;/pre>&lt;p>Then, we need to update everywhere &lt;code>Region&lt;/code> is used, and on and on… All in all this process is just repeating &lt;code>cargo check&lt;/code>, letting the compiler vent on you, and taking good care of it by fixing the errors. It's quite reassuring to know you will not miss a single place. Thank you, compiler!&lt;/p>&lt;p>But wait, how could scanning for a decreased value work for any &lt;code>T&lt;/code>? The type is not &lt;code>Ord&lt;/code>, we should add some trait bounds. And also, what happens if the type is not &lt;code>Copy&lt;/code>? It could implement &lt;code>Drop&lt;/code>&lt;a href="#fn:1">&lt;sup id="fnref:1">↪1&lt;/sup>&lt;/a>, and we will be transmuting from raw bytes, which would trigger the &lt;code>Drop&lt;/code> implementation when we're done with the value! Not memory safe at all! And how could we possibly cast raw memory to the type without knowing its siz– oh nevermind, &lt;a href="https://doc.rust-lang.org/stable/std/marker/trait.Sized.html">&lt;code>T&lt;/code> is already &lt;code>Sized&lt;/code> by default&lt;/a>. But anyway, we need the other bounds.&lt;/p>&lt;p>In order to not repeat ourselves, we will implement a new &lt;code>trait&lt;/code>, let's say &lt;code>Scannable&lt;/code>, which requires all other bounds:&lt;/p>&lt;pre>&lt;code class="language-rust">pub trait Scannable: Copy + PartialEq + PartialOrd {}

impl&amp;lt;T: Copy + PartialEq + PartialOrd&amp;gt; Scannable for T {}
&lt;/code>&lt;/pre>&lt;p>And fix our definitions:&lt;/p>&lt;pre>&lt;code class="language-rust">pub enum Scan&amp;lt;T: Scannable&amp;gt; { ... }
pub enum Value&amp;lt;T: Scannable&amp;gt; { ... }
pub struct Region&amp;lt;T: Scannable&amp;gt; { ... }

// ...and the many other places referring to T
&lt;/code>&lt;/pre>&lt;p>Every type which is &lt;code>Copy&lt;/code>, &lt;code>PartialEq&lt;/code> and &lt;code>PartialOrd&lt;/code> can be scanned over&lt;a href="#fn:2">&lt;sup id="fnref:2">↪2&lt;/sup>&lt;/a>, because we &lt;code>impl Scan for T&lt;/code> where the bounds are met. Unfortunately, we cannot require &lt;code>Eq&lt;/code> or &lt;code>Ord&lt;/code> because the floating point types do not implement it.&lt;/p>&lt;h2 id="transmuting-memory">&lt;a href="#transmuting-memory">Transmuting memory&lt;/a>&lt;/h2>&lt;p>Also known as reinterpreting a bunch of bytes as something else, or perhaps it stands for "summoning the demon":&lt;/p>&lt;blockquote>&lt;p>&lt;code>transmute&lt;/code> is &lt;strong>incredibly&lt;/strong> unsafe. There are a vast number of ways to cause &lt;a href="https://doc.rust-lang.org/stable/reference/behavior-considered-undefined.html">undefined behavior&lt;/a> with this function. &lt;code>transmute&lt;/code> should be the absolute last resort.&lt;/p>&lt;/blockquote>&lt;p>Types like &lt;code>i32&lt;/code> define methods such as &lt;a href="https://doc.rust-lang.org/stable/std/primitive.i32.html#method.from_ne_bytes">&lt;code>from_ne_bytes&lt;/code>&lt;/a> and &lt;a href="https://doc.rust-lang.org/stable/std/primitive.i32.html#method.to_ne_bytes">&lt;code>to_ne_bytes&lt;/code>&lt;/a> which convert raw bytes from and into its native representation. This is all really nice, but unfortunately, there's no standard trait in the Rust's standard library to "interpret a type &lt;code>T&lt;/code> as the byte sequence of its native representation". &lt;code>transmute&lt;/code>, however, does exist, and similar to any other &lt;code>unsafe&lt;/code> function, it's safe to call &lt;strong>as long as we respect its invariants&lt;/strong>. What are these invariants&lt;a href="#fn:3">&lt;sup id="fnref:3">↪3&lt;/sup>&lt;/a>?&lt;/p>&lt;blockquote>&lt;p>Both types must have the same size&lt;/p>&lt;/blockquote>&lt;p>Okay, we can just assert that the window length matches the type's length. What else?&lt;/p>&lt;blockquote>&lt;p>Neither the original, nor the result, may be an &lt;a href="https://doc.rust-lang.org/nomicon/what-unsafe-does.html">invalid value&lt;/a>.&lt;/p>&lt;/blockquote>&lt;p>What's an invalid value?&lt;/p>&lt;blockquote>&lt;ul>&lt;li>a &lt;code>bool&lt;/code> that isn't 0 or 1&lt;/li>&lt;li>an &lt;code>enum&lt;/code> with an invalid discriminant&lt;/li>&lt;li>a null &lt;code>fn&lt;/code> pointer&lt;/li>&lt;li>a &lt;code>char&lt;/code> outside the ranges [0x0, 0xD7FF] and [0xE000, 0x10FFFF]&lt;/li>&lt;li>a &lt;code>!&lt;/code> (all values are invalid for this type)&lt;/li>&lt;li>an integer (&lt;code>i*&lt;/code>/&lt;code>u*&lt;/code>), floating point value (&lt;code>f*&lt;/code>), or raw pointer read from uninitialized memory, or uninitialized memory in a &lt;code>str&lt;/code>.&lt;/li>&lt;li>a reference/&lt;code>Box&lt;/code> that is dangling, unaligned, or points to an invalid value.&lt;/li>&lt;li>a wide reference, &lt;code>Box&lt;/code>, or raw pointer that has invalid metadata:&lt;ul>&lt;li>&lt;code>dyn Trait&lt;/code> metadata is invalid if it is not a pointer to a vtable for &lt;code>Trait&lt;/code> that matches the actual dynamic trait the pointer or reference points to&lt;/li>&lt;li>slice metadata is invalid if the length is not a valid &lt;code>usize&lt;/code> (i.e., it must not be read from uninitialized memory)&lt;/li>&lt;/ul>&lt;/li>&lt;li>a type with custom invalid values that is one of those values, such as a &lt;code>NonNull&lt;/code> that is null. (Requesting custom invalid values is an unstable feature, but some stable libstd types, like &lt;code>NonNull&lt;/code>, make use of it.)&lt;/li>&lt;/ul>&lt;/blockquote>&lt;p>Okay, that's actually an awful lot. Types like &lt;code>bool&lt;/code> implement all the trait bounds we defined, and it would be insta-UB to ever try to cast them from arbitrary bytes. The same goes for &lt;code>char&lt;/code>, and all &lt;code>enum&lt;/code> are out of our control, too. At least we're safe on the "memory is initialized" front.&lt;/p>&lt;p>Dang it, I really wanted to use &lt;code>transmute&lt;/code>! But if we were to use it for arbitrary types, it would trigger undefined behaviour sooner than later.&lt;/p>&lt;p>We have several options here:&lt;/p>&lt;ul>&lt;li>Make it an &lt;code>unsafe trait&lt;/code>. Implementors will be responsible for ensuring that the type they're implementing it for can be safely transmuted from and into.&lt;/li>&lt;li>&lt;a href="https://rust-lang.github.io/api-guidelines/future-proofing.html">Seal the &lt;code>trait&lt;/code>&lt;/a> and implement it only for types we know are safe&lt;a href="#fn:4">&lt;sup id="fnref:4">↪4&lt;/sup>&lt;/a>, like &lt;code>i32&lt;/code>.&lt;/li>&lt;li>Add methods to the &lt;code>trait&lt;/code> definition that do the conversion of the type into its native representation.&lt;/li>&lt;/ul>&lt;p>We will go with the first option&lt;a href="#fn:5">&lt;sup id="fnref:5">↪5&lt;/sup>&lt;/a>, because I really want to use &lt;code>transmute&lt;/code>, and I want users to be able to implement the trait on their own types.&lt;/p>&lt;p>In any case, we need to change our &lt;code>impl&lt;/code> to something more specific, in order to prevent it from automatically implementing the trait for types for which their memory representation has invalid values. So we get rid of this:&lt;/p>&lt;pre>&lt;code class="language-rust">pub trait Scannable: Copy + PartialEq + PartialOrd {}

impl&amp;lt;T: Copy + PartialEq + PartialOrd&amp;gt; Scannable for T {}
&lt;/code>&lt;/pre>&lt;p>And replace it with this:&lt;/p>&lt;pre>&lt;code class="language-rust">pub unsafe trait Scannable: Copy + PartialEq + PartialOrd {}

macro_rules! impl_many {
    ( unsafe impl $trait:tt for $( $ty:ty ),* ) =&amp;gt; {
        $( unsafe impl $trait for $ty {} )*
    };
}

// SAFETY: all these types respect `Scannable` invariants.
impl_many!(unsafe impl Scannable for i8, u8, i16, u16, i32, u32, i64, u64, f32, f64);
&lt;/code>&lt;/pre>&lt;p>Making a small macro for things like these is super useful. You could of course write &lt;code>unsafe impl Scannable for T&lt;/code> for all ten &lt;code>T&lt;/code> as well, but that introduces even more &lt;code>unsafe&lt;/code> to read. Last but not least, let's replace the hardcoded &lt;code>i32::from_ne_bytes&lt;/code> and &lt;code>i32::to_ne_bytes&lt;/code> with &lt;code>mem::transmute&lt;/code>.&lt;/p>&lt;p>All the &lt;code>windows(4)&lt;/code> need to be replaced with &lt;code>windows(mem::size_of::&amp;lt;T&amp;gt;())&lt;/code> because the size may no longer be &lt;code>4&lt;/code>. All the &lt;code>i32::from_ne_bytes(...)&lt;/code> need to be replaced with &lt;code>mem::transmute::&amp;lt;_, T&amp;gt;(...)&lt;/code>. We explicitly write out &lt;code>T&lt;/code> to make sure the compiler doesn't accidentally infer something we didn't intend.&lt;/p>&lt;p>And… it doesn't work at all. We're working with byte slices of arbitrary length. We cannot transmute a &lt;code>&amp;amp;[]&lt;/code> type, which is 16 bytes (8 for the pointer and 8 for the length), to our &lt;code>T&lt;/code>. My plan to use transmute can't possibly work here. Sigh.&lt;/p>&lt;h2 id="not-quite-transmuting-memory">&lt;a href="#not-quite-transmuting-memory">Not quite transmuting memory&lt;/a>&lt;/h2>&lt;p>Okay, we can't transmute, because we don't have a sized value, we only have a slice of bytes pointing somewhere else. What we &lt;em>could&lt;/em> do is reinterpret the pointer to those bytes as a different type, and then dereference it! This is still a form of "transmutation", just without using &lt;code>transmute&lt;/code>.&lt;/p>&lt;pre>&lt;code class="language-rust">let value = unsafe { *(window.as_ptr() as *const T) };
&lt;/code>&lt;/pre>&lt;p>Woop! You can compile this and test it out on the step 2 and 3 of the tutorial, using &lt;code>i32&lt;/code>, and it will still work! Something troubles me, though. Can you see what it is?&lt;/p>&lt;p>When we talked about invalid values, it had a note about unaligned references:&lt;/p>&lt;blockquote>&lt;p>a reference/&lt;code>Box&lt;/code> that is dangling, unaligned, or points to an invalid value.&lt;/p>&lt;/blockquote>&lt;p>Our &lt;code>window&lt;/code> is essentially a reference to &lt;code>T&lt;/code>. The only difference is we're working at the pointer level, but they're pretty much references. Let's see what the documentation for &lt;a href="https://doc.rust-lang.org/std/primitive.pointer.html">&lt;code>pointer&lt;/code>&lt;/a> has to say as well, since we're dereferencing pointers:&lt;/p>&lt;blockquote>&lt;p>when a raw pointer is dereferenced (using the &lt;code>*&lt;/code> operator), it must be non-null and aligned.&lt;/p>&lt;/blockquote>&lt;p>It must be aligned. The only reason why our data is aligned is because we are also performing a "fast scan", so we only look at aligned locations. This is a time bomb waiting to blow up. Is there any other way to &lt;a href="https://doc.rust-lang.org/std/ptr/fn.read.html">&lt;code>read&lt;/code>&lt;/a> from a pointer which is safer?&lt;/p>&lt;blockquote>&lt;p>&lt;code>src&lt;/code> must be properly aligned. Use &lt;a href="https://doc.rust-lang.org/std/ptr/fn.read_unaligned.html">&lt;code>read_unaligned&lt;/code>&lt;/a> if this is not the case.&lt;/p>&lt;/blockquote>&lt;p>Bingo! Both &lt;code>read&lt;/code> and &lt;code>read_unaligned&lt;/code>, unlike dereferencing the pointer, will perform a copy, but if it can make the code less prone to blowing up, I'll take it&lt;a href="#fn:6">&lt;sup id="fnref:6">↪6&lt;/sup>&lt;/a>. Let's change the code one more time:&lt;/p>&lt;pre>&lt;code class="language-rust">let current = unsafe { window.as_ptr().cast::&amp;lt;T&amp;gt;().read_unaligned() };
&lt;/code>&lt;/pre>&lt;p>I prefer to avoid type annotations in variables where possible, which is why I use the &lt;a href="https://www.reddit.com/r/rust/comments/3fimgp/why_double_colon_rather_that_dot/ctozkd0/">turbofish&lt;/a> so often. You can get rid of the cast and use a type annotation instead, but make sure the type is known, otherwise it will think it's &lt;code>u8&lt;/code> because &lt;code>window&lt;/code> is a &lt;code>&amp;amp;[u8]&lt;/code>.&lt;/p>&lt;p>Now, this is all cool and good. You can replace &lt;code>i32&lt;/code> with &lt;code>f32&lt;/code> for &lt;code>T&lt;/code> and you'll be able to get halfway done with the step 4 of Cheat Engine's tutorial. Unfortunately, as it is, this code is not enough to complete step 4 with exact scans&lt;a href="#fn:7">&lt;sup id="fnref:7">↪7&lt;/sup>&lt;/a>. You see, comparing floating point values is not as simple as checking for bitwise equality. We were actually really lucky that the &lt;code>f32&lt;/code> part works! But the values in the &lt;code>f64&lt;/code> part are not as precise as our inputs, so our exact scan fails.&lt;/p>&lt;p>Using a fixed type parameter is pretty limiting as well. On the one hand, it is nice that, if you scan for &lt;code>i32&lt;/code>, the compiler statically guarantees that subsequent scans will also happen on &lt;code>i32&lt;/code> and thus be compatible. On the other, this requires us to know the type at compile time, which for an interactive program, is not possible. While we &lt;em>could&lt;/em> create different methods for each supported type and, at runtime, decide to which we should jump, I am not satisfied with that solution. It also means we can't switch from scanning an &lt;code>u32&lt;/code> to an &lt;code>i32&lt;/code>, for whatever reason.&lt;/p>&lt;p>So we need to work around this once more.&lt;/p>&lt;h2 id="rethinking-the-scans">&lt;a href="#rethinking-the-scans">Rethinking the scans&lt;/a>&lt;/h2>&lt;p>What does our scanning function need, really? It needs a way to compare two chunks of memory as being equal or not (as we have seen, this isn't trivial with types such as floating point numbers) and, for other types of scans, it needs to be able to produce an ordering, or calculate a difference.&lt;/p>&lt;p>Instead of having a our trait require the bounds &lt;code>PartialEq&lt;/code> and &lt;code>PartialOrd&lt;/code>, we can define our own methods to compare &lt;code>Self&lt;/code> with &lt;code>&amp;amp;[u8]&lt;/code>. It still should be &lt;code>Clone&lt;/code>, so we can pass it around without worrying about lifetimes:&lt;/p>&lt;pre>&lt;code class="language-rust">// Callers must `assert_eq!(memory.len(), mem::size_of::&amp;lt;Self&amp;gt;())`.
unsafe fn eq(&amp;amp;self, memory: &amp;amp;[u8]) -&amp;gt; bool;
unsafe fn cmp(&amp;amp;self, memory: &amp;amp;[u8]) -&amp;gt; Ordering;
&lt;/code>&lt;/pre>&lt;p>This can be trivially implemented for all integer types:&lt;/p>&lt;pre>&lt;code class="language-rust">macro_rules! impl_scannable_for_int {
    ( $( $ty:ty ),* ) =&amp;gt; {
        $(
            // SAFETY: caller is responsible to `assert_eq!(memory.len(), mem::size_of::&amp;lt;T&amp;gt;())`
            impl Scannable for $ty {
                unsafe fn eq(&amp;amp;self, memory: &amp;amp;[u8]) -&amp;gt; bool {
                    let other = unsafe { memory.as_ptr().cast::&amp;lt;$ty&amp;gt;().read_unaligned() };
                    *self == other
                }

                unsafe fn cmp(&amp;amp;self, memory: &amp;amp;[u8]) -&amp;gt; Ordering {
                    let other = unsafe { memory.as_ptr().cast::&amp;lt;$ty&amp;gt;().read_unaligned() };
                    &amp;lt;$ty as Ord&amp;gt;::cmp(self, &amp;amp;other)
                }
            }
        )*
    };
}

impl_scannable_for_int!(i8, u8, i16, u16, i32, u32, i64, u64);
&lt;/code>&lt;/pre>&lt;p>The funny &lt;code>&amp;lt;$ty as Ord&amp;gt;&lt;/code> is because I decided to call the method &lt;code>Scannable::cmp&lt;/code>, so I have to disambiguate between it and &lt;code>Ord::cmp&lt;/code>. We can go ahead and update the code using &lt;code>Scannable&lt;/code> to use these new functions instead.&lt;/p>&lt;p>Now, you may have noticed I only implemented it for the integer types. That's because floats need some extra care. Unfortunately, floating point types do not have any form of "precision" embedded in them, so we can't accurately say "compare these floats to the precision level the user specified". What we can do, however, is drop a few bits from the mantissa, so "relatively close" quantities are considered equal. It's definitely not as good as comparing floats to the user's precision, but it will get the job done.&lt;/p>&lt;p>I'm going to arbitrarily say that we are okay comparing with "half" the precision. We can achieve that by masking half of the bits from the mantissa to zero:&lt;/p>&lt;pre>&lt;code class="language-rust">
macro_rules! impl_scannable_for_float {
    ( $( $ty:ty : $int_ty:ty ),* ) =&amp;gt; {
        $(
            #[allow(unused_unsafe)] // mind you, it is necessary
            impl Scannable for $ty {
                unsafe fn eq(&amp;amp;self, memory: &amp;amp;[u8]) -&amp;gt; bool {
                    const MASK: $int_ty = !((1 &amp;lt;&amp;lt; (&amp;lt;$ty&amp;gt;::MANTISSA_DIGITS / 2)) - 1);

                    // SAFETY: caller is responsible to `assert_eq!(memory.len(), mem::size_of::&amp;lt;T&amp;gt;())`
                    let other = unsafe { memory.as_ptr().cast::&amp;lt;$ty&amp;gt;().read_unaligned() };
                    let left = &amp;lt;$ty&amp;gt;::from_bits(self.to_bits() &amp;amp; MASK);
                    let right = &amp;lt;$ty&amp;gt;::from_bits(other.to_bits() &amp;amp; MASK);
                    left == right
                }

                ...
            }
        )*
    };
}

impl_scannable_for_float!(f32: u32, f64: u64);
&lt;/code>&lt;/pre>&lt;p>You may be wondering what's up with that weird &lt;code>MASK&lt;/code>. Let's visualize it with a &lt;a href="https://en.wikipedia.org/wiki/Bfloat16_floating-point_format">&lt;code>f16&lt;/code>&lt;/a>. This type has 16 bits, 1 for sign, 5 for exponent, and 10 for the mantissa:&lt;/p>&lt;pre>S EEEEE MMMMMMMMMM
&lt;/pre>&lt;p>If we substitute the constant with the numeric value and operate:&lt;/p>&lt;pre>&lt;code class="language-rust">!((1 &amp;lt;&amp;lt; (10 / 2)) - 1)
!((1 &amp;lt;&amp;lt; 5) - 1)
!(0b00000000_00100000 - 1)
!(0b00000000_00011111)
0b11111111_11100000
&lt;/code>&lt;/pre>&lt;p>So effectively, half of the mantisssa bit will be masked to 0. For the &lt;code>f16&lt;/code> example, this makes us lose 5 bits of precision. Comparing two floating point values with their last five bits truncated is equivalent to checking if they are "roughly equal"!&lt;/p>&lt;p>When Cheat Engine scans for floating point values, several additional settings show, and one such option is "truncated". I do not know if it behaves like this, but it might.&lt;/p>&lt;p>Let's try this out:&lt;/p>&lt;pre>&lt;code class="language-rust">#[test]
fn f32_roughly_eq() {
    let left = 0.25f32;
    let right = 0.25000123f32;
    let memory = unsafe { mem::transmute::&amp;lt;_, [u8; 4]&amp;gt;(right) };
    assert_ne!(left, right);
    assert!(unsafe { Scannable::eq(&amp;amp;left, &amp;amp;memory) });
}
&lt;/code>&lt;/pre>&lt;pre>&amp;gt;cargo test f32_roughly_eq

running 1 test
test scan::candidate_location_tests::f32_roughly_eq ... ok
&lt;/pre>&lt;p>Huzzah! The &lt;code>assert_ne!&lt;/code> makes sure that a normal comparision would fail, and then we &lt;code>assert!&lt;/code> that our custom one passes the test. When the user performs an exact scan, the code will be more tolerant to the user's less precise inputs, which overall should result in a nicer experience.&lt;/p>&lt;h2 id="dynamically-sized-scans">&lt;a href="#dynamically-sized-scans">Dynamically sized scans&lt;/a>&lt;/h2>&lt;p>The second problem we need to solve is the possibility of the size not being known at compile time&lt;a href="#fn:8">&lt;sup id="fnref:8">↪8&lt;/sup>&lt;/a>. While we can go as far as scanning over strings of a known length, this is rather limiting, because we need to know the length at compile time&lt;a href="#fn:9">&lt;sup id="fnref:9">↪9&lt;/sup>&lt;/a>. Heap allocated objects are another problem, because we don't want to compare the memory representation of the stack object, but likely the memory where they point to (such as &lt;code>String&lt;/code>).&lt;/p>&lt;p>Instead of using &lt;code>mem::size_of&lt;/code>, we can add a new method to our &lt;code>Scannable&lt;/code>, &lt;code>size&lt;/code>, which will tell us the size required of the memory view we're comparing against:&lt;/p>&lt;pre>&lt;code class="language-rust">unsafe impl Scannable {
    ...

    fn size(&amp;amp;self) -&amp;gt; usize;
}
&lt;/code>&lt;/pre>&lt;p>It is &lt;code>unsafe&lt;/code> to implement, because we are relying on the returned value to be truthful and unchanging. It should be safe to call, because it cannot have any invariants. Unfortunately, signaling "unsafe to implement" is done by marking the entire trait as &lt;code>unsafe&lt;/code>, since "unsafe to call" is reserved for &lt;code>unsafe fn&lt;/code>, and even though the rest of methods are not necessarily unsafe to implement, they're treated as such.&lt;/p>&lt;p>At the moment, &lt;code>Scannable&lt;/code> cannot be made into a trait object because it is &lt;a href="https://doc.rust-lang.org/stable/error-index.html#E0038">not object safe&lt;/a>. This is caused by the &lt;code>Clone&lt;/code> requirement on all &lt;code>Scannable&lt;/code> object, which in turn needs the types to be &lt;code>Sized&lt;/code> because &lt;code>clone&lt;/code> returns &lt;code>Self&lt;/code>. Because of this, the size must be known.&lt;/p>&lt;p>However, we &lt;em>can&lt;/em> move the &lt;code>Clone&lt;/code> requirement to the methods that need it! This way, &lt;code>Scannable&lt;/code> can remain object safe, enabling us to do the following:&lt;/p>&lt;pre>&lt;code class="language-rust">unsafe impl&amp;lt;T: AsRef&amp;lt;dyn Scannable&amp;gt; + AsMut&amp;lt;dyn Scannable&amp;gt;&amp;gt; Scannable for T {
    unsafe fn eq(&amp;amp;self, memory: &amp;amp;[u8]) -&amp;gt; bool {
        self.as_ref().eq(memory)
    }

    unsafe fn cmp(&amp;amp;self, memory: &amp;amp;[u8]) -&amp;gt; Ordering {
        self.as_ref().cmp(memory)
    }

    fn mem_view(&amp;amp;self) -&amp;gt; &amp;amp;[u8] {
        self.as_ref().mem_view()
    }

    fn size(&amp;amp;self) -&amp;gt; usize {
        self.as_ref().size()
    }
}
&lt;/code>&lt;/pre>&lt;p>Any type which can be interpreted as a reference to &lt;code>Scannable&lt;/code> is also a scannable! This enables us to perform scans over &lt;code>Box&amp;lt;dyn i32&amp;gt;&lt;/code>, where the type is known at runtime! Or rather, it would, if &lt;code>Box&amp;lt;dyn T&amp;gt;&lt;/code> implemented &lt;code>Clone&lt;/code>, which it can't&lt;a href="#fn:10">&lt;sup id="fnref:10">↪10&lt;/sup>&lt;/a> because that's what prompted this entire issue. Dang it! I can't catch a breath today!&lt;/p>&lt;p>Okay, let's step back. Why did we need our scannables to be clone in the first place? When we perform exact scans, we store the original value in the region, which we don't own, so we clone it. But what if we &lt;em>did&lt;/em> own the value? Instead of taking the &lt;code>Scan&lt;/code> by reference, which holds &lt;code>T: Scannable&lt;/code>, we could take it by value. If we get rid of all the &lt;code>Clone&lt;/code> bounds and update &lt;code>Scan::run&lt;/code> to take &lt;code>self&lt;/code>, along with updating all the things that take a &lt;code>Region&lt;/code> to take them by value as well, it should all work out.&lt;/p>&lt;p>But it does not. If we take &lt;code>Scan&lt;/code> by value, with it not being &lt;code>Clone&lt;/code>, we simply can't use it to scan over multiple regions. After the first region, we have lost the &lt;code>Scan&lt;/code>.&lt;/p>&lt;p>Let's take a second step back. We are scanning memory, and we want to compare memory, but we want to treat the memory with different semantics (for example, if we treat it as &lt;code>f32&lt;/code>, we want to check for rough equality). Instead of storing the &lt;em>value&lt;/em> itself, we could store its &lt;em>memory representation&lt;/em>, and when we compare memory representations, we can do so under certain semantics.&lt;/p>&lt;p>First off, let's revert getting rid of all &lt;code>Clone&lt;/code>. Wherever we stored a &lt;code>T&lt;/code>, we will now store a &lt;code>Vec&amp;lt;u8&amp;gt;&lt;/code>. We will still use a type parameter to represent the "implementations of &lt;code>Scannable&lt;/code>". For this to work, our definitions need to use &lt;code>T&lt;/code> somewhere, or else the compiler refuses to compile the code with error &lt;a href="https://doc.rust-lang.org/stable/error-index.html#E0392">E0392&lt;/a>. For this, I will stick a &lt;a href="https://doc.rust-lang.org/stable/std/marker/struct.PhantomData.html">&lt;code>PhantomData&lt;/code>&lt;/a> in the &lt;code>Exact&lt;/code> variant. It's a bit pointless to include it in all variants, and &lt;code>Exact&lt;/code> seems the most appropriated:&lt;/p>&lt;pre>&lt;code class="language-rust">pub enum Scan&amp;lt;T: Scannable&amp;gt; {
    Exact(Vec&amp;lt;u8&amp;gt;, PhantomData&amp;lt;T&amp;gt;),
    Unknown,
    ...
}
&lt;/code>&lt;/pre>&lt;p>This keeps in line with &lt;code>Value&lt;/code>:&lt;/p>&lt;pre>&lt;code class="language-rust">pub enum Value&amp;lt;T: Scannable&amp;gt; {
    Exact(Vec&amp;lt;u8&amp;gt;, PhantomData&amp;lt;T&amp;gt;),
    ...
}
&lt;/code>&lt;/pre>&lt;p>Our &lt;code>Scannable&lt;/code> will no longer work on &lt;code>T&lt;/code> and &lt;code>&amp;amp;[u8]&lt;/code>. Instead, it will work on two &lt;code>&amp;amp;[u8]&lt;/code>. We will also need a way to interpret a &lt;code>T&lt;/code> as &lt;code>&amp;amp;[u8]&lt;/code>, which we can achieve with a new method, &lt;code>mem_view&lt;/code>. This method interprets the raw memory representation of &lt;code>self&lt;/code> as its raw bytes. It also lets us get rid of &lt;code>size&lt;/code>, because we can simply do &lt;code>mem_view().len()&lt;/code>. It's still &lt;code>unsafe&lt;/code> to implement, because it should return the same length every time:&lt;/p>&lt;pre>&lt;code class="language-rust">pub unsafe trait Scannable {
    // Callers must `assert_eq!(left.len(), right.len(), self.mem_view().len())`.
    unsafe fn eq(left: &amp;amp;[u8], right: &amp;amp;[u8]) -&amp;gt; bool;
    unsafe fn cmp(left: &amp;amp;[u8], right: &amp;amp;[u8]) -&amp;gt; Ordering;
    fn mem_view(&amp;amp;self) -&amp;gt; &amp;amp;[u8];
}
&lt;/code>&lt;/pre>&lt;p>But now we can't use it in trait object, so the following no longer works:&lt;/p>&lt;pre>&lt;code class="language-rust">unsafe impl&amp;lt;T: AsRef&amp;lt;dyn Scannable&amp;gt; + AsMut&amp;lt;dyn Scannable&amp;gt;&amp;gt; Scannable for T {
    ...
}
&lt;/code>&lt;/pre>&lt;p>Ugh! Well, to be fair, we no longer have a "scannable" at this point. It's more like a scan mode that tells us how memory should be compared according to a certain type. Let's split the trait into two: one for the scan mode, and other for "things which are scannable":&lt;/p>&lt;pre>&lt;code class="language-rust">pub trait ScanMode {
    unsafe fn eq(left: &amp;amp;[u8], right: &amp;amp;[u8]) -&amp;gt; bool;
    unsafe fn cmp(left: &amp;amp;[u8], right: &amp;amp;[u8]) -&amp;gt; Ordering;
}

pub unsafe trait Scannable {
    type Mode: ScanMode;

    fn mem_view(&amp;amp;self) -&amp;gt; &amp;amp;[u8];
}
&lt;/code>&lt;/pre>&lt;p>Note that we have an associated &lt;code>type Mode&lt;/code> which contains the corresponding &lt;code>ScanMode&lt;/code>. If we used a trait bound such as &lt;code>Scannable: ScanMode&lt;/code>, we'd be back to square one: it would inherit the method definitions that don't use &lt;code>&amp;amp;self&lt;/code> and thus cannot be used as trait objects.&lt;/p>&lt;p>With these changes, it is possible to implement &lt;code>Scannable&lt;/code> for any &lt;code>dyn Scannable&lt;/code>:&lt;/p>&lt;pre>&lt;code class="language-rust">unsafe impl&amp;lt;T: ScanMode + AsRef&amp;lt;dyn Scannable&amp;lt;Mode = Self&amp;gt;&amp;gt;&amp;gt; Scannable for T {
    type Mode = Self;

    fn mem_view(&amp;amp;self) -&amp;gt; &amp;amp;[u8] {
        self.as_ref().mem_view()
    }
}
&lt;/code>&lt;/pre>&lt;p>We do have to adjust a few places of the code to account for both &lt;code>Scannable&lt;/code> and &lt;code>ScanMode&lt;/code>, but all in all, it's pretty straightforward. Things like &lt;code>Value&lt;/code> don't need to store the &lt;code>Scannable&lt;/code> anymore, just a &lt;code>Vec&amp;lt;u8&amp;gt;&lt;/code>. It also doesn't need the &lt;code>ScanMode&lt;/code>, because it's not going to be scanning anything on its own. This applies transitively to &lt;code>Region&lt;/code> which was holding a &lt;code>Value&lt;/code>.&lt;/p>&lt;p>&lt;code>Value&lt;/code> &lt;em>does&lt;/em> need to be updated to store the size of the region we are scanning for, however, because we need that information when running a subsequent scan. For all &lt;code>Scan&lt;/code> that don't have a explicit thing to scan for (like &lt;code>Decreased&lt;/code>), the &lt;code>size&lt;/code> also needs to be stored in them.&lt;/p>&lt;p>Despite all our efforts, we're still unable to return an &lt;code>Scannable&lt;/code> chosen at runtime.&lt;/p>&lt;pre>&lt;code class="language-rust">fn prompt_user_for_scan() -&amp;gt; Scan&amp;lt;Box&amp;lt;dyn Scannable&amp;lt;Mode = ???&amp;gt;&amp;gt;&amp;gt; {
    todo!()
}
&lt;/code>&lt;/pre>&lt;p>As far as I can tell, there's simply no way to specify that type. We want to return a type which is scannable, which has itself (which is also a &lt;code>ScanMode&lt;/code>) as the corresponding mode. Even if we just tried to return the mode, we simply can't, because it's not object-safe. Is this the end of the road?&lt;/p>&lt;h2 id="specifying-the-scan-mode">&lt;a href="#specifying-the-scan-mode">Specifying the scan mode&lt;/a>&lt;/h2>&lt;p>We need a way to pass an arbitrary scan mode to our &lt;code>Scan&lt;/code>. This scan mode should go in tandem with &lt;code>Scannable&lt;/code> types, because it would be unsafe otherwise. We've seen that using a type just doesn't cut it. What else can we do?&lt;/p>&lt;p>Using an enumeration is a no-go, because I want users to be able to extend it further. I also would like to avoid having to update the &lt;code>enum&lt;/code> and all the matches every time I come up with a different type combination. And it could get pretty complicated if I ever built something dynamically, such as letting the user combine different scans in one pass.&lt;/p>&lt;p>So what if we make &lt;code>Scannable&lt;/code> return a value that implements the functions we need?&lt;/p>&lt;pre>&lt;code class="language-rust">pub struct ScanMode {
    eq: unsafe fn(left: &amp;amp;[u8], right: &amp;amp;[u8]) -&amp;gt; bool,
    cmp: unsafe fn(left: &amp;amp;[u8], right: &amp;amp;[u8]) -&amp;gt; Ordering,
}
&lt;/code>&lt;/pre>&lt;p>It's definitely… non-conventional. But hey, now we're left with the &lt;code>Scannable&lt;/code> trait, which is object-safe, and does not have any type parameters!&lt;/p>&lt;pre>&lt;code class="language-rust">pub unsafe trait Scannable {
    fn mem_view(&amp;amp;self) -&amp;gt; &amp;amp;[u8];
    fn scan_mode(&amp;amp;self) -&amp;gt; ScanMode;
}
&lt;/code>&lt;/pre>&lt;p>It is a bit weird, but defining local functions and using those in the returned value is a nice way to keep things properly scoped:&lt;/p>&lt;pre>&lt;code class="language-rust">macro_rules! impl_scannable_for_int {
    ( $( $ty:ty ),* ) =&amp;gt; {
        $(
            unsafe impl Scannable for $ty {
                fn mem_view(&amp;amp;self) -&amp;gt; &amp;amp;[u8] {
                    unsafe { std::slice::from_raw_parts(self as *const _ as *const u8, mem::size_of::&amp;lt;$ty&amp;gt;()) }
                }

                fn scan_mode(&amp;amp;self) -&amp;gt; ScanMode {
                    unsafe fn eq(left: &amp;amp;[u8], right: &amp;amp;[u8]) -&amp;gt; bool {
                        ...
                    }

                    unsafe fn cmp(left: &amp;amp;[u8], right: &amp;amp;[u8]) -&amp;gt; Ordering {
                        ...
                    }

                    ScanMode { eq, cmp }
                }
            }
        )*
    };
}
&lt;/code>&lt;/pre>&lt;p>Our &lt;code>Scan&lt;/code> needs to store the &lt;code>Scannable&lt;/code> type, and not just the memory, once again. For variants that don't need any value, they can store the &lt;code>ScanMode&lt;/code> and size instead.&lt;/p>&lt;p>Does this solution work? Yes! It's possible to return a &lt;code>Box&amp;lt;dyn Scannable&amp;gt;&lt;/code> from a function, and underneath, it may be using any type which is &lt;code>Scannable&lt;/code>. Is this the best solution? Well, that's hard to say. This is &lt;em>one&lt;/em> of the possible solutions.&lt;/p>&lt;p>We have been going around in circles for quite some time now, so I'll leave it there. It's a solution, which may not be pretty, but it works. With these changes, the code is capable of completing all of the steps in the Cheat Engine tutorial up until point!&lt;/p>&lt;h2 id="finale">&lt;a href="#finale">Finale&lt;/a>&lt;/h2>&lt;p>If there's one lesson to learn from this post, it's that there is often no single correct solution to a problem. We could have approached the scan types in many, many ways (and we tried quite a few!), but in the end, choosing one option or the other comes down to your (sometimes self-imposed) requirements.&lt;/p>&lt;p>You may &lt;a href="https://github.com/lonami/memo">obtain the code for this post&lt;/a> over at my GitHub. You can run &lt;code>git checkout step4&lt;/code> after cloning the repository to get the right version of the code. The code has gone through a lot of iterations, and I'd still like to polish it a bit more, so it might slightly differ from the code presented in this entry.&lt;/p>&lt;p>If you feel adventurous, Cheat Engine has different options for scanning floating point types: "rounded (default)", "rounded (extreme)", and truncated. Optionally, it can scan for "simple values only". You could go ahead and toy around with these!&lt;/p>&lt;p>We didn't touch on types with different lengths, such as strings. You could support UTF-8, UTF-16, or arbitrary byte sequences. This post also didn't cover scanning for multiple things at once, known as "groupscan commands", although from what I can tell, these are just a nice way to scan for arbitrary byte sequences.&lt;/p>&lt;p>We also didn't look into supporting different the same scan with different alignments. All these things may be worth exploring depending on your requirements. You could even get rid of such genericity and go with something way simpler. Supporting &lt;code>i32&lt;/code>, &lt;code>f32&lt;/code> and &lt;code>f64&lt;/code> is enough to complete the Cheat Engine tutorial. But I wanted something more powerful, although my solution currently can't scan for a sequence such as "exact type, unknown, exact matching the unknown". So yeah.&lt;/p>&lt;p>In the &lt;a href="/blog/woce-5">next post&lt;/a>, we'll tackle the fifth step of the tutorial: Code finder. Cheat Engine attaches its debugger to the process for this one, and then replaces the instruction that performs the write with a different no-op so that nothing is written anymore. This will be quite the challenge!&lt;/p>&lt;h3 id="footnotes">&lt;a href="#footnotes">Footnotes&lt;/a>&lt;/h3>&lt;p id="fn:1" class="footnote-definition">&lt;span>1&lt;/span>&lt;a href="https://doc.rust-lang.org/stable/std/ops/trait.Drop.html#copy-and-drop-are-exclusive">&lt;code>Copy&lt;/code> and &lt;code>Drop&lt;/code> are exclusive&lt;/a>. See also &lt;a href="https://doc.rust-lang.org/stable/error-index.html#E0184">E0184&lt;/a>.&amp;nbsp;&lt;a href="#fnref:1">↩&lt;/a>&lt;/p>&lt;p id="fn:2" class="footnote-definition">&lt;span>2&lt;/span> If you added more scan types that require additional bounds, make sure to add them too. For example, the "decreased by" scan requires the type to &lt;code>impl Sub&lt;/code>.&amp;nbsp;&lt;a href="#fnref:2">↩&lt;/a>&lt;/p>&lt;p id="fn:3" class="footnote-definition">&lt;span>3&lt;/span> This is a good time to remind you to read the documentation. It is of special importance when dealing with &lt;code>unsafe&lt;/code> methods; I recommend reading it a couple times.&amp;nbsp;&lt;a href="#fnref:3">↩&lt;/a>&lt;/p>&lt;p id="fn:4" class="footnote-definition">&lt;span>4&lt;/span> Even with this option, it would not be a bad idea to make the trait &lt;code>unsafe&lt;/code>.&amp;nbsp;&lt;a href="#fnref:4">↩&lt;/a>&lt;/p>&lt;p id="fn:5" class="footnote-definition">&lt;span>5&lt;/span> Not for long. As we will find out later, this approach has its limitations.&amp;nbsp;&lt;a href="#fnref:5">↩&lt;/a>&lt;/p>&lt;p id="fn:6" class="footnote-definition">&lt;span>6&lt;/span> We can still perform the pointer dereference when we know it's aligned. This would likely be an optimization, although it would definitely complicate the code more.&amp;nbsp;&lt;a href="#fnref:6">↩&lt;/a>&lt;/p>&lt;p id="fn:7" class="footnote-definition">&lt;span>7&lt;/span> It &lt;em>would&lt;/em> work if you scanned for unknown values and then checked for decreased values repeatedly. But we can't just leave exact scan broken!&amp;nbsp;&lt;a href="#fnref:7">↩&lt;/a>&lt;/p>&lt;p id="fn:8" class="footnote-definition">&lt;span>8&lt;/span> Unfortunately, this makes some optimizations harder or even impossible to perform. Providing specialized functions for types where the size is known at compile time could be worth doing. Programming is all tradeoffs.&amp;nbsp;&lt;a href="#fnref:8">↩&lt;/a>&lt;/p>&lt;p id="fn:9" class="footnote-definition">&lt;span>9&lt;/span>&lt;a href="https://blog.rust-lang.org/2021/02/26/const-generics-mvp-beta.html">Rust 1.51&lt;/a>, which was not out at the time of writing, would make it a lot easier to allow scanning for fixed-length sequences of bytes, thanks to const generics.&amp;nbsp;&lt;a href="#fnref:9">↩&lt;/a>&lt;/p>&lt;p id="fn:10" class="footnote-definition">&lt;span>10&lt;/span> Workarounds do exist, such as &lt;a href="https://crates.io/crates/dyn-clone">dtolnay's &lt;code>dyn-clone&lt;/code>&lt;/a>. But I would rather not go that route.&amp;nbsp;&lt;a href="#fnref:10">↩&lt;/a>&lt;/p></content></entry><entry xml:lang="en"><title>Writing our own Cheat Engine: Unknown initial value</title><published>2021-02-19T00:00:00+00:00</published><updated>2021-02-19T00:00:00+00:00</updated><link href="https://lonami.dev/blog/woce-3/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/woce-3/</id><content type="html">&lt;p>This is part 3 on the &lt;em>Writing our own Cheat Engine&lt;/em> series:&lt;/p>&lt;ul>&lt;li>&lt;a href="/blog/woce-1">Part 1: Introduction&lt;/a> (start here if you're new to the series!)&lt;/li>&lt;li>&lt;a href="/blog/woce-2">Part 2: Exact Value scanning&lt;/a>&lt;/li>&lt;li>Part 3: Unknown initial value&lt;/li>&lt;li>&lt;a href="/blog/woce-4">Part 4: Floating points&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-5">Part 5: Code finder&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-6">Part 6: Pointers&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-7">Part 7: Code Injection&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-8">Part 8: Multilevel pointers&lt;/a>&lt;/li>&lt;/ul>&lt;p>In part 2 we left off with a bit of a cliff-hanger. Our little program is now able to scan for an exact value, remember the couple hundred addresses pointing to said value, and perform subsequent scans to narrow the list of addresses down until we're left with a handful of them.&lt;/p>&lt;p>However, it is not always the case that you have an exact value to work with. The best you can do in these cases is guess what the software might be storing. For example, it could be a floating point for your current movement speed in a game, or an integer for your current health.&lt;/p>&lt;p>The problem with this is that there are far too many possible locations storing our desired value. If you count misaligned locations, this means there is a different location to address every single byte in memory. A program with one megabyte of memory already has a &lt;em>million&lt;/em> of addresses. Clearly, we need to do better than performing one million memory reads&lt;a href="#fn:1">&lt;sup id="fnref:1">↪1&lt;/sup>&lt;/a>.&lt;/p>&lt;p>This post will shift focus a bit from using &lt;code>winapi&lt;/code> to possible techniques to perform the various scans.&lt;/p>&lt;h2 id="unknown-initial-value">&lt;a href="#unknown-initial-value">Unknown initial value&lt;/a>&lt;/h2>&lt;details open>&lt;summary>Cheat Engine Tutorial: Step 3&lt;/summary>&lt;blockquote>&lt;p>Ok, seeing that you've figured out how to find a value using exact value let's move on to the next step.&lt;/p>&lt;p>First things first though. Since you are doing a new scan, you have to click on New Scan first, to start a new scan. (You may think this is straighforward, but you'd be surprised how many people get stuck on that step) I won't be explaining this step again, so keep this in mind Now that you've started a new scan, let's continue&lt;/p>&lt;p>In the previous test we knew the initial value so we could do a exact value, but now we have a status bar where we don't know the starting value. We only know that the value is between 0 and 500. And each time you click 'hit me' you lose some health. The amount you lose each time is shown above the status bar.&lt;/p>&lt;p>Again there are several different ways to find the value. (like doing a decreased value by... scan), but I'll only explain the easiest. "Unknown initial value", and decreased value. Because you don't know the value it is right now, a exact value wont do any good, so choose as scantype 'Unknown initial value', again, the value type is 4-bytes. (most windows apps use 4-bytes)click first scan and wait till it's done.&lt;/p>&lt;p>When it is done click 'hit me'. You'll lose some of your health. (the amount you lost shows for a few seconds and then disappears, but you don't need that) Now go to Cheat Engine, and choose 'Decreased Value' and click 'Next Scan' When that scan is done, click hit me again, and repeat the above till you only find a few.&lt;/p>&lt;p>We know the value is between 0 and 500, so pick the one that is most likely the address we need, and add it to the list. Now change the health to 5000, to proceed to the next step.&lt;/p>&lt;/blockquote>&lt;/details>&lt;h2 id="dense-memory-locations">&lt;a href="#dense-memory-locations">Dense memory locations&lt;/a>&lt;/h2>&lt;p>The key thing to notice here is that, when we read memory from another process, we do so over &lt;em>entire regions&lt;/em>. A memory region is represented by a starting offset, a size, and a bunch of other things like protection level.&lt;/p>&lt;p>When running the first scan for an unknown value, all we need to remember is the starting offset and size for every single region. All the candidate locations that could point to our value fall within this range, so it is enough for us to store the range definition, and not every location within it.&lt;/p>&lt;p>To gain a better understanding of what this means, let's come up with a more specific scenario. With our current approach of doing things, we store an address (&lt;code>usize&lt;/code>) for every location pointing to our desired value. In the case of unknown values, all locations are equally valid, since we don't know what value they should point to yet, and any value they point to is good. With this representation, we would end up with a very large vector:&lt;/p>&lt;pre>&lt;code class="language-rust">let locations = vec![0x2000, 0x2001, ..., 0x20ff, 0x2100];
&lt;/code>&lt;/pre>&lt;p>This representation is dense. Every single number in the range &lt;code>0x2000..=0x2100&lt;/code> is present. So why bother storing the values individually when the range is enough?:&lt;/p>&lt;pre>&lt;code class="language-rust">let locations = EntireRegion { range: 0x2000..=0x2100 };
&lt;/code>&lt;/pre>&lt;p>Much better! With two &lt;code>usize&lt;/code>, one for the starting location and another for the end, we can indicate that we care about all the locations falling in that range.&lt;/p>&lt;p>In fact, some accessible memory regions immediately follow eachother, so we could even compact this further and merge regions which are together. But due to their potential differences with regards to protection levels, we will not attempt to merge regions.&lt;/p>&lt;p>We don't want to get rid of the old way of storing locations, because once we start narrowing them down, we will want to go back to storing just a few candidates. To keep things tidy, let's introduce a new &lt;code>enum&lt;/code> representing either possibility:&lt;/p>&lt;pre>&lt;code class="language-rust">use std::ops::Range;

pub enum CandidateLocations {
    Discrete {
        locations: Vec&amp;lt;usize&amp;gt;,
    },
    Dense {
        range: Range&amp;lt;usize&amp;gt;,
    }
}
&lt;/code>&lt;/pre>&lt;p>Let's also introduce another &lt;code>enum&lt;/code> to perform the different scan types. For the time being, we will only worry about looking for &lt;code>i32&lt;/code> in memory:&lt;/p>&lt;pre>&lt;code class="language-rust">pub enum Scan {
    Exact(i32),
    Unknown,
}
&lt;/code>&lt;/pre>&lt;h2 id="storing-scanned-values">&lt;a href="#storing-scanned-values">Storing scanned values&lt;/a>&lt;/h2>&lt;p>When scanning for exact values, it's not necessary to store the value found. We already know they're all the same, for example, value &lt;code>42&lt;/code>. However, if the value is unknown, we do need to store it so that we can compare it in a subsequent scan to see if the value is the same or it changed. This means the value can be "any within" the read memory chunk:&lt;/p>&lt;pre>&lt;code class="language-rust">pub enum Value {
    Exact(i32),
    AnyWithin(Vec&amp;lt;u8&amp;gt;),
}
&lt;/code>&lt;/pre>&lt;p>For every region in memory, there will be some candidate locations and a value (or value range) we need to compare against in subsequent scans:&lt;/p>&lt;pre>&lt;code class="language-rust">pub struct Region {
    pub info: winapi::um::winnt::MEMORY_BASIC_INFORMATION,
    pub locations: CandidateLocations,
    pub value: Value,
}
&lt;/code>&lt;/pre>&lt;p>With all the data structures needed setup, we can finally refactor our old scanning code into a new method capable of dealing with all these cases. For brevity, I will omit the exact scan, as it remains mostly unchanged:&lt;/p>&lt;pre>&lt;code class="language-rust">use winapi::um::winnt::MEMORY_BASIC_INFORMATION;

...

// inside `impl Process`
pub fn scan_regions(&amp;amp;self, regions: &amp;amp;[MEMORY_BASIC_INFORMATION], scan: Scan) -&amp;gt; Vec&amp;lt;Region&amp;gt; {
    regions
        .iter()
        .flat_map(|region| match scan {
            Scan::Exact(n) =&amp;gt; todo!("old scan implementation"),
            Scan::Unknown =&amp;gt; {
                let base = region.BaseAddress as usize;
                match self.read_memory(region.BaseAddress as _, region.RegionSize) {
                    Ok(memory) =&amp;gt; Some(Region {
                        info: region.clone(),
                        locations: CandidateLocations::Dense {
                            range: base..base + region.RegionSize,
                        },
                        value: Value::AnyWithin(memory),
                    }),
                    Err(_) =&amp;gt; None,
                }
            }
        })
        .collect()
}
&lt;/code>&lt;/pre>&lt;p>Time to try it out!&lt;/p>&lt;pre>&lt;code class="language-rust">impl CandidateLocations {
    pub fn len(&amp;amp;self) -&amp;gt; usize {
        match self {
            CandidateLocations::Discrete { locations } =&amp;gt; locations.len(),
            CandidateLocations::Dense { range } =&amp;gt; range.len(),
        }
    }
}

...

fn main() {
    // -snip-

    println!("Scanning {} memory regions", regions.len());
    let last_scan = process.scan_regions(&amp;amp;regions, Scan::Unknown);
    println!(
        "Found {} locations",
        last_scan.iter().map(|r| r.locations.len()).sum::&amp;lt;usize&amp;gt;()
    );
}
&lt;/code>&lt;/pre>&lt;pre>Scanning 88 memory regions
Found 3014656 locations
&lt;/pre>&lt;p>If we consider misaligned locations, there is a lot of potential addresses where we could look for. Running the same scan on Cheat Engine yields &lt;code>2,449,408&lt;/code> addresses, which is pretty close. It's probably skipping some additional regions that we are considering. Emulating Cheat Engine to perfection is not a concern for us at the moment, so I'm not going to investigate what regions it actually uses.&lt;/p>&lt;h2 id="comparing-scanned-values">&lt;a href="#comparing-scanned-values">Comparing scanned values&lt;/a>&lt;/h2>&lt;p>Now that we have performed the initial scan and have stored all the &lt;code>CandidateLocations&lt;/code> and &lt;code>Value&lt;/code>, we can re-implement the "next scan" step to handle any variant of our &lt;code>Scan&lt;/code> enum. This enables us to mix-and-match any &lt;code>Scan&lt;/code> mode in any order. For example, one could perform an exact scan, then one for decreased values, or start with unknown scan and scan for unchanged values.&lt;/p>&lt;p>The tutorial suggests using "decreased value" scan, so let's start with that:&lt;/p>&lt;pre>&lt;code class="language-rust">pub enum Scan {
    Exact(i32),
    Unknown,
    Decreased, // new!
}
&lt;/code>&lt;/pre>&lt;p>Other scanning modes, such as decreased by a known amount rather than any decrease, increased, unchanged, changed and so on, are not very different from the "decreased" scan, so I won't bore you with the details.&lt;/p>&lt;p>I will use a different method to perform a "rescan", since the first one is a bit more special in that it doesn't start with any previous values:&lt;/p>&lt;pre>&lt;code class="language-rust">pub fn rescan_regions(&amp;amp;self, regions: &amp;amp;[Region], scan: Scan) -&amp;gt; Vec&amp;lt;Region&amp;gt; {
    regions
        .iter()
        .flat_map(|region| match scan {
            Scan::Decreased =&amp;gt; {
                let mut locations = Vec::new();
                match region.locations {
                    CandidateLocations::Dense { range } =&amp;gt; {
                        match self.read_memory(range.start, range.end - range.start) {
                            Ok(memory) =&amp;gt; match region.value {
                                Value::AnyWithin(previous) =&amp;gt; {
                                    memory
                                        .windows(4)
                                        .zip(previous.windows(4))
                                        .enumerate()
                                        .step_by(4)
                                        .for_each(|(offset, (new, old))| {
                                            let new = i32::from_ne_bytes([
                                                new[0], new[1], new[2], new[3],
                                            ]);
                                            let old = i32::from_ne_bytes([
                                                old[0], old[1], old[2], old[3],
                                            ]);
                                            if new &amp;lt; old {
                                                locations.push(range.start + offset);
                                            }
                                        });

                                    Some(Region {
                                        info: region.info.clone(),
                                        locations: CandidateLocations::Discrete { locations },
                                        value: Value::AnyWithin(memory),
                                    })
                                }
                                _ =&amp;gt; todo!(),
                            },
                            _ =&amp;gt; todo!(),
                        }
                    }
                    _ =&amp;gt; todo!(),
                }
            }
            _ =&amp;gt; todo!(),
        })
        .collect()
}
&lt;/code>&lt;/pre>&lt;p>If you've skimmed over that, I do not blame you. Here's the summary: for every existing region, when executing the scan mode "decreased", if the previous locations were dense, read the entire memory region. On success, if the previous values were a chunk of memory, iterate over the current and old memory at the same time, and for every aligned &lt;code>i32&lt;/code>, if the new value is less, store it.&lt;/p>&lt;p>It's also making me ill. Before I leave a mess on the floor, does it work?&lt;/p>&lt;pre>&lt;code class="language-rust">std::thread::sleep(std::time::Duration::from_secs(10));
let last_scan = process.rescan_regions(&amp;amp;last_scan, Scan::Decreased);
println!(
    "Found {} locations",
    last_scan.iter().map(|r| r.locations.len()).sum::&amp;lt;usize&amp;gt;()
);
&lt;/code>&lt;/pre>&lt;pre>&lt;code class="language-rust">Found 3014656 locations
Found 177 locations
&lt;/code>&lt;/pre>&lt;p>Okay, great, let's clean up this mess…&lt;/p>&lt;h2 id="refactoring">&lt;a href="#refactoring">Refactoring&lt;/a>&lt;/h2>&lt;p>Does it also make you uncomfortable to be writing something that you know will end up &lt;em>huge&lt;/em> unless you begin refactoring other parts right now? I definitely feel that way. But I think it's good discipline to push through with something that works first, even if it's nasty, before going on a tangent. Now that we have the basic implementation working, let's take on this monster before it eats us alive.&lt;/p>&lt;p>First things first, that method is inside an &lt;code>impl&lt;/code> block. The deepest nesting level is 13. I almost have to turn around my chair to read the entire thing out!&lt;/p>&lt;p>Second, we're nesting four matches. Three of them we care about: scan, candidate location, and value. If each of these &lt;code>enum&lt;/code> has &lt;code>S&lt;/code>, &lt;code>C&lt;/code> and &lt;code>V&lt;/code> variants respectively, writing each of these by hand will require &lt;code>S * C * V&lt;/code> different implementations! Cheat Engine offers 10 different scans, I can think of at least 3 different ways to store candidate locations, and another 3 ways to store the values found. That's &lt;code>10 * 3 * 3 = 90&lt;/code> different combinations. I am not willing to write out all these&lt;a href="#fn:2">&lt;sup id="fnref:2">↪2&lt;/sup>&lt;/a>, so we need to start introducing some abstractions. Just imagine what a monster function you would end with! The horror!&lt;/p>&lt;p>Third, why is the scan being executed in the process? This is something that should be done in the &lt;code>impl Scan&lt;/code> instead!&lt;/p>&lt;p>Let's begin the cleanup:&lt;/p>&lt;pre>&lt;code class="language-rust">pub fn rescan_regions(&amp;amp;self, regions: &amp;amp;[Region], scan: Scan) -&amp;gt; Vec&amp;lt;Region&amp;gt; {
    todo!()
}
&lt;/code>&lt;/pre>&lt;p>I already feel ten times better.&lt;/p>&lt;p>Now, this method will unconditionally read the entire memory region, even if the scan or the previous candidate locations don't need it&lt;a href="#fn:3">&lt;sup id="fnref:3">↪3&lt;/sup>&lt;/a>. In the worst case with a single discrete candidate location, we will be reading a very large chunk of memory when we could have read just the 4 bytes needed for the &lt;code>i32&lt;/code>. On the bright side, if there &lt;em>are&lt;/em> more locations in this memory region, we will get read of them at the same time&lt;a href="#fn:4">&lt;sup id="fnref:4">↪4&lt;/sup>&lt;/a>. So even if we're moving more memory around all the time, it isn't &lt;em>too&lt;/em> bad.&lt;/p>&lt;pre>&lt;code class="language-rust">regions
    .iter()
    .flat_map(
        |region| match self.read_memory(region.info.BaseAddress as _, region.info.RegionSize) {
            Ok(memory) =&amp;gt; todo!(),
            Err(err) =&amp;gt; {
                eprintln!(
                    "Failed to read {} bytes at {:?}: {}",
                    region.info.RegionSize, region.info.BaseAddress, err,
                );
                None
            }
        },
    )
    .collect()
&lt;/code>&lt;/pre>&lt;p>Great! If reading memory succeeds, we want to rerun the scan:&lt;/p>&lt;pre>&lt;code class="language-rust">Ok(memory) =&amp;gt; Some(scan.rerun(region, memory)),
&lt;/code>&lt;/pre>&lt;p>The rerun will live inside &lt;code>impl Scan&lt;/code>:&lt;/p>&lt;pre>&lt;code class="language-rust">pub fn rerun(&amp;amp;self, region: &amp;amp;Region, memory: Vec&amp;lt;u8&amp;gt;) -&amp;gt; Region {
    match self {
        Scan::Exact(_) =&amp;gt; self.run(region.info.clone(), memory),
        Scan::Unknown =&amp;gt; region.clone(),
        Scan::Decreased =&amp;gt; todo!(),
    }
}
&lt;/code>&lt;/pre>&lt;p>An exact scan doesn't care about any previous values, so it behaves like a first scan. The first scan is done by the &lt;code>run&lt;/code> function (it contains the implementation factored out of the &lt;code>Process::scan_regions&lt;/code> method), which only needs the region information and the current memory chunk we just read.&lt;/p>&lt;p>The unknown scan leaves the region unchanged: any value stored is still valid, because it is unknown what we're looking for.&lt;/p>&lt;p>The decreased scan will have to iterate over all the candidate locations, and compare them with the current memory chunk. But this time, we'll abstract this iteration too:&lt;/p>&lt;pre>&lt;code class="language-rust">impl Region {
    fn iter_locations&amp;lt;'a&amp;gt;(
        &amp;amp;'a self,
        new_memory: &amp;amp;'a [u8],
    ) -&amp;gt; impl Iterator&amp;lt;Item = (usize, i32, i32)&amp;gt; + 'a {
        match &amp;amp;self.locations {
            CandidateLocations::Dense { range } =&amp;gt; range.clone().step_by(4).map(move |addr| {
                let old = self.value_at(addr);
                let new = i32::from_ne_bytes([
                    new_memory[0],
                    new_memory[1],
                    new_memory[2],
                    new_memory[3],
                ]);
                (addr, old, new)
            }),
            _ =&amp;gt; todo!(),
        }
    }
}
&lt;/code>&lt;/pre>&lt;p>For a dense candidate location, we iterate over all the 4-aligned addresses (fast scan for &lt;code>i32&lt;/code> values), and yield &lt;code>(current address, old value, new value)&lt;/code>. This way, the &lt;code>Scan&lt;/code> can do anything it wants with the old and new values, and if it finds a match, it can use the address.&lt;/p>&lt;p>The &lt;code>value_at&lt;/code> method will deal with all the &lt;code>Value&lt;/code> variants:&lt;/p>&lt;pre>&lt;code class="language-rust">fn value_at(&amp;amp;self, addr: usize) -&amp;gt; i32 {
    match &amp;amp;self.value {
        Value::AnyWithin(chunk) =&amp;gt; {
            let base = addr - self.info.BaseAddress as usize;
            let bytes = &amp;amp;chunk[base..base + 4];
            i32::from_ne_bytes([bytes[0], bytes[1], bytes[2], bytes[3]])
        }
        _ =&amp;gt; todo!(),
    }
}
&lt;/code>&lt;/pre>&lt;p>This way, &lt;code>iter_locations&lt;/code> can easily use any value type. With this, we have all &lt;code>enum&lt;/code> covered: &lt;code>Scan&lt;/code> in &lt;code>rerun&lt;/code>, &lt;code>CandidateLocation&lt;/code> in &lt;code>iter_locations&lt;/code>, and &lt;code>Value&lt;/code> in &lt;code>value_at&lt;/code>. Now we can add as many variants as we want, and we will only need to update a single &lt;code>match&lt;/code> arm for each of them. Let's implement &lt;code>Scan::Decreased&lt;/code> and try it out:&lt;/p>&lt;pre>&lt;code class="language-rust">pub fn rerun(&amp;amp;self, region: &amp;amp;Region, memory: Vec&amp;lt;u8&amp;gt;) -&amp;gt; Region {
    match self {
        Scan::Decreased =&amp;gt; Region {
            info: region.info.clone(),
            locations: CandidateLocations::Discrete {
                locations: region
                    .iter_locations(&amp;amp;memory)
                    .flat_map(|(addr, old, new)| if new &amp;lt; old { Some(addr) } else { None })
                    .collect(),
            },
            value: Value::AnyWithin(memory),
        },,
    }
}
&lt;/code>&lt;/pre>&lt;pre>Found 3014656 locations
Found 223791 locations
&lt;/pre>&lt;p>Hmm… before we went down from &lt;code>3014656&lt;/code> to &lt;code>177&lt;/code> locations, and now we went down to &lt;code>223791&lt;/code>. Where did we go wrong?&lt;/p>&lt;p>After spending several hours on this, I can tell you where we went wrong. &lt;code>iter_locations&lt;/code> is always accessing the memory range &lt;code>0..4&lt;/code>, and not the right address. Here's the fix:&lt;/p>&lt;pre>&lt;code class="language-rust">CandidateLocations::Dense { range } =&amp;gt; range.clone().step_by(4).map(move |addr| {
    let old = self.value_at(addr);
    let base = addr - self.info.BaseAddress as usize;
    let bytes = &amp;amp;new_memory[base..base + 4];
    let new = i32::from_ne_bytes([bytes[0], bytes[1], bytes[2], bytes[3]]);
    (addr, old, new)
}),
&lt;/code>&lt;/pre>&lt;h2 id="going-beyond">&lt;a href="#going-beyond">Going beyond&lt;/a>&lt;/h2>&lt;p>Let's take a look at other possible &lt;code>Scan&lt;/code> types. Cheat Engine supports the following initial scan types:&lt;/p>&lt;ul>&lt;li>Exact Value&lt;/li>&lt;li>Bigger than…&lt;/li>&lt;li>Smaller than…&lt;/li>&lt;li>Value between…&lt;/li>&lt;li>Unknown initial value&lt;/li>&lt;/ul>&lt;p>"Bigger than" and "Smaller than" can both be represented by "Value between", so it's pretty much just three.&lt;/p>&lt;p>For subsequent scans, in addition to the scan types described above, we find:&lt;/p>&lt;ul>&lt;li>Increased value&lt;/li>&lt;li>Increased value by…&lt;/li>&lt;li>Decreased value&lt;/li>&lt;li>Decreased value by…&lt;/li>&lt;li>Changed value&lt;/li>&lt;li>Unchanged value&lt;/li>&lt;/ul>&lt;p>Not only does Cheat Engine provide all of these scans, but all of them can also be negated. For example, "find values that were not increased by 7". One could imagine to also support things like "increased value by range". For the increased and decreased scans, Cheat Engine also supports "at least xx%", so that if the value changed within the specified percentage interval, it will be considered.&lt;/p>&lt;p>What about &lt;code>CandidateLocations&lt;/code>? I can't tell you how Cheat Engine stores these, but I can tell you that &lt;code>CandidateLocations::Discrete&lt;/code> can still be quite inefficient. Imagine you've started with a scan for unknown values and then ran a scan for unchanged valueus. Most values in memory will have been unchanged, but with our current implementation, we are now storing an entire &lt;code>usize&lt;/code> address for each of these. One option would be to introduce &lt;code>CandidateLocations::Sparse&lt;/code>, which would be a middle ground. You could implement it like &lt;code>Dense&lt;/code> and include a vector of booleans telling you which values to consider, or go smaller and use a bitstring or bit vector. You could use a sparse vector data structure.&lt;/p>&lt;p>&lt;code>Value&lt;/code> is very much like &lt;code>CandidateLocations&lt;/code>, except that it stores a value to compare against and not an address. Here we can either have an exact value, or an older copy of the memory. Again, keeping a copy of the entire memory chunk when all we need is a handful of values is inefficient. You could keep a mapping from addresses to values if you don't have too many. Or you could shrink and fragment the copied memory in a more optimal way. There's a lot of room for improvement!&lt;/p>&lt;p>What if, despite all of the efforts above, we still don't have enough RAM to store all this information? The Cheat Engine Tutorial doesn't use a lot of memory, but as soon as you try scanning bigger programs, like games, you may find yourself needing several gigabytes worth of memory to remember all the found values in order to compare them in subsequent scans. You may even need to consider dumping all the regions to a file and read from it to run the comparisons. For example, running a scan for "unknown value" in Cheat Engine brings its memory up by the same amount of memory used by the process scanned (which makes sense), but as soon as I ran a scan for "unchanged value" over the misaligned values, Cheat Engine's disk usage skyrocketed to 1GB/s (!) for several seconds on my SSD. After it finished, memory usage went down to normal. It was very likely writing out all candidate locations to disk.&lt;/p>&lt;h2 id="finale">&lt;a href="#finale">Finale&lt;/a>&lt;/h2>&lt;p>There is a lot of things to learn from Cheat Engine just by observing its behaviour, and we're only scratching its surface.&lt;/p>&lt;p>In the &lt;a href="/blog/woce-4">next post&lt;/a>, we'll tackle the fourth step of the tutorial: Floating points. So far, we have only been working with &lt;code>i32&lt;/code> for simplicity. We will need to update our code to be able to account for different data types, which will make it easy to support other types like &lt;code>i16&lt;/code>, &lt;code>i64&lt;/code>, or even strings, represented as an arbitrary sequence of bytes.&lt;/p>&lt;p>As usual, you can &lt;a href="https://github.com/lonami/memo">obtain the code for this post&lt;/a> over at my GitHub. You can run &lt;code>git checkout step3&lt;/code> after cloning the repository to get the right version of the code. This version is a bit cleaner than the one presented in the blog, and contains some of the things described in the &lt;a href="#going-beyond">Going beyond&lt;/a> section. Until next time!&lt;/p>&lt;h3 id="footnotes">&lt;a href="#footnotes">Footnotes&lt;/a>&lt;/h3>&lt;p id="fn:1" class="footnote-definition">&lt;span>1&lt;/span> Well, technically, we will perform a million memory reads&lt;a href="#fn:5">&lt;sup id="fnref:5">↪5&lt;/sup>&lt;/a>. The issue here is the million calls to &lt;code>ReadProcessMemory&lt;/code>, not reading memory per se.&amp;nbsp;&lt;a href="#fnref:1">↩&lt;/a>&lt;/p>&lt;p id="fn:2" class="footnote-definition">&lt;span>2&lt;/span> Not currently. After a basic implementation works, writing each implementation by hand and fine-tuning them by treating each of them as a special case could yield significant speed improvements. So although it would be a lot of work, this option shouldn't be ruled out completely.&amp;nbsp;&lt;a href="#fnref:2">↩&lt;/a>&lt;/p>&lt;p id="fn:3" class="footnote-definition">&lt;span>3&lt;/span> You could ask the candidate locations where one should read, which would still keep the code reasonably simple.&amp;nbsp;&lt;a href="#fnref:3">↩&lt;/a>&lt;/p>&lt;p id="fn:4" class="footnote-definition">&lt;span>4&lt;/span> You could also optimize for this case by determining both the smallest and largest address, and reading enough to cover them both. Or apply additional heuristics to only do so if the ratio of the size you're reading compared to the size you need isn't too large and abort the joint read otherwise. There is a lot of room for optimization here.&amp;nbsp;&lt;a href="#fnref:4">↩&lt;/a>&lt;/p>&lt;p id="fn:5" class="footnote-definition">&lt;span>5&lt;/span> (A footnote in a footnote?) The machine registers, memory cache and compiler will all help lower this cost, so the generated executable might not actually need that many reads from RAM. But that's getting way too deep into the details now.&amp;nbsp;&lt;a href="#fnref:5">↩&lt;/a>&lt;/p></content></entry><entry xml:lang="en"><title>Writing our own Cheat Engine: Exact Value scanning</title><published>2021-02-12T00:00:00+00:00</published><updated>2021-02-19T00:00:00+00:00</updated><link href="https://lonami.dev/blog/woce-2/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/woce-2/</id><content type="html">&lt;p>This is part 2 on the &lt;em>Writing our own Cheat Engine&lt;/em> series:&lt;/p>&lt;ul>&lt;li>&lt;a href="/blog/woce-1">Part 1: Introduction&lt;/a> (start here if you're new to the series!)&lt;/li>&lt;li>Part 2: Exact Value scanning&lt;/li>&lt;li>&lt;a href="/blog/woce-3">Part 3: Unknown initial value&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-4">Part 4: Floating points&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-5">Part 5: Code finder&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-6">Part 6: Pointers&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-7">Part 7: Code Injection&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-8">Part 8: Multilevel pointers&lt;/a>&lt;/li>&lt;/ul>&lt;p>In the introduction, we spent a good deal of time enumerating all running processes just so we could find out the pid we cared about. With the pid now in our hands, we can do pretty much anything to its corresponding process.&lt;/p>&lt;p>It's now time to read the process' memory and write to it. If our process was a single-player game, this would enable us to do things like setting a very high value on the player's current health pool, making us invincible. This technique will often not work for multi-player games, because the server likely knows your true current health (the most you could probably do is make the client render an incorrect value). However, if the server is crappy and it trusts the client, then you're still free to mess around with your current health.&lt;/p>&lt;p>Even if we don't want to write to the process' memory, reading is still very useful. Maybe you could enhance your experience by making a custom overlay that displays useful information, or something that makes noise if it detects the life is too low, or even simulating a keyboard event to automatically recover some mana when you're running low.&lt;/p>&lt;p>Be warned about anti-cheat systems. Anything beyond a basic game is likely to have some protection measures in place, making the analysis more difficult (perhaps the values are scrambled in memory), or even pinging the server if it detects something fishy.&lt;/p>&lt;p>&lt;strong>I am not responsible for any bans!&lt;/strong> Use your brain before messing with online games, and don't ruin the fun for everyone else. If you get caught for cheating, I don't want to know about it.&lt;/p>&lt;p>Now that all &lt;a href="https://www.urbandictionary.com/define.php?term=script%20kiddie">script kiddies&lt;/a> have left the room, let's proceed with the post.&lt;/p>&lt;h2 id="exact-value-scanning">&lt;a href="#exact-value-scanning">Exact Value scanning&lt;/a>&lt;/h2>&lt;details open>&lt;summary>Cheat Engine Tutorial: Step 2&lt;/summary>&lt;blockquote>&lt;p>Now that you have opened the tutorial with Cheat Engine let's get on with the next step.&lt;/p>&lt;p>You can see at the bottom of this window is the text Health: xxx. Each time you click 'Hit me' your health gets decreased.&lt;/p>&lt;p>To get to the next step you have to find this value and change it to 1000&lt;/p>&lt;p>To find the value there are different ways, but I'll tell you about the easiest, 'Exact Value': First make sure value type is set to at least 2-bytes or 4-bytes. 1-byte will also work, but you'll run into an easy to fix problem when you've found the address and want to change it. The 8-byte may perhaps works if the bytes after the address are 0, but I wouldn't take the bet. Single, double, and the other scans just don't work, because they store the value in a different way.&lt;/p>&lt;p>When the value type is set correctly, make sure the scantype is set to 'Exact Value'. Then fill in the number your health is in the value box. And click 'First Scan'. After a while (if you have a extremely slow pc) the scan is done and the results are shown in the list on the left&lt;/p>&lt;p>If you find more than 1 address and you don't know for sure which address it is, click 'Hit me', fill in the new health value into the value box, and click 'Next Scan'. Repeat this until you're sure you've found it. (that includes that there's only 1 address in the list.....)&lt;/p>&lt;p>Now double click the address in the list on the left. This makes the address pop-up in the list at the bottom, showing you the current value. Double click the value, (or select it and press enter), and change the value to 1000.&lt;/p>&lt;p>If everything went ok the next button should become enabled, and you're ready for the next step.&lt;/p>&lt;p>Note: If you did anything wrong while scanning, click "New Scan" and repeat the scanning again. Also, try playing around with the value and click 'hit me'&lt;/p>&lt;/blockquote>&lt;/details>&lt;h2 id="our-first-scan">&lt;a href="#our-first-scan">Our First Scan&lt;/a>&lt;/h2>&lt;p>The Cheat Engine tutorial talks about "value types" and "scan types" like "exact value".&lt;/p>&lt;p>The &lt;strong>value types&lt;/strong> will help us narrow down &lt;em>what&lt;/em> we're looking for. For example, the integer type &lt;code>i32&lt;/code> is represented in memory as 32 bits, or 4 bytes. However, &lt;code>f32&lt;/code> is &lt;em>also&lt;/em> represented by 4 bytes, and so is &lt;code>u32&lt;/code>. Or perhaps the 4 bytes represent RGBA values of a color! So any 4 bytes in memory can be interpreted in many ways, and it's up to us to decide which way we interpret the bytes in.&lt;/p>&lt;p>When programming, numbers which are 32-bit wide are common, as they're a good (and fast) size to work with. Scanning for this type is often a good bet. For positive numbers, &lt;code>i32&lt;/code> is represented the same as &lt;code>u32&lt;/code> in memory, so even if the value turns out to not be signed, the scan is likely to work. Focusing on &lt;code>i32&lt;/code> will save us from scanning for &lt;code>f32&lt;/code> or even other types, like interpreting 8 bytes for &lt;code>i64&lt;/code>, &lt;code>f64&lt;/code>, or less bytes like &lt;code>i16&lt;/code>.&lt;/p>&lt;p>The &lt;strong>scan types&lt;/strong> will help us narrow down &lt;em>how&lt;/em> we're looking for a value. Scanning for an exact value means what you think it does: interpret all 4 bytes in the process' memory as our value type, and check if they exactly match our value. This will often yield a lot of candidates, but it will be enough to get us started. Variations of the exact scan include checking for all values below a threshold, above, in between, or even just… unknown.&lt;/p>&lt;p>What's the point of scanning for unknown values if &lt;em>everything&lt;/em> in memory is unknown? Sometimes you don't have a concrete value. Maybe your health pool is a bar and it nevers tell you how much health you actually have, just a visual indicator of your percentage left, even if the health is not stored as a percentage. As we will find later on, scanning for unknown values is more useful than it might appear at first.&lt;/p>&lt;p>We can access the memory of our own program by guessing random pointers and trying to read from them. But Windows isolates the memory of each program, so no pointer we could ever guess will let us read from the memory of another process. Luckily for us, searching for "read process memory winapi" leads us to the &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/memoryapi/nf-memoryapi-readprocessmemory">&lt;code>ReadProcessMemory&lt;/code>&lt;/a> function. Spot on.&lt;/p>&lt;pre>&lt;code class="language-rust">pub fn read_memory(&amp;amp;self, addr: usize, n: usize) -&amp;gt; io::Result&amp;lt;Vec&amp;lt;u8&amp;gt;&amp;gt; {
    todo!()
}
&lt;/code>&lt;/pre>&lt;p>Much like trying to dereference a pointer pointing to released memory or even null, reading from an arbitrary address can fail for the same reasons (and more). We will want to signal this with &lt;code>io::Result&lt;/code>. It's funny to note that, even though we're doing something that seems wildly unsafe (reading arbitrary memory, even if the other process is mutating it at the same time), the function is perfectly safe. If we cannot read something, it will return &lt;code>Err&lt;/code>, but if it succeeds, it has taken a snapshot of the memory of the process, and the returned value will be correctly initialized.&lt;/p>&lt;p>The function will be defined inside our &lt;code>impl Process&lt;/code>, since it conveniently holds an open handle to the process in question. It takes &lt;code>&amp;amp;self&lt;/code>, because we do not need to mutate anything in the &lt;code>Process&lt;/code> instance. After adding the &lt;code>memoryapi&lt;/code> feature to &lt;code>Cargo.toml&lt;/code>, we can perform the call:&lt;/p>&lt;pre>&lt;code class="language-rust">let mut buffer = Vec::&amp;lt;u8&amp;gt;::with_capacity(n);
let mut read = 0;

// SAFETY: the buffer points to valid memory, and the buffer size is correctly set.
if unsafe {
    winapi::um::memoryapi::ReadProcessMemory(
        self.handle.as_ptr(),
        addr as *const _,
        buffer.as_mut_ptr().cast(),
        buffer.capacity(),
        &amp;amp;mut read,
    )
} == FALSE
{
    Err(io::Error::last_os_error())
} else {
    // SAFETY: the call succeeded and `read` contains the amount of bytes written.
    unsafe { buffer.set_len(read as usize) };
    Ok(buffer)
}
&lt;/code>&lt;/pre>&lt;p>Great! But the address space is somewhat large. 64 bits large. Eighteen quintillion, four hundred and forty-six quadrillion, seven hundred and forty-four trillion, seventy-three billion, seven hundred and nine million, five hundred and fifty-one thousand, six hundred and sixteen&lt;a href="#fn:1">&lt;sup id="fnref:1">↪1&lt;/sup>&lt;/a> large. You gave up reading that, didn't you? Anyway, 18'446'744'073'709'551'616 is a &lt;em>big&lt;/em> number.&lt;/p>&lt;p>I am not willing to wait for the program to scan over so many values. I don't even have 16 &lt;a href="https://en.wikipedia.org/wiki/Orders_of_magnitude_(data)">exbibytes&lt;/a> of RAM installed on my laptop yet&lt;a href="#fn:2">&lt;sup id="fnref:2">↪2&lt;/sup>&lt;/a>! What's up with that?&lt;/p>&lt;h2 id="memory-regions">&lt;a href="#memory-regions">Memory regions&lt;/a>&lt;/h2>&lt;p>The program does not actually have all that memory allocated (surprise!). Random-guessing an address is extremely likely to point out to invalid memory. Reading from the start of the address space all the way to the end would not be any better. And we &lt;strong>need&lt;/strong> to do better.&lt;/p>&lt;p>We need to query for the memory regions allocated to the program. For this purpose we can use &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/memoryapi/nf-memoryapi-virtualqueryex">&lt;code>VirtualQueryEx&lt;/code>&lt;/a>.&lt;/p>&lt;blockquote>&lt;p>Retrieves information about a range of pages within the virtual address space of a specified process.&lt;/p>&lt;/blockquote>&lt;p>We have enumerated things before, and this function is not all that different.&lt;/p>&lt;pre>&lt;code class="language-rust">fn memory_regions(&amp;amp;self) -&amp;gt; io::Result&amp;lt;winapi::um::winnt::MEMORY_BASIC_INFORMATION&amp;gt; {
    let mut info = MaybeUninit::uninit();

    // SAFETY: the info structure points to valid memory.
    let written = unsafe {
        winapi::um::memoryapi::VirtualQueryEx(
            self.handle.as_ptr(),
            std::ptr::null(),
            info.as_mut_ptr(),
            mem::size_of::&amp;lt;winapi::um::winnt::MEMORY_BASIC_INFORMATION&amp;gt;(),
        )
    };
    if written == 0 {
        Err(io::Error::last_os_error())
    } else {
        // SAFETY: a non-zero amount was written to the structure
        Ok(unsafe { info.assume_init() })
    }
}
&lt;/code>&lt;/pre>&lt;p>We start with a base address of zero&lt;a href="#fn:3">&lt;sup id="fnref:3">↪3&lt;/sup>&lt;/a> (&lt;code>std::ptr::null()&lt;/code>), and ask the function to tell us what's in there. Let's try it out, with the &lt;code>impl-debug&lt;/code> crate feature in &lt;code>Cargo.toml&lt;/code>:&lt;/p>&lt;pre>&lt;code class="language-rust">dbg!(process.memory_regions());
&lt;/code>&lt;/pre>&lt;pre>&amp;gt;cargo run
Compiling memo v0.1.0

error[E0277]: `winapi::um::winnt::MEMORY_BASIC_INFORMATION` doesn't implement `std::fmt::Debug`
   --&amp;gt; src\main.rs:185:5
    |
185 |     dbg!(process.memory_regions());
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ `winapi::um::winnt::MEMORY_BASIC_INFORMATION` cannot be formatted using `{:?}` because it doesn't implement `std::fmt::Debug`
&lt;/pre>&lt;p>That's annoying. It seems not everything has an &lt;code>impl std::fmt::Debug&lt;/code>, and &lt;a href="https://github.com/retep998/winapi-rs/issues/548#issuecomment-355278090">you're supposed to send a PR&lt;/a> if you want it to have debug, even if the &lt;code>impl-debug&lt;/code> feature is set. I'm surprised they don't auto-generate all of this and have to rely on manually adding &lt;code>Debug&lt;/code> as needed? Oh well, let's get rid of the feature and print it out ourselves:&lt;/p>&lt;pre>eprintln!(
    "Region:
    BaseAddress: {:?}
    AllocationBase: {:?}
    AllocationProtect: {:?}
    RegionSize: {:?}
    State: {:?}
    Protect: {:?}
    Type: {:?}",
    region.BaseAddress,
    region.AllocationBase,
    region.AllocationProtect,
    region.RegionSize,
    region.State,
    region.Protect,
    region.Type,
);
&lt;/pre>&lt;p>Hopefully we don't need to do this often:&lt;/p>&lt;pre>&amp;gt;cargo run
   Compiling memo v0.1.0
    Finished dev [unoptimized + debuginfo] target(s) in 0.60s
     Running `target\debug\memo.exe`

Region:
    BaseAddress: 0x0
    AllocationBase: 0x0
    AllocationProtect: 0
    RegionSize: 65536
    State: 65536
    Protect: 1
    Type: 0
&lt;/pre>&lt;p>Awesome! There is a region at &lt;code>null&lt;/code>, and the &lt;code>AllocationProtect&lt;/code> of zero indicates that "the caller does not have access" when the region was created. However, &lt;code>Protect&lt;/code> is &lt;code>1&lt;/code>, and that is the &lt;em>current&lt;/em> protection level. A value of one indicates &lt;a href="https://docs.microsoft.com/en-us/windows/win32/memory/memory-protection-constants">&lt;code>PAGE_NOACCESS&lt;/code>&lt;/a>:&lt;/p>&lt;blockquote>&lt;p>Disables all access to the committed region of pages. An attempt to read from, write to, or execute the committed region results in an access violation.&lt;/p>&lt;/blockquote>&lt;p>Now that we know that the first region starts at 0 and has a size of 64 KiB, we can simply query for the page at &lt;code>(current base + current size)&lt;/code> to fetch the next region. Essentially, we want to loop until it fails, after which we'll know there are no more pages&lt;a href="#fn:4">&lt;sup id="fnref:4">↪4&lt;/sup>&lt;/a>:&lt;/p>&lt;pre>&lt;code class="language-rust">pub fn memory_regions(&amp;amp;self) -&amp;gt; Vec&amp;lt;winapi::um::winnt::MEMORY_BASIC_INFORMATION&amp;gt; {
    let mut base = 0;
    let mut regions = Vec::new();
    let mut info = MaybeUninit::uninit();

    loop {
        // SAFETY: the info structure points to valid memory.
        let written = unsafe {
            winapi::um::memoryapi::VirtualQueryEx(
                self.handle.as_ptr(),
                base as *const _,
                info.as_mut_ptr(),
                mem::size_of::&amp;lt;winapi::um::winnt::MEMORY_BASIC_INFORMATION&amp;gt;(),
            )
        };
        if written == 0 {
            break regions;
        }
        // SAFETY: a non-zero amount was written to the structure
        let info = unsafe { info.assume_init() };
        base = info.BaseAddress as usize + info.RegionSize;
        regions.push(info);
    }
}
&lt;/code>&lt;/pre>&lt;p>&lt;code>RegionSize&lt;/code> is:&lt;/p>&lt;blockquote>&lt;p>The size of the region beginning at the base address in which all pages have identical attributes, in bytes.&lt;/p>&lt;/blockquote>&lt;p>…which also hints that the value we want is "base address", not the "allocation base". With these two values, we can essentially iterate over all the page ranges:&lt;/p>&lt;pre>&lt;code class="language-rust">dbg!(process.memory_regions().len());
&lt;/code>&lt;/pre>&lt;pre>&amp;gt;cargo run
   Compiling memo v0.1.0
    Finished dev [unoptimized + debuginfo] target(s) in 0.63s
     Running `target\debug\memo.exe`

[src\main.rs:189] process.memory_regions().len() = 367
&lt;/pre>&lt;p>That's a lot of pages!&lt;/p>&lt;h2 id="protection-levels">&lt;a href="#protection-levels">Protection levels&lt;/a>&lt;/h2>&lt;p>Let's try to narrow the amount of pages down. How many pages aren't &lt;code>PAGE_NOACCESS&lt;/code>?&lt;/p>&lt;pre>&lt;code class="language-rust">dbg!(process
    .memory_regions()
    .into_iter()
    .filter(|p| p.Protect != winapi::um::winnt::PAGE_NOACCESS)
    .count());
&lt;/code>&lt;/pre>&lt;pre>295
&lt;/pre>&lt;p>Still a fair bit! Most likely, there are just a few interleaved &lt;code>NOACCESS&lt;/code> pages, and the rest are allocated each with different protection levels. How much memory do we need to scan through?&lt;/p>&lt;pre>&lt;code class="language-rust">dbg!(process
    .memory_regions()
    .into_iter()
    .filter(|p| p.Protect != winapi::um::winnt::PAGE_NOACCESS)
    .map(|p| p.RegionSize)
    .sum::&amp;lt;usize&amp;gt;());
&lt;/code>&lt;/pre>&lt;pre>4480434176
&lt;/pre>&lt;p>Wait, what? What do you mean over 4 GiB? The Task Manager claims that the Cheat Engine Tutorial is only using 2.1 MB worth of RAM! Perhaps we can narrow down the &lt;a href="https://docs.microsoft.com/en-us/windows/win32/memory/memory-protection-constants">protection levels&lt;/a> a bit more. If you look at the scan options in Cheat Engine, you will notice the "Memory Scan Options" groupbox. By default, it only scans for memory that is writable, and doesn't care if it's executable or not:&lt;/p>&lt;pre>&lt;code class="language-rust">let mask = winnt::PAGE_EXECUTE_READWRITE
    | winnt::PAGE_EXECUTE_WRITECOPY
    | winnt::PAGE_READWRITE
    | winnt::PAGE_WRITECOPY;

dbg!(process
    .memory_regions()
    .into_iter()
    .filter(|p| (p.Protect &amp;amp; mask) != 0)
    .map(|p| p.RegionSize)
    .sum::&amp;lt;usize&amp;gt;());
&lt;/code>&lt;/pre>&lt;p>Each memory protection level has its own bit, so we can OR them all together to have a single mask. When ANDing this mask with the protection level, if any bit is set, it will be non-zero, meaning we want to keep this region.&lt;/p>&lt;p>Don't ask me why there isn't a specific bit for "write", "read", "execute", and there are only bits for combinations. I guess this way Windows forbids certain combinations.&lt;/p>&lt;pre>2580480
&lt;/pre>&lt;p>Hey, that's close to the value shown by the Task Manager! A handfull of megabytes is a lot more manageable than 4 entire gigabytes.&lt;/p>&lt;h2 id="actually-running-our-first-scan">&lt;a href="#actually-running-our-first-scan">Actually running our First Scan&lt;/a>&lt;/h2>&lt;p>Okay, we have all the memory regions from which the program can read, write, or execute. Now we also can read the memory in these regions:&lt;/p>&lt;pre>&lt;code class="language-rust">let regions = process
    .memory_regions()
    .into_iter()
    .filter(|p| (p.Protect &amp;amp; mask) != 0)
    .collect::&amp;lt;Vec&amp;lt;_&amp;gt;&amp;gt;();

println!("Scanning {} memory regions", regions.len());

regions.into_iter().for_each(|region| {
    match process.read_memory(region.BaseAddress as _, region.RegionSize) {
        Ok(memory) =&amp;gt; todo!(),
        Err(err) =&amp;gt; eprintln!(
            "Failed to read {} bytes at {:?}: {}",
            region.RegionSize, region.BaseAddress, err,
        ),
    }
})
&lt;/code>&lt;/pre>&lt;p>All that's left is for us to scan for a target value. To do this, we want to iterate over all the &lt;a href="https://doc.rust-lang.org/stable/std/primitive.slice.html#method.windows">&lt;code>slice::windows&lt;/code>&lt;/a> of size equal to the size of our scan type.&lt;/p>&lt;pre>&lt;code class="language-rust">let target: i32 = ...;
let target = target.to_ne_bytes();

// -snip-

// inside the Ok match, replacing the todo!() -- this is where the first scan happens
Ok(memory) =&amp;gt; memory
    .windows(target.len())
    .enumerate()
    .for_each(|(offset, window)| {
        if window == target {
            println!(
                "Found exact value at [{:?}+{:x}]",
                region.BaseAddress, offset
            );
        }
    })
&lt;/code>&lt;/pre>&lt;p>We convert the 32-bit exact target value to its memory representation as a byte array in &lt;a href="https://doc.rust-lang.org/stable/std/primitive.i32.html#method.to_ne_bytes">native byte order&lt;/a>. This way we can compare the target bytes with the window bytes. Another option is to interpret the window bytes as an &lt;code>i32&lt;/code> with &lt;code>from_be_bytes&lt;/code>, but &lt;code>slice::windows&lt;/code> gives us slices of type &lt;code>&amp;amp;[u8]&lt;/code>, and &lt;code>from_be_bytes&lt;/code> wants an &lt;code>[u8; 4]&lt;/code> array, so it's a bit more annoying to convert.&lt;/p>&lt;p>This is enough to find the value in the process' memory!&lt;/p>&lt;pre>Found exact value at [0x10000+aec]
Failed to read 12288 bytes at 0x13f8000: Only part of a ReadProcessMemory or WriteProcessMemory request was completed. (os error 299)
Found exact value at [0x14f0000+3188]
Found exact value at [0x14f0000+ac74]
...
Found exact value at [0x10030e000+1816]
Found exact value at [0x7ff8f7b93000+441a]
...
Found exact value at [0x7ff8fb381000+4023]
&lt;/pre>&lt;p>The tutorial starts out with health "100", which is what I scanned. Apparently, there are nearly a hundred of &lt;code>100&lt;/code>-valued integers stored in the memory of the tutorial.&lt;/p>&lt;p>Attentive readers will notice that some values are located at an offset modulo 4. In Cheat Engine, this is known as "Fast Scan", which is enabled by default with an alignment of 4. Most of the time, values are aligned in memory, and this alignment often corresponds with the size of the type itself. For 4-byte integers, it's common that they're 4-byte aligned.&lt;/p>&lt;p>We can perform a fast scan ourselves with &lt;a href="https://doc.rust-lang.org/stable/std/iter/trait.Iterator.html#method.step_by">&lt;code>step_by&lt;/code>&lt;/a>&lt;a href="#fn:5">&lt;sup id="fnref:5">↪5&lt;/sup>&lt;/a>:&lt;/p>&lt;pre>&lt;code class="language-rust">memory
    .windows(target.len())
    .enumerate()
    .step_by(4)
    .for_each(...)
&lt;/code>&lt;/pre>&lt;p>As a bonus, over half the addresses are gone, so we have less results to worry about&lt;a href="#fn:6">&lt;sup id="fnref:6">↪6&lt;/sup>&lt;/a>.&lt;/p>&lt;h2 id="next-scan">&lt;a href="#next-scan">Next Scan&lt;/a>&lt;/h2>&lt;p>The first scan gave us way too many results. We have no way to tell which is the correct one, as they all have the same value. What we need to do is a &lt;em>second&lt;/em> scan at the &lt;em>locations we just found&lt;/em>. This way, we can get a second reading, and compare it against a new value. If it's the same, we're on good track, and if not, we can discard a location. Repeating this process lets us cut the hundreds of potential addresses to just a handful of them.&lt;/p>&lt;p>For example, let's say we're scanning our current health of &lt;code>100&lt;/code> in a game. This gives us over a hundred addresses that point to the value of &lt;code>100&lt;/code>. If we go in-game and get hit&lt;a href="#fn:7">&lt;sup id="fnref:7">↪7&lt;/sup>&lt;/a> by some enemy and get our health down to, say, &lt;code>99&lt;/code> (we have a lot of defense), we can then read the memory at the hundred memory locations we found before. If this second reading is not &lt;code>99&lt;/code>, we know the address does not actually point to our health pool and it just happened to also contain a &lt;code>100&lt;/code> on the first scan. This address can be removed from the list of potential addresses pointing to our health.&lt;/p>&lt;p>Let's do that:&lt;/p>&lt;pre>&lt;code class="language-rust">// new vector to hold the locations, before getting into `memory.windows`' for-each
let mut locations = Vec::with_capacity(regions.len());

// -snip-

// updating the `println!("Found exact value...")` to store the location instead.
if window == target {
    locations.push(region.BaseAddress as usize + offset);
}

// -snip-

// performing a second scan on the locations the first scan found.
let target: i32 = ...;
let target = target.to_ne_bytes();
locations.retain(|addr| match process.read_memory(*addr, target.len()) {
    Ok(memory) =&amp;gt; memory == target,
    Err(_) =&amp;gt; false,
});

println!("Now have {} locations", locations.len());
&lt;/code>&lt;/pre>&lt;p>We create a vector to store all the locations the first scan finds, and then retain those that match a second target value. You may have noticed that we perform a memory read, and thus a call to the Windows API, for every single address. With a hundred locations to read from, this is not a big deal, but oftentimes you will have tens of thousands of addresses. For the time being, we will not worry about this inefficiency, but we will get back to it once it matters:&lt;/p>&lt;pre>Scanning 98 memory regions
Which exact value to scan for?: 100
Failed to read 12288 bytes at 0x13f8000: Only part of a ReadProcessMemory or WriteProcessMemory request was completed. (os error 299)
...
Found 49 locations
Which exact value to scan for next?: 99
Now have 1 locations
&lt;/pre>&lt;p>Sweet! In a real-world scenario, you will likely need to perform these additional scans a couple of times, and even then, there may be more than one value left no matter what.&lt;/p>&lt;p>For good measure, we'll wrap our &lt;code>retain&lt;/code> in a &lt;code>while&lt;/code> loop&lt;a href="#fn:8">&lt;sup id="fnref:8">↪8&lt;/sup>&lt;/a>:&lt;/p>&lt;pre>&lt;code class="language-rust">while locations.len() != 1 {
    let target: i32 = ...;
    let target = target.to_ne_bytes();
    locations.retain(...);
}
&lt;/code>&lt;/pre>&lt;h2 id="modifying-memory">&lt;a href="#modifying-memory">Modifying memory&lt;/a>&lt;/h2>&lt;p>Now that we have very likely locations pointing to our current health in memory, all that's left is writing our new desired value to gain infinite health&lt;a href="#fn:9">&lt;sup id="fnref:9">↪9&lt;/sup>&lt;/a>. Much like how we're able to read memory with &lt;code>ReadProcessMemory&lt;/code>, we can write to it with &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/memoryapi/nf-memoryapi-writeprocessmemory">&lt;code>WriteProcessMemory&lt;/code>&lt;/a>. Its usage is straightforward:&lt;/p>&lt;pre>&lt;code class="language-rust">pub fn write_memory(&amp;amp;self, addr: usize, value: &amp;amp;[u8]) -&amp;gt; io::Result&amp;lt;usize&amp;gt; {
    let mut written = 0;

    // SAFETY: the input value buffer points to valid memory.
    if unsafe {
        winapi::um::memoryapi::WriteProcessMemory(
            self.handle.as_ptr(),
            addr as *mut _,
            value.as_ptr().cast(),
            value.len(),
            &amp;amp;mut written,
        )
    } == FALSE
    {
        Err(io::Error::last_os_error())
    } else {
        Ok(written)
    }
}
&lt;/code>&lt;/pre>&lt;p>Similar to how writing to a file can return short, writing to a memory location could also return short. Here we mimic the API for writing files and return the number of bytes written. The documentation indicates that we could actually ignore the amount written by passing &lt;code>ptr::null_mut()&lt;/code> as the last parameter, but it does no harm to retrieve the written count as well.&lt;/p>&lt;pre>&lt;code class="language-rust">let new_value: i32 = ...;
locations
    .into_iter()
    .for_each(|addr| match process.write_memory(addr, &amp;amp;new_value) {
        Ok(n) =&amp;gt; eprintln!("Written {} bytes to [{:x}]", n, addr),
        Err(e) =&amp;gt; eprintln!("Failed to write to [{:x}]: {}", addr, e),
    });
&lt;/code>&lt;/pre>&lt;p>And just like that:&lt;/p>&lt;pre>Now have 1 location(s)
Enter new memory value: 1000
Failed to write to [15d8b90]: Access is denied. (os error 5)
&lt;/pre>&lt;p>…oh noes. Oh yeah. The documentation, which I totally didn't forget to read, mentions:&lt;/p>&lt;blockquote>&lt;p>The handle must have &lt;code>PROCESS_VM_WRITE&lt;/code> and &lt;code>PROCESS_VM_OPERATION&lt;/code> access to the process.&lt;/p>&lt;/blockquote>&lt;p>We currently open our process with &lt;code>PROCESS_QUERY_INFORMATION&lt;/code> and &lt;code>PROCESS_VM_READ&lt;/code>, which is enough for reading, but not for writing. Let's adjust &lt;code>OpenProcess&lt;/code> to accomodate for our new requirements:&lt;/p>&lt;pre>&lt;code class="language-rust">winapi::um::processthreadsapi::OpenProcess(
    winnt::PROCESS_QUERY_INFORMATION
        | winnt::PROCESS_VM_READ
        | winnt::PROCESS_VM_WRITE
        | winnt::PROCESS_VM_OPERATION,
    FALSE,
    pid,
)
&lt;/code>&lt;/pre>&lt;p>Behold:&lt;/p>&lt;pre>Now have 1 location(s)
Enter new memory value: 1000
Written 4 bytes to [15d8b90]
&lt;/pre>&lt;p>&lt;img src="https://user-images.githubusercontent.com/6297805/107829541-3f4f2d00-6d8a-11eb-87c4-e2f2d505afbc.png" alt="Tutorial complete with memo">&lt;/p>&lt;p>Isn't that active &lt;em>Next&lt;/em> button just beautiful?&lt;/p>&lt;h2 id="finale">&lt;a href="#finale">Finale&lt;/a>&lt;/h2>&lt;p>This post somehow ended up being longer than part one, but look at what we've achieved! We completed a step of the Cheat Engine Tutorial &lt;em>without using Cheat Engine&lt;/em>. Just pure Rust. Figuring out how a program works and reimplementing it yourself is a great way to learn what it's doing behind the scenes. And now that this code is yours, you can extend it as much as you like, without being constrained by Cheat Engine's UI. You can automate it as much as you want.&lt;/p>&lt;p>And we're not even done. The current tutorial has nine steps, and three additional graphical levels.&lt;/p>&lt;p>In the &lt;a href="/blog/woce-3">next post&lt;/a>, we'll tackle the third step of the tutorial: Unknown initial value. This will pose a challenge, because with just 2 MiB of memory, storing all the 4-byte aligned locations would require 524288 addresses (&lt;code>usize&lt;/code>, 8 bytes). This adds up to twice as much memory as the original program (4 MiB), but that's not our main concern, having to perform over five hundred thousand API calls is!&lt;/p>&lt;p>Remember that you can &lt;a href="https://github.com/lonami/memo">obtain the code for this post&lt;/a> over at my GitHub. You can run &lt;code>git checkout step2&lt;/code> after cloning the repository to get the right version of the code.&lt;/p>&lt;h3 id="footnotes">&lt;a href="#footnotes">Footnotes&lt;/a>&lt;/h3>&lt;p id="fn:1" class="footnote-definition">&lt;span>1&lt;/span> I did in fact use an online tool to spell it out for me.&amp;nbsp;&lt;a href="#fnref:1">↩&lt;/a>&lt;/p>&lt;p id="fn:2" class="footnote-definition">&lt;span>2&lt;/span> 16 GiB is good enough for my needs. I don't think I'll ever upgrade to 16 EiB.&amp;nbsp;&lt;a href="#fnref:2">↩&lt;/a>&lt;/p>&lt;p id="fn:3" class="footnote-definition">&lt;span>3&lt;/span> Every address we query should have a corresponding region, even if it's not allocated or we do not have access. This is why we can query for the memory address zero to get its corresponding region.&amp;nbsp;&lt;a href="#fnref:3">↩&lt;/a>&lt;/p>&lt;p id="fn:4" class="footnote-definition">&lt;span>4&lt;/span> Another option is to &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/sysinfoapi/nf-sysinfoapi-getsysteminfo">&lt;code>GetSystemInfo&lt;/code>&lt;/a> to determine the &lt;code>lpMinimumApplicationAddress&lt;/code> and &lt;code>lpMaximumApplicationAddress&lt;/code> and only work within bounds.&amp;nbsp;&lt;a href="#fnref:4">↩&lt;/a>&lt;/p>&lt;p id="fn:5" class="footnote-definition">&lt;span>5&lt;/span> Memory regions are page-aligned, which is a large power of two. Our alignment of 4 is much lower than this, so we're guaranteed to start off at an aligned address.&amp;nbsp;&lt;a href="#fnref:5">↩&lt;/a>&lt;/p>&lt;p id="fn:6" class="footnote-definition">&lt;span>6&lt;/span> If it turns out that the value was actually misaligned, we will miss it. You will notice this if, after going through the whole process, there are no results. It could mean that either the value type is wrong, or the value type is misaligned. In the worst case, the value is not stored directly but is rather computed with something like &lt;code>maximum - stored&lt;/code>, or XORed with some magic value, or a myriad other things.&amp;nbsp;&lt;a href="#fnref:6">↩&lt;/a>&lt;/p>&lt;p id="fn:7" class="footnote-definition">&lt;span>7&lt;/span> You could do this without getting hit, and just keep on repeating the scan for the same value over and over again. This does work, but the results are suboptimal, because there are also many other values that didn't change. Scanning for a changed value is a better option.&amp;nbsp;&lt;a href="#fnref:7">↩&lt;/a>&lt;/p>&lt;p id="fn:8" class="footnote-definition">&lt;span>8&lt;/span> You could actually just go ahead and try to modify the memory at the hundred addresses you just found, although don't be surprised if the program starts to misbehave!&amp;nbsp;&lt;a href="#fnref:8">↩&lt;/a>&lt;/p>&lt;p id="fn:9" class="footnote-definition">&lt;span>9&lt;/span> Okay, we cannot fit infinity in an &lt;code>i32&lt;/code>. However, we can fit sufficiently large numbers. Like &lt;code>1000&lt;/code>, which is enough to complete the tutorial.&amp;nbsp;&lt;a href="#fnref:9">↩&lt;/a>&lt;/p></content></entry><entry xml:lang="en"><title>Writing our own Cheat Engine: Introduction</title><published>2021-02-07T00:00:00+00:00</published><updated>2021-02-19T00:00:00+00:00</updated><link href="https://lonami.dev/blog/woce-1/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/woce-1/</id><content type="html">&lt;p>This is part 1 on the &lt;em>Writing our own Cheat Engine&lt;/em> series:&lt;/p>&lt;ul>&lt;li>Part 1: Introduction&lt;/li>&lt;li>&lt;a href="/blog/woce-2">Part 2: Exact Value scanning&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-3">Part 3: Unknown initial value&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-4">Part 4: Floating points&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-5">Part 5: Code finder&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-6">Part 6: Pointers&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-7">Part 7: Code Injection&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/woce-8">Part 8: Multilevel pointers&lt;/a>&lt;/li>&lt;/ul>&lt;p>&lt;a href="https://cheatengine.org/">Cheat Engine&lt;/a> is a tool designed to modify single player games and contains other useful tools within itself that enable its users to debug games or other applications. It comes with a memory scanner, (dis)assembler, inspection tools and a handful other things. In this series, we will be writing our own tiny Cheat Engine capable of solving all steps of the tutorial, and diving into how it all works underneath.&lt;/p>&lt;p>Needless to say, we're doing this for private and educational purposes only. One has to make sure to not violate the EULA or ToS of the specific application we're attaching to. This series, much like cheatengine.org, does not condone the illegal use of the code shared.&lt;/p>&lt;p>Cheat Engine is a tool for Windows, so we will be developing for Windows as well. However, you can also &lt;a href="https://stackoverflow.com/q/12977179/4759433">read memory from Linux-like systems&lt;/a>. &lt;a href="https://github.com/scanmem/scanmem">GameConqueror&lt;/a> is a popular alternative to Cheat Engine on Linux systems, so if you feel adventurous, you could definitely follow along too! The techniques shown in this series apply regardless of how we read memory from a process. You will learn a fair bit about doing FFI in Rust too.&lt;/p>&lt;p>We will be developing the application in Rust, because it enables us to interface with the Windows API easily, is memory safe (as long as we're careful with &lt;code>unsafe&lt;/code>!), and is speedy (we will need this for later steps in the Cheat Engine tutorial). You could use any language of your choice though. For example, &lt;a href="https://lonami.dev/blog/ctypes-and-windows/">Python also makes it relatively easy to use the Windows API&lt;/a>. You don't need to be a Rust expert to follow along, but this series assumes some familiarity with C-family languages. Slightly advanced concepts like the use of &lt;code>unsafe&lt;/code> or the &lt;code>MaybeUninit&lt;/code> type will be briefly explained. What a &lt;code>fn&lt;/code> is or what &lt;code>let&lt;/code> does will not be explained.&lt;/p>&lt;p>&lt;a href="https://github.com/cheat-engine/cheat-engine/">Cheat Engine's source code&lt;/a> is mostly written in Pascal and C. And it's &lt;em>a lot&lt;/em> of code, with a very flat project structure, and files ranging in the thousand lines of code each. It's daunting&lt;a href="#fn:1">&lt;sup id="fnref:1">↪1&lt;/sup>&lt;/a>. It's a mature project, with a lot of knowledge encoded in the code base, and a lot of features like distributed scanning or an entire disassembler. Unfortunately, there's not a lot of comments. For these reasons, I'll do some guesswork when possible as to how it's working underneath, rather than actually digging into what Cheat Engine is actually doing.&lt;/p>&lt;p>With that out of the way, let's get started!&lt;/p>&lt;h2 id="welcome-to-the-cheat-engine-tutorial">&lt;a href="#welcome-to-the-cheat-engine-tutorial">Welcome to the Cheat Engine Tutorial&lt;/a>&lt;/h2>&lt;details open>&lt;summary>Cheat Engine Tutorial: Step 1&lt;/summary>&lt;blockquote>&lt;p>This tutorial will teach you the basics of cheating in video games. It will also show you foundational aspects of using Cheat Engine (or CE for short). Follow the steps below to get started.&lt;/p>&lt;ol>&lt;li>Open Cheat Engine if it currently isn't running.&lt;/li>&lt;li>Click on the "Open Process" icon (it's the top-left icon with the computer on it, below "File".).&lt;/li>&lt;li>With the Process List window now open, look for this tutorial's process in the list. It will look something like &amp;gt; "00001F98-Tutorial-x86_64.exe" or "0000047C-Tutorial-i386.exe". (The first 8 numbers/letters will probably be different.)&lt;/li>&lt;li>Once you've found the process, click on it to select it, then click the "Open" button. (Don't worry about all the &amp;gt; other buttons right now. You can learn about them later if you're interested.)&lt;/li>&lt;/ol>&lt;p>Congratulations! If you did everything correctly, the process window should be gone with Cheat Engine now attached to the &amp;gt; tutorial (you will see the process name towards the top-center of CE).&lt;/p>&lt;p>Click the "Next" button below to continue, or fill in the password and click the "OK" button to proceed to that step.)&lt;/p>&lt;p>If you're having problems, simply head over to forum.cheatengine.org, then click on "Tutorials" to view beginner-friendly &amp;gt; guides!&lt;/p>&lt;/blockquote>&lt;/details>&lt;h2 id="enumerating-processes">&lt;a href="#enumerating-processes">Enumerating processes&lt;/a>&lt;/h2>&lt;p>Our first step is attaching to the process we want to work with. But we need a way to find that process in the first place! Having to open the task manager, look for the process we care about, noting down the process ID (PID), and slapping it in the source code is not satisfying at all. Instead, let's enumerate all the processes from within the program, and let the user select one by typing its name.&lt;/p>&lt;p>From a quick &lt;a href="https://ddg.gg/winapi%20enumerate%20all%20processes">DuckDuckGo search&lt;/a>, we find an official tutorial for &lt;a href="https://docs.microsoft.com/en-us/windows/win32/psapi/enumerating-all-processes">Enumerating All Processes&lt;/a>, which leads to the &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/psapi/nf-psapi-enumprocesses">&lt;code>EnumProcesses&lt;/code>&lt;/a> call. Cool! Let's slap in the &lt;a href="https://crates.io/crates/winapi">&lt;code>winapi&lt;/code>&lt;/a> crate on &lt;code>Cargo.toml&lt;/code>, because I don't want to write all the definitions by myself:&lt;/p>&lt;pre>&lt;code class="language-toml">[dependencies]
winapi = { version = "0.3.9", features = ["psapi"] }
&lt;/code>&lt;/pre>&lt;p>Because &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/psapi/nf-psapi-enumprocesses">&lt;code>EnumProcesses&lt;/code>&lt;/a> is in &lt;code>Psapi.h&lt;/code> (you can see this in the online page of its documentation), we know we'll need the &lt;code>psapi&lt;/code> crate feature. Another option is to search for it in the &lt;a href="https://docs.rs/winapi/">&lt;code>winapi&lt;/code> documentation&lt;/a> and noting down the parent module where its stored.&lt;/p>&lt;p>The documentation for the method has the following remark:&lt;/p>&lt;blockquote>&lt;p>It is a good idea to use a large array, because it is hard to predict how many processes there will be at the time you call &lt;strong>EnumProcesses&lt;/strong>.&lt;/p>&lt;/blockquote>&lt;p>&lt;em>Sidenote: reading the documentation for the methods we'll use from the Windows API is extremely important. There's a lot of gotchas involved, so we need to make sure we're extra careful.&lt;/em>&lt;/p>&lt;p>1024 is a pretty big number, so let's go with that:&lt;/p>&lt;pre>&lt;code class="language-rust">use std::io;
use std::mem;
use winapi::shared::minwindef::{DWORD, FALSE};

pub fn enum_proc() -&amp;gt; io::Result&amp;lt;Vec&amp;lt;u32&amp;gt;&amp;gt; {
    let mut pids = Vec::&amp;lt;DWORD&amp;gt;::with_capacity(1024);
    let mut size = 0;
    // SAFETY: the pointer is valid and the size matches the capacity.
    if unsafe {
        winapi::um::psapi::EnumProcesses(
            pids.as_mut_ptr(),
            (pids.capacity() * mem::size_of::&amp;lt;DWORD&amp;gt;()) as u32,
            &amp;amp;mut size,
        )
    } == FALSE
    {
        return Err(io::Error::last_os_error());
    }

    todo!()
}
&lt;/code>&lt;/pre>&lt;p>We allocate enough space&lt;a href="#fn:2">&lt;sup id="fnref:2">↪2&lt;/sup>&lt;/a> for 1024 &lt;code>pids&lt;/code> in a vector&lt;a href="#fn:3">&lt;sup id="fnref:3">↪3&lt;/sup>&lt;/a>, and pass a mutable pointer to the contents to &lt;code>EnumProcesses&lt;/code>. Note that the size of the array is in &lt;em>bytes&lt;/em>, not items, so we need to multiply the capacity by the size of &lt;code>DWORD&lt;/code>. The API likes to use &lt;code>u32&lt;/code> for sizes, unlike Rust which uses &lt;code>usize&lt;/code>, so we need a cast.&lt;/p>&lt;p>Last, we need another mutable variable where the amount of bytes written is stored, &lt;code>size&lt;/code>.&lt;/p>&lt;blockquote>&lt;p>If the function fails, the return value is zero. To get extended error information, call &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/errhandlingapi/nf-errhandlingapi-getlasterror">&lt;code>GetLastError&lt;/code>&lt;/a>.&lt;/p>&lt;/blockquote>&lt;p>That's precisely what we do. If it returns false (zero), we return the last OS error. Rust provides us with &lt;a href="https://doc.rust-lang.org/stable/std/io/struct.Error.html#method.last_os_error">&lt;code>std::io::Error::last_os_error&lt;/code>&lt;/a>, which essentially makes that same call but returns a proper &lt;code>io::Error&lt;/code> instance. Cool!&lt;/p>&lt;blockquote>&lt;p>To determine how many processes were enumerated, divide the &lt;em>lpcbNeeded&lt;/em> value by &lt;code>sizeof(DWORD)&lt;/code>.&lt;/p>&lt;/blockquote>&lt;p>Easy enough:&lt;/p>&lt;pre>&lt;code class="language-rust">let count = size as usize / mem::size_of::&amp;lt;DWORD&amp;gt;();
// SAFETY: the call succeeded and count equals the right amount of items.
unsafe { pids.set_len(count) };
Ok(pids)
&lt;/code>&lt;/pre>&lt;p>Rust doesn't know that the memory for &lt;code>count&lt;/code> items were initialized by the call, but we do, so we make use of the &lt;a href="https://doc.rust-lang.org/stable/std/vec/struct.Vec.html#method.set_len">&lt;code>Vec::set_len&lt;/code>&lt;/a> call to indicate this. The Rust documentation even includes a FFI similar to our code!&lt;/p>&lt;p>Let's give it a ride:&lt;/p>&lt;pre>&lt;code class="language-rust">fn main() {
    dbg!(enum_proc().unwrap().len());
}
&lt;/code>&lt;/pre>&lt;pre>&amp;gt;cargo run
   Compiling memo v0.1.0
    Finished dev [unoptimized + debuginfo] target(s) in 0.20s
     Running `target\debug\memo.exe`
[src\main.rs:27] enum_proc().unwrap().len() = 178
&lt;/pre>&lt;p>It works! But currently we only have a bunch of process identifiers, with no way of knowing which process they refer to.&lt;/p>&lt;blockquote>&lt;p>To obtain process handles for the processes whose identifiers you have just obtained, call the &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-openprocess">&lt;code>OpenProcess&lt;/code>&lt;/a> function.&lt;/p>&lt;/blockquote>&lt;p>Oh!&lt;/p>&lt;h2 id="opening-a-process">&lt;a href="#opening-a-process">Opening a process&lt;/a>&lt;/h2>&lt;p>The documentation for &lt;code>OpenProcess&lt;/code> also contains the following:&lt;/p>&lt;blockquote>&lt;p>When you are finished with the handle, be sure to close it using the &lt;a href="closehandle">&lt;code>CloseHandle&lt;/code>&lt;/a> function.&lt;/p>&lt;/blockquote>&lt;p>This sounds to me like the perfect time to introduce a custom &lt;code>struct Process&lt;/code> with an &lt;code>impl Drop&lt;/code>! We're using &lt;code>Drop&lt;/code> to cleanup resources, not behaviour, so it's fine. &lt;a href="https://internals.rust-lang.org/t/pre-rfc-leave-auto-trait-for-reliable-destruction/13825">Using &lt;code>Drop&lt;/code> to cleanup behaviour is a bad idea&lt;/a>. But anyway, let's get back to the code:&lt;/p>&lt;pre>&lt;code class="language-rust">use std::ptr::NonNull;
use winapi::ctypes::c_void;

pub struct Process {
    pid: u32,
    handle: NonNull&amp;lt;c_void&amp;gt;,
}

impl Process {
    pub fn open(pid: u32) -&amp;gt; io::Result&amp;lt;Self&amp;gt; {
        todo!()
    }
}

impl Drop for Process {
    fn drop(&amp;amp;mut self) {
        todo!()
    }
}
&lt;/code>&lt;/pre>&lt;p>For &lt;code>open&lt;/code>, we'll want to use &lt;code>OpenProcess&lt;/code> (and we also need to add the &lt;code>processthreadsapi&lt;/code> feature to the &lt;code>winapi&lt;/code> dependency in &lt;code>Cargo.toml&lt;/code>). It returns a &lt;code>HANDLE&lt;/code>, which is a nullable mutable pointer to &lt;code>c_void&lt;/code>. If it's null, the call failed, and if it's non-null, it succeeded and we have a valid handle. This is why we use Rust's &lt;a href="https://doc.rust-lang.org/stable/std/ptr/struct.NonNull.html">&lt;code>NonNull&lt;/code>&lt;/a>:&lt;/p>&lt;pre>&lt;code class="language-rust">// SAFETY: the call doesn't have dangerous side-effects.
NonNull::new(unsafe { winapi::um::processthreadsapi::OpenProcess(0, FALSE, pid) })
    .map(|handle| Self { pid, handle })
    .ok_or_else(io::Error::last_os_error)
&lt;/code>&lt;/pre>&lt;p>&lt;code>NonNull&lt;/code> will return &lt;code>Some&lt;/code> if the pointer is non-null. We map the non-null pointer to a &lt;code>Process&lt;/code> instance with &lt;code>Self { .. }&lt;/code>. &lt;code>ok_or_else&lt;/code> converts the &lt;code>Option&lt;/code> to a &lt;code>Result&lt;/code> with the error builder function we provide if it was &lt;code>None&lt;/code>.&lt;/p>&lt;p>The first parameter is a bitflag of permissions we want to have. For now, we can leave it as zero (all bits unset, no specific permissions granted). The second one is whether we want to inherit the handle, which we don't, and the third one is the process identifier. Let's close the resource handle on &lt;code>Drop&lt;/code> (after adding &lt;code>handleapi&lt;/code> to the crate features):&lt;/p>&lt;pre>&lt;code class="language-rust">// SAFETY: the handle is valid and non-null.
unsafe { winapi::um::handleapi::CloseHandle(self.handle.as_mut()) };
&lt;/code>&lt;/pre>&lt;p>&lt;code>CloseHandle&lt;/code> can actually fail (for example, on double-close), but given our invariants, it won't. You could add an &lt;code>assert!&lt;/code> to panic if this is not the case.&lt;/p>&lt;p>We can now open processes, and they will be automatically closed on &lt;code>Drop&lt;/code>. Does any of this work though?&lt;/p>&lt;pre>&lt;code class="language-rust">fn main() {
    let mut success = 0;
    let mut failed = 0;
    enum_proc().unwrap().into_iter().for_each(|pid| match Process::open(pid) {
        Ok(_) =&amp;gt; success += 1,
        Err(_) =&amp;gt; failed += 1,
    });

    eprintln!("Successfully opened {}/{} processes", success, success + failed);
}
&lt;/code>&lt;/pre>&lt;pre>&amp;gt;cargo run
   Compiling memo v0.1.0
    Finished dev [unoptimized + debuginfo] target(s) in 0.36s
     Running `target\debug\memo.exe`
Successfully opened 0/191 processes
&lt;/pre>&lt;p>…nope. Maybe the documentation for &lt;code>OpenProcess&lt;/code> says something?&lt;/p>&lt;blockquote>&lt;p>&lt;code>dwDesiredAccess&lt;/code>&lt;/p>&lt;p>The access to the process object. This access right is checked against the security descriptor for the process. This parameter can be &lt;strong>one or more&lt;/strong> of the process access rights.&lt;/p>&lt;/blockquote>&lt;p>One or more, but we're setting zero permissions. I told you, reading the documentation is important&lt;a href="#fn:4">&lt;sup id="fnref:4">↪4&lt;/sup>&lt;/a>! The &lt;a href="https://docs.microsoft.com/en-us/windows/win32/procthread/process-security-and-access-rights">Process Security and Access Rights&lt;/a> page lists all possible values we could use. &lt;code>PROCESS_QUERY_INFORMATION&lt;/code> seems to be appropriated:&lt;/p>&lt;blockquote>&lt;p>Required to retrieve certain information about a process, such as its token, exit code, and priority class&lt;/p>&lt;/blockquote>&lt;pre>&lt;code class="language-rust">OpenProcess(winapi::um::winnt::PROCESS_QUERY_INFORMATION, ...)
&lt;/code>&lt;/pre>&lt;p>Does this fix it?&lt;/p>&lt;pre>&lt;code class="language-rust">&amp;gt;cargo run
   Compiling memo v0.1.0
    Finished dev [unoptimized + debuginfo] target(s) in 0.36s
     Running `target\debug\memo.exe`
Successfully opened 69/188 processes
&lt;/code>&lt;/pre>&lt;p>&lt;em>Nice&lt;/em>. It does solve it. But why did we only open 69 processes out of 188? Does it help if we run our code as administrator? Let's search for &lt;code>cmd&lt;/code> in the Windows menu and right click to Run as administrator, then &lt;code>cd&lt;/code> into our project and try again:&lt;/p>&lt;pre>&amp;gt;cargo run
    Finished dev [unoptimized + debuginfo] target(s) in 0.01s
     Running `target\debug\memo.exe`
Successfully opened 77/190 processes
&lt;/pre>&lt;p>We're able to open a few more, so it does help. In general, we'll want to run as administrator, so normal programs can't sniff on what we're doing, and so that we have permission to do more things.&lt;/p>&lt;h2 id="getting-the-name-of-a-process">&lt;a href="#getting-the-name-of-a-process">Getting the name of a process&lt;/a>&lt;/h2>&lt;p>We're not done enumerating things just yet. To get the "name" of a process, we need to enumerate the modules that it has loaded, and only then can we get the module base name. The first module is the program itself, so we don't need to enumerate &lt;em>all&lt;/em> modules, just the one is enough.&lt;/p>&lt;p>For this we want &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/psapi/nf-psapi-enumprocessmodules">&lt;code>EnumProcessModules&lt;/code>&lt;/a> and &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/psapi/nf-psapi-getmodulebasenamea">&lt;code>GetModuleBaseNameA&lt;/code>&lt;/a>. I'm using the ASCII variant of &lt;code>GetModuleBaseName&lt;/code> because I'm too lazy to deal with UTF-16 of the &lt;code>W&lt;/code> (wide, unicode) variants.&lt;/p>&lt;pre>&lt;code class="language-rust">use std::mem::MaybeUninit;
use winapi::shared::minwindef::HMODULE;

pub fn name(&amp;amp;self) -&amp;gt; io::Result&amp;lt;String&amp;gt; {
    let mut module = MaybeUninit::&amp;lt;HMODULE&amp;gt;::uninit();
    let mut size = 0;
    // SAFETY: the pointer is valid and the size is correct.
    if unsafe {
        winapi::um::psapi::EnumProcessModules(
            self.handle.as_ptr(),
            module.as_mut_ptr(),
            mem::size_of::&amp;lt;HMODULE&amp;gt;() as u32,
            &amp;amp;mut size,
        )
    } == FALSE
    {
        return Err(io::Error::last_os_error());
    }

    // SAFETY: the call succeeded, so module is initialized.
    let module = unsafe { module.assume_init() };
    todo!()
}
&lt;/code>&lt;/pre>&lt;p>&lt;code>EnumProcessModules&lt;/code> takes a pointer to an array of &lt;code>HMODULE&lt;/code>. We could use a &lt;code>Vec&lt;/code> of capacity one to hold the single module, but in memory, a pointer a single item can be seen as a pointer to an array of items. &lt;code>MaybeUninit&lt;/code> helps us reserve enough memory for the one item we need.&lt;/p>&lt;p>With the module handle, we can retrieve its base name:&lt;/p>&lt;pre>&lt;code class="language-rust">let mut buffer = Vec::&amp;lt;u8&amp;gt;::with_capacity(64);
// SAFETY: the handle, module and buffer are all valid.
let length = unsafe {
    winapi::um::psapi::GetModuleBaseNameA(
        self.handle.as_ptr(),
        module,
        buffer.as_mut_ptr().cast(),
        buffer.capacity() as u32,
    )
};
if length == 0 {
    return Err(io::Error::last_os_error());
}

// SAFETY: the call succeeded and length represents bytes.
unsafe { buffer.set_len(length as usize) };
Ok(String::from_utf8(buffer).unwrap())
&lt;/code>&lt;/pre>&lt;p>Similar to how we did with &lt;code>EnumProcesses&lt;/code>, we create a buffer that will hold the ASCII string of the module's base name&lt;a href="#fn:5">&lt;sup id="fnref:5">↪5&lt;/sup>&lt;/a>. The call wants us to pass a pointer to a mutable buffer of &lt;code>i8&lt;/code>, but Rust's &lt;code>String::from_utf8&lt;/code> wants a &lt;code>Vec&amp;lt;u8&amp;gt;&lt;/code>, so instead we declare a buffer of &lt;code>u8&lt;/code> and &lt;code>.cast()&lt;/code> the pointer in the call. You could also do this with &lt;code>as _&lt;/code>, and Rust would infer the right type, but &lt;code>cast&lt;/code> is neat.&lt;/p>&lt;p>We &lt;code>unwrap&lt;/code> the creation of the UTF-8 string because the buffer should contain only ASCII characters (which are also valid UTF-8). We could use the &lt;code>unsafe&lt;/code> variant to create the string, but what if somehow it contains non-ASCII characters? The less &lt;code>unsafe&lt;/code>, the better.&lt;/p>&lt;p>Let's see it in action:&lt;/p>&lt;pre>&lt;code class="language-rust">fn main() {
    enum_proc()
        .unwrap()
        .into_iter()
        .for_each(|pid| match Process::open(pid) {
            Ok(proc) =&amp;gt; match proc.name() {
                Ok(name) =&amp;gt; println!("{}: {}", pid, name),
                Err(e) =&amp;gt; println!("{}: (failed to get name: {})", pid, e),
            },
            Err(e) =&amp;gt; eprintln!("failed to open {}: {}", pid, e),
        });
}
&lt;/code>&lt;/pre>&lt;pre>&amp;gt;cargo run
   Compiling memo v0.1.0
    Finished dev [unoptimized + debuginfo] target(s) in 0.32s
     Running `target\debug\memo.exe`
failed to open 0: The parameter is incorrect. (os error 87)
failed to open 4: Access is denied. (os error 5)
...
failed to open 5940: Access is denied. (os error 5)
5608: (failed to get name: Access is denied. (os error 5))
...
1704: (failed to get name: Access is denied. (os error 5))
failed to open 868: Access is denied. (os error 5)
...
&lt;/pre>&lt;p>That's not good. What's up with that? Maybe…&lt;/p>&lt;blockquote>&lt;p>The handle must have the &lt;code>PROCESS_QUERY_INFORMATION&lt;/code> and &lt;code>PROCESS_VM_READ&lt;/code> access rights.&lt;/p>&lt;/blockquote>&lt;p>…I should've read the documentation. Okay, fine:&lt;/p>&lt;pre>&lt;code class="language-rust">use winapi::um::winnt;
OpenProcess(winnt::PROCESS_QUERY_INFORMATION | winnt::PROCESS_VM_READ, ...)
&lt;/code>&lt;/pre>&lt;pre>&amp;gt;cargo run
   Compiling memo v0.1.0 (C:\Users\L\Desktop\memo)
    Finished dev [unoptimized + debuginfo] target(s) in 0.35s
     Running `target\debug\memo.exe`
failed to open 0: The parameter is incorrect. (os error 87)
failed to open 4: Access is denied. (os error 5)
...
9348: cheatengine-x86_64.exe
3288: Tutorial-x86_64.exe
8396: cmd.exe
4620: firefox.exe
7964: cargo.exe
10052: cargo.exe
5756: memo.exe
&lt;/pre>&lt;p>Hooray 🎉! There's some processes we can't open, but that's because they're system processes. Security works!&lt;/p>&lt;h2 id="finale">&lt;a href="#finale">Finale&lt;/a>&lt;/h2>&lt;p>That was a fairly long post when all we did was print a bunch of pids and their corresponding name. But in all fairness, we also laid out a good foundation for what's coming next.&lt;/p>&lt;p>You can &lt;a href="https://github.com/lonami/memo">obtain the code for this post&lt;/a> over at my GitHub. At the end of every post, the last commit will be tagged, so you can &lt;code>git checkout step1&lt;/code> to see the final code for any blog post.&lt;/p>&lt;p>In the &lt;a href="/blog/woce-2">next post&lt;/a>, we'll tackle the second step of the tutorial: Exact Value scanning.&lt;/p>&lt;h3 id="footnotes">&lt;a href="#footnotes">Footnotes&lt;/a>&lt;/h3>&lt;p id="fn:1" class="footnote-definition">&lt;span>1&lt;/span> You could say I simply love reinventing the wheel, which I do, but in this case, the codebase contains &lt;em>far&lt;/em> more features than we're interested in. The (apparent) lack of structure and documentation regarding the code, along with the unfortunate &lt;a href="https://github.com/cheat-engine/cheat-engine/issues/60">lack of license&lt;/a> for the source code, make it a no-go. There's a license, but I think that's for the distributed program itself.&amp;nbsp;&lt;a href="#fnref:1">↩&lt;/a>&lt;/p>&lt;p id="fn:2" class="footnote-definition">&lt;span>2&lt;/span> If it turns out that there are more than 1024 processes, our code will be unaware of those extra processes. The documentation suggests to perform the call again with a larger buffer if &lt;code>count == provided capacity&lt;/code>, but given I have under 200 processes on my system, it seems unlikely we'll reach this limit. If you're worried about hitting this limit, simply use a larger limit or retry with a larger vector.&amp;nbsp;&lt;a href="#fnref:2">↩&lt;/a>&lt;/p>&lt;p id="fn:3" class="footnote-definition">&lt;span>3&lt;/span> C code would likely use &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-globalalloc">&lt;code>GlobalAlloc&lt;/code>&lt;/a> here, but Rust's &lt;code>Vec&lt;/code> handles the allocation for us, making the code both simpler and more idiomatic. In general, if you see calls to &lt;code>GlobalAlloc&lt;/code> when porting some code to Rust, you can probably replace it with a &lt;code>Vec&lt;/code>.&amp;nbsp;&lt;a href="#fnref:3">↩&lt;/a>&lt;/p>&lt;p id="fn:4" class="footnote-definition">&lt;span>4&lt;/span> This will be a recurring theme.&amp;nbsp;&lt;a href="#fnref:4">↩&lt;/a>&lt;/p>&lt;p id="fn:5" class="footnote-definition">&lt;span>5&lt;/span> …and similar to &lt;code>EnumProcesses&lt;/code>, if the name doesn't fit in our buffer, the result will be truncated.&amp;nbsp;&lt;a href="#fnref:5">↩&lt;/a>&lt;/p></content></entry><entry xml:lang="en"><title>Data Mining, Warehousing and Information Retrieval</title><published>2020-07-03T00:00:00+00:00</published><updated>2020-07-03T00:00:00+00:00</updated><link href="https://lonami.dev/blog/university/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/university/</id><content type="html">&lt;p>During university, there were a few subjects where I had to write blog posts for (either as evaluable tasks or just for fun). I thought it was really fun and I wanted to preserve that work here, with the hopes it's interesting to someone.&lt;/p>&lt;p>The posts series were auto-generated from the original HTML files and manually anonymized later.&lt;/p>&lt;ul>&lt;li>&lt;a href="/blog/mdad">Data Mining and Data Warehousing&lt;/a>&lt;/li>&lt;li>&lt;a href="/blog/ribw">Information Retrieval and Web Search&lt;/a>&lt;/li>&lt;/ul></content></entry><entry xml:lang="en"><title>My new computer</title><published>2020-06-19T00:00:00+00:00</published><updated>2020-07-03T00:00:00+00:00</updated><link href="https://lonami.dev/blog/new-computer/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/new-computer/</id><content type="html">&lt;p>This post will be mostly me ranting about setting up a new laptop, but I also just want to share my upgrade. If you're considering installing Arch Linux with dual-boot for Windows, maybe this post will help. Or perhaps you will learn something new to troubleshoot systems in the future. Let's begin!&lt;/p>&lt;p>Last Sunday, I ordered a Asus Rog Strix G531GT-BQ165 for 900€ (on a 20% discount) with the following specifications:&lt;/p>&lt;ul>&lt;li>Intel® Core i7-9750H (6 cores, 12MB cache, 2.6GHz up to 4.5GHz, 64-bit)&lt;/li>&lt;li>16GB RAM (8GB*2) DDR4 2666MHz&lt;/li>&lt;li>512GB SSD M.2 PCIe® NVMe&lt;/li>&lt;li>Display 15.6" (1920x1080/16:9) 60Hz&lt;/li>&lt;li>Graphics NVIDIA® GeForce® GTX1650 4GB GDDR5 VRAM&lt;/li>&lt;li>LAN 10/100/1000&lt;/li>&lt;li>Wi-Fi 5 (802.11ac) 2x2 RangeBoost&lt;/li>&lt;li>Bluetooth 5.0&lt;/li>&lt;li>48Wh battery with 3 cells&lt;/li>&lt;li>3 x USB 3.1 (GEN1)&lt;/li>&lt;/ul>&lt;p>I was mostly interested in a general upgrade (better processor, disk, more RAM), although the graphics card is a really nice addition which will allow me to take some time off on more games. After using it for a bit, I really love the feel of the keyboard, and I love the lack of numpad! (No sarcasm, I really don't like numpads.)&lt;/p>&lt;p>This is an upgrade from my previous laptop (Asus X554LA-XX822T), which I won in a competition before entering university in a programming challenge. It has served me really well for the past five years, and had the following specifications:&lt;/p>&lt;ul>&lt;li>Intel® Core™ i5-5200U&lt;/li>&lt;li>4GB RAM DDR3L 1600MHz (which I upgraded to have 8GB)&lt;/li>&lt;li>1TB HDD&lt;/li>&lt;li>Display 15.6" (1366x768/16:9)&lt;/li>&lt;li>Intel® HD Graphics 4400&lt;/li>&lt;li>LAN 10/100/1000&lt;/li>&lt;li>Wifi 802.11 bgn&lt;/li>&lt;li>Bluetooth 4.0&lt;/li>&lt;li>Battery 2 cells&lt;/li>&lt;li>1 x USB 2.0&lt;/li>&lt;li>2 x USB 3.0&lt;/li>&lt;/ul>&lt;p>Prior to this one, I had a Lenovo (also won in the same competition of the previous year), and prior to that (just for the sake of history), it was HP Pavilion, AMD A4-3300M processor, which unfortunately ended with heating problems. But that's very old now.&lt;/p>&lt;h2 id="laptop-arrival">&lt;a href="#laptop-arrival">Laptop arrival&lt;/a>&lt;/h2>&lt;p>The laptop arrived 2 days ago at roughly 19:00, which I put charged for 3 hours as the book said. The day after, nightmares began!&lt;/p>&lt;p>Trying to boot it the first two times was fun, as it comes with a somewhat loud sound on boot. I don't know why they would do this, and I immediately turned it off in the BIOS.&lt;/p>&lt;h2 id="installation-journey">&lt;a href="#installation-journey">Installation journey&lt;/a>&lt;/h2>&lt;p>I spent all of yesterday trying to setup Windows and Arch Linux (and didn't even finish, it took me this morning too and even now it's only half functional). I absolutely &lt;em>hate&lt;/em> the amount of partitions the Windows installer creates on a clean disk. So instead, I first went with Arch Linux, and followed the &lt;a href="https://wiki.archlinux.org/index.php/Installation_guide">installation guide on the Arch wiki&lt;/a>. Pre-installation, setting up the wireless network, creating the partitions and formatting them went all good. I decided to avoid GRUB at first and go with rEFInd, but alas I missed a big warning on the wiki and after reboot (I would later find out) it was not mounting root properly, so all I had was whatever was in the Initramfs. Reboot didn't work, so I had to hold the power button.&lt;/p>&lt;p>Anyway, once the partitions were created, I went to install Windows (there was a lot of back and forth burning different &lt;code>.iso&lt;/code> images on the USB, which was a bit annoying because it wasn't the fastest thing in the world). This was pretty painless, and the process was standard: select advanced to let me choose the right partition, pick the one, say "no" to everything in the services setup, and done. But this was the first Windows &lt;code>.iso&lt;/code> I tried. It was an old revision, and the drivers were causing issues when running (something weird about their &lt;code>.dll&lt;/code>, manually installing the &lt;code>.ini&lt;/code> driver files seemed to work?). The Nvidia drivers didn't want to be installed on such an old revision, after updating everything I could via Windows updates. So back I went to burning a newer Windows &lt;code>.iso&lt;/code> and going through the same process again…&lt;/p>&lt;p>Once Windows was ready and I verified that I could boot to it correctly, it was time to have a second go at Arch Linux. And I went through the setup at least three times, getting it wrong every single time, formatting root every single time, redownloading the packages every single pain. If only had I known earlier what the issue was!&lt;/p>&lt;p>Why bother with Arch? I was pretty happy with Linux Mint, and I lowkey wanted to try NixOS, but I had used Arch before and it's a really nice distro overall (up-to-date, has AUR, quite minimal, imperative), except for trying to install rEFInd while chrooted…&lt;/p>&lt;p>In the end I managed to get something half-working, I still need to properly configure WiFi and pulseaudio in my system but hey it works.&lt;/p>&lt;p>I like to be able to dual-boot Windows and Linux because Linux is amazing for productivity, but unfortunately, some games only work fine on Windows. Might as well have both systems and use one for gaming, while the other is my daily driver.&lt;/p>&lt;h2 id="setting-up-arch-linux">&lt;a href="#setting-up-arch-linux">Setting up Arch Linux&lt;/a>&lt;/h2>&lt;p>This is the process I followed to install Arch Linux in the end, along with a brief explanation on what I think the things are doing and why we are doing them. I think the wiki could do a better job at this, but I also know it's hard to get it right for everyone. Something I do dislike is the link colour, after opening a link it becomes gray and it's a lot easier to miss the fact that it is a link in the first place, which was tough when re-reading it because some links actually matter a lot. Furthermore, important information may just be a single line, also easy to skim over. Anyway, on to the installation process…&lt;/p>&lt;p>The first thing we want to do is configure our keyboard layout or else the keys won't correspond to what we expect:&lt;/p>&lt;pre>&lt;code class="language-sh">loadkeys es
&lt;/code>&lt;/pre>&lt;p>Because we're on a recent system, we want to verify that UEFI works correctly. If we see files listed, then it works fine:&lt;/p>&lt;pre>&lt;code class="language-sh">ls /sys/firmware/efi/efivars
&lt;/code>&lt;/pre>&lt;p>The next thing we want to do is configure the WiFi, because I don't have any ethernet cable nearby. To do this, we check what network interfaces our laptop has (we're looking for the one prefixed with "w", presumably for wireless, such as "wlan0" or "wlo1"), we set it up, scan for available wireless network, and finally connect. In my case, the network has WPA security so we rely on &lt;code>wpa_supplicant&lt;/code> to connect, passing the SSID (network name) and password:&lt;/p>&lt;pre>&lt;code class="language-sh">ip link
ip link set &amp;lt;IFACE&amp;gt; up
iw dev &amp;lt;IFACE&amp;gt; scan | less
wpa_supplicant -B -i &amp;lt;IFACE&amp;gt; -c &amp;lt;(wpa_passphrase &amp;lt;SSID&amp;gt; &amp;lt;PASS&amp;gt;)
&lt;/code>&lt;/pre>&lt;p>After that's done, pinging an IP address like "1.1.1.1" should Just Work™, but to be able to resolve hostnames, we need to also setup a nameserver. I'm using Cloudflare's, but you could use any other:&lt;/p>&lt;pre>&lt;code class="language-sh">echo nameserver 1.1.1.1 &amp;gt; /etc/resolv.conf
ping archlinux.org
^C
&lt;/code>&lt;/pre>&lt;p>If the ping works, then network works! If you still have issues, you may need to &lt;a href="https://wiki.archlinux.org/index.php/Network_configuration#Static_IP_address">manually configure a static IP address&lt;/a> and add a route with the address of your, well, router. This basically shows if we have any address, adds a static address (so people know who we are), shows what route we have, and adds a default one (so our packets know where to go):&lt;/p>&lt;pre>&lt;code class="language-sh">ip address show
ip address add &amp;lt;YOUR ADDR&amp;gt;/24 broadcast + dev &amp;lt;IFACE&amp;gt;
ip route show
ip route add default via &amp;lt;ROUTER ADDR&amp;gt; dev &amp;lt;IFACE&amp;gt;
&lt;/code>&lt;/pre>&lt;p>Now that we have network available, we can enable NTP to synchronize our system time (this may be required for network operations where certificates have a validity period, not sure; in any case nobody wants a wrong system time):&lt;/p>&lt;pre>&lt;code class="language-sh">timedatectl set-ntp true
&lt;/code>&lt;/pre>&lt;p>After that, we can manage our disk and partitions using &lt;code>fdisk&lt;/code>. We want to define partitions to tell the system where it should live. To determine the disk name, we first list them, and then edit it. &lt;code>fdisk&lt;/code> is really nice and reminds you at every step that help can be accessed with "m", which you should constantly use to guide you through.&lt;/p>&lt;pre>&lt;code class="language-sh">fdisk -l
fdisk /dev/&amp;lt;DISK&amp;gt;
&lt;/code>&lt;/pre>&lt;p>The partitions I made are the following:&lt;/p>&lt;ul>&lt;li>A 100MB one for the EFI system.&lt;/li>&lt;li>A 32GB one for Linux' root &lt;code>/&lt;/code> partition.&lt;/li>&lt;li>A 200GB one for Linux' home &lt;code>/home&lt;/code> partition.&lt;/li>&lt;li>The rest was unallocated for Windows because I did this first.&lt;/li>&lt;/ul>&lt;p>I like to have &lt;code>/home&lt;/code> and &lt;code>/&lt;/code> separate because I can reinstall root without losing anything from home (projects, music, photos, screenshots, videos…).&lt;/p>&lt;p>After the partitions are made, we format them in FAT32 and EXT4 which are good defaults for EFI, root and home. They need to have a format, or else they won't be usable:&lt;/p>&lt;pre>&lt;code class="language-sh">mkfs.fat -F32 /dev/&amp;lt;DISK&amp;gt;&amp;lt;PART1&amp;gt;
mkfs.ext4 /dev/&amp;lt;DISK&amp;gt;&amp;lt;PART2&amp;gt;
mkfs.ext4 /dev/&amp;lt;DISK&amp;gt;&amp;lt;PART3&amp;gt;
&lt;/code>&lt;/pre>&lt;p>Because the laptop was new, there was no risk to lose anything, but if you're doing a install on a previous system, be very careful with the partition names. Make sure they match with the ones in &lt;code>fdisk -l&lt;/code>.&lt;/p>&lt;p>Now that we have usable partitions, we need to mount them or they won't be accessible. We can do this with &lt;code>mount&lt;/code>:&lt;/p>&lt;pre>&lt;code class="language-sh">mount /dev/&amp;lt;DISK&amp;gt;&amp;lt;PART2&amp;gt; /mnt
mkdir /mnt/efi
mount /dev/&amp;lt;DISK&amp;gt;&amp;lt;PART1&amp;gt; /mnt/efi
mkdir /mnt/home
mount /dev/&amp;lt;DISK&amp;gt;&amp;lt;PART3&amp;gt; /mnt/home
&lt;/code>&lt;/pre>&lt;p>Remember to use the correct partitions while mounting. We mount everything so that the system knows which partitions we care about, which we will let know about later on.&lt;/p>&lt;p>Next step is to setup the basic Arch Linux system on root, which can be done with &lt;code>pacstrap&lt;/code>. What follows the directory is a list of packages, and you may choose any you wish (at least add &lt;code>base&lt;/code>, &lt;code>linux&lt;/code> and &lt;code>linux-firmware&lt;/code>). These can be installed later, but I'd recommend having them from the beginning, just in case:&lt;/p>&lt;pre>&lt;code class="language-sh">pacstrap /mnt base linux linux-firmware sudo vim-minimal dhcpcd wpa_supplicant man-db man-pages intel-ucode grub efibootmgr os-prober ntfs-3g
&lt;/code>&lt;/pre>&lt;p>Because my system has an intel CPU, I also installed &lt;code>intel-ucode&lt;/code>.&lt;/p>&lt;p>Next up is generating the &lt;code>fstab&lt;/code> file, which we tell to use UUIDs to be on the safe side through &lt;code>-U&lt;/code>. This file is important, because without it the system won't know what partitions exist and will happily only boot with the initramfs, without anything of what we just installed at root. Not knowing this made me restart the entire installation process a few times.&lt;/p>&lt;pre>&lt;code class="language-sh">genfstab -U /mnt &amp;gt;&amp;gt; /mnt/etc/fstab
&lt;/code>&lt;/pre>&lt;p>After that's done, we can change our root into our mount point and finish up configuration. We setup our timezone (so DST can be handled correctly if needed), synchronize the hardware clock (to persist the current time to the BIOS), uncomment our locales (exit &lt;code>vim&lt;/code> by pressing ESC, then type &lt;code>:wq&lt;/code> and press enter), generate locale files (which some applications need), configure language and keymap, update the hostname of our laptop and what indicate what &lt;code>localhost&lt;/code> means…&lt;/p>&lt;pre>&lt;code class="language-sh">ln -sf /usr/share/zoneinfo/&amp;lt;REGION&amp;gt;/&amp;lt;CITY&amp;gt; /etc/localtime
hwclock --systohc
vim /etc/locale.gen
locale-gen
echo LANG=es_ES.UTF-8 &amp;gt; /etc/locale.conf
echo KEYMAP=es &amp;gt; /etc/vconsole.conf
echo &amp;lt;HOST&amp;gt; /etc/hostname
cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/hosts
127.0.0.1 localhost
::1 localhost
127.0.1.1 &amp;lt;HOST&amp;gt;.localdomain &amp;lt;HOST&amp;gt;
EOF
&lt;/code>&lt;/pre>&lt;p>Really, we could've done all of this later, and the same goes for setting root's password with &lt;code>passwd&lt;/code> or creating users (some of the groups you probably want are &lt;code>power&lt;/code> and &lt;code>wheel&lt;/code>).&lt;/p>&lt;p>The important part here is installing GRUB (which also needed the &lt;code>efibootmgr&lt;/code> package):&lt;/p>&lt;pre>&lt;code class="language-sh">grub-install --target=x86_64-efi --efi-directory=/efi --bootloader-id=GRUB
&lt;/code>&lt;/pre>&lt;p>If we want GRUB to find our Windows install, we also need the &lt;code>os-prober&lt;/code> and &lt;code>ntfs-3g&lt;/code> packages that we installed earlier with &lt;code>pacstrap&lt;/code>, and with those we need to mount the Windows partition somewhere. It doesn't matter where. With that done, we can generate the GRUB configuration file which lists all the boot options:&lt;/p>&lt;pre>&lt;code class="language-sh">mkdir /windows
mount /dev/&amp;lt;DISK&amp;gt;&amp;lt;PART5&amp;gt; /windows
grub-mkconfig -o /boot/grub/grub.cfg
&lt;/code>&lt;/pre>&lt;p>(In my case, I installed Windows before completing the Arch install, which created an additional partition in between).&lt;/p>&lt;p>With GRUB ready, we can exit the chroot and reboot the system, and if all went well, you should be greeted with a choice of operating system to use:&lt;/p>&lt;pre>&lt;code class="language-sh">exit
reboot
&lt;/code>&lt;/pre>&lt;p>If for some reason you need to find what mountpoints were active prior to rebooting (to &lt;code>unmount&lt;/code> them for example), you can use &lt;code>findmnt&lt;/code>.&lt;/p>&lt;p>Before GRUB I tried rEFInd, which as I explained had issues with for missing a warning. Then I tried systemd-boot, which did not pick up Arch at first. That's where the several reinstalls come from, I didn't want to work with a half-worked system so I mostly redid the entire process quite a few times.&lt;/p>&lt;h2 id="migrating-to-the-new-laptop">&lt;a href="#migrating-to-the-new-laptop">Migrating to the new laptop&lt;/a>&lt;/h2>&lt;p>I had a external disk formatted with NTFS. Of course, after moving every file I cared about from my previous Linux install caused all the permissions to reset. All my &lt;code>.git&lt;/code> repositories, dirty with file permission changes! This is going to take a while to fix, or maybe I should just &lt;code>git config core.fileMode false&lt;/code>. Here is a &lt;a href="https://stackoverflow.com/a/2083563">lovely command&lt;/a> to sort them out on a per-repository basis:&lt;/p>&lt;pre>&lt;code class="language-sh">git diff --summary | grep --color 'mode change 100644 =&amp;gt; 100755' | cut -d' ' -f7- | xargs -d'\n' chmod -x
&lt;/code>&lt;/pre>&lt;p>I never realized how much I had stored over the years, but it really was a lot. While moving things to the external disk, I tried to do some cleanup, such as removing some build artifacts which needlessly occupy space, or completely skipping all the binary application files. If I need those I will install them anyway. The process was mostly focused on finding all the projects and program data that I did care about, or even some game saves. Nothing too difficult, but definitely time consuming.&lt;/p>&lt;h2 id="tuning-arch">&lt;a href="#tuning-arch">Tuning Arch&lt;/a>&lt;/h2>&lt;p>Now that our system is ready, install &lt;code>pacman-contrib&lt;/code> to grab a copy of the &lt;code>rankmirrors&lt;/code> speed. It should help speed up the download of whatever packages you want to install, since it will help us &lt;a href="https://wiki.archlinux.org/index.php/Mirrors#List_by_speed">rank the mirrors by download speed&lt;/a>. Making a copy of the file is important, otherwise whenever you try to install something it will fail saying it can't find anything.&lt;/p>&lt;pre>&lt;code class="language-sh">cp /etc/pacman.d/mirrorlist /etc/pacman.d/mirrorlist.backup
sed -i 's/^#Server/Server/' /etc/pacman.d/mirrorlist.backup
rankmirrors -n 6 /etc/pacman.d/mirrorlist.backup | tee /etc/pacman.d/mirrorlist
&lt;/code>&lt;/pre>&lt;p>This will take a while, but it should be well worth it. We're using &lt;code>tee&lt;/code> to see the progress as it goes.&lt;/p>&lt;p>Some other packages I installed after I had a working system in no particular order:&lt;/p>&lt;ul>&lt;li>&lt;code>xfce4&lt;/code> and &lt;code>xorg-server&lt;/code>. I just love the simplicity of XFCE.&lt;/li>&lt;li>&lt;code>xfce4-whiskermenu-plugin&lt;/code>, a really nice start menu.&lt;/li>&lt;li>&lt;code>xfce4-pulseaudio-plugin&lt;/code> and &lt;code>pavucontrol&lt;/code>, to quickly adjust the audio with my mouse.&lt;/li>&lt;li>&lt;code>xfce4-taskmanager&lt;/code>, a GUI alternative I generally prefer to &lt;code>htop&lt;/code>.&lt;/li>&lt;li>&lt;code>pulseaudio&lt;/code> and &lt;code>pulseaudio-alsa&lt;/code> to get nice integration with XFCE4 and audio mixing.&lt;/li>&lt;li>&lt;code>firefox&lt;/code>, which comes with fonts too. A really good web browser.&lt;/li>&lt;li>&lt;code>git&lt;/code>, to commit &lt;del>crimes&lt;/del> code.&lt;/li>&lt;li>&lt;code>code&lt;/code>, a wonderful editor which I used to write this blog entry.&lt;/li>&lt;li>&lt;code>nano&lt;/code>, so much nicer to write a simple commit message.&lt;/li>&lt;li>&lt;code>python&lt;/code> and &lt;code>python-pip&lt;/code>, my favourite language to toy around ideas or use as a calculator.&lt;/li>&lt;li>&lt;code>telegram-desktop&lt;/code>, for my needs on sharing memes.&lt;/li>&lt;li>&lt;code>cmus&lt;/code> and &lt;code>mpv&lt;/code>, a simple terminal music player and media player.&lt;/li>&lt;li>&lt;code>openssh&lt;/code>, to connect into any VPS I have access to.&lt;/li>&lt;li>&lt;code>base-devel&lt;/code>, necessary to build most projects I'll find myself working with (or even compiling some projects Rust which I installed via &lt;code>rustup&lt;/code>).&lt;/li>&lt;li>&lt;code>flac&lt;/code>, &lt;code>libmad&lt;/code>, &lt;code>opus&lt;/code>, and &lt;code>libvorbis&lt;/code>, to be able to play more audio files.&lt;/li>&lt;li>&lt;code>inkscape&lt;/code>, to make random drawings.&lt;/li>&lt;li>&lt;code>ffmpeg&lt;/code>, to convert media or record screen.&lt;/li>&lt;li>&lt;code>xclip&lt;/code>, to automatically copy screenshots to my clipboard.&lt;/li>&lt;li>&lt;code>gvfs&lt;/code>, needed by Thunar to handle mounting and having a trash (perma-deletion by default can be nasty sometimes).&lt;/li>&lt;li>&lt;code>noto-fonts&lt;/code>, &lt;code>noto-fonts-cjk&lt;/code>, &lt;code>noto-fonts-extra&lt;/code> and &lt;code>noto-fonts-emoji&lt;/code>, if you don't want missing gliphs everywhere.&lt;/li>&lt;li>&lt;code>xfce4-notifyd&lt;/code> and &lt;code>libnotify&lt;/code>, for notifications.&lt;/li>&lt;li>&lt;code>cronie&lt;/code>, to be able to &lt;code>crontab -e&lt;/code>. Make sure to &lt;code>system enable cronie&lt;/code>.&lt;/li>&lt;li>&lt;code>xarchiver&lt;/code> (with &lt;code>p7zip&lt;/code>, &lt;code>zip&lt;/code>, &lt;code>unzip&lt;/code> and &lt;code>unrar&lt;/code>) to uncompress stuff.&lt;/li>&lt;li>&lt;code>xreader&lt;/code> to read &lt;code>.pdf&lt;/code> files.&lt;/li>&lt;li>&lt;code>sqlitebrowser&lt;/code> is always nice to tinker around with SQLite databases.&lt;/li>&lt;li>&lt;code>jre8-openjdk&lt;/code> if you want to run Java applications.&lt;/li>&lt;li>&lt;code>smartmontools&lt;/code> is nice with a SSD to view your disk statistics.&lt;/li>&lt;/ul>&lt;p>After that, I configured my Super L key to launch &lt;code>xfce4-popup-whiskermenu&lt;/code> so that it opens the application menu, pretty much the same as it would on Windows, moved the panels around and configured them to my needs, and it feels like home once more.&lt;/p>&lt;p>I made some mistakes while &lt;a href="https://wiki.archlinux.org/index.php/Systemd-networkd">configuring systemd-networkd&lt;/a> and accidentally added a service that was incorrect, which caused boot to wait for it to timeout before completing. My boot time was taking 90 seconds longer because of this! &lt;a href="https://www.reddit.com/r/archlinux/comments/4nv9yi/my_arch_greets_me_now_with_a_start_job/">The solution was to remove said service&lt;/a>, so this is something to look out for.&lt;/p>&lt;p>In order to find what was taking long, I had to edit the &lt;a href="https://wiki.archlinux.org/index.php/kernel_parameters">kernel parameters&lt;/a> to remove the &lt;code>quiet&lt;/code> option. I prefer seeing the output on what my computer is doing anyway, because it gives me a sense of progress and most importantly is of great value when things go wrong. Another interesting option is &lt;code>noauto,x-systemd.automount&lt;/code>, which makes a disk lazily-mounted. If you have a slow disk, this could help speed things up.&lt;/p>&lt;p>If you see a service taking long, you can also use &lt;code>systemd-analyze blame&lt;/code> to see what takes the longest, and &lt;code>systemctl list-dependencies&lt;/code> is also helpful to find what services are active.&lt;/p>&lt;p>My &lt;code>locale charmap&lt;/code> was spitting out a bunch of warnings:&lt;/p>&lt;pre>&lt;code class="language-sh">$ locale charmap
locale: Cannot set LC_CTYPE to default locale: No such file or directory
locale: Cannot set LC_MESSAGES to default locale: No such file or directory
locale: Cannot set LC_ALL to default locale: No such file or directory
ANSI_X3.4-1968
&lt;/code>&lt;/pre>&lt;p>…ANSI encoding? Immediately I added the following to &lt;code>~/.bashrc&lt;/code> and &lt;code>~/.profile&lt;/code>:&lt;/p>&lt;pre>&lt;code class="language-sh">export LC_ALL=en_US.UTF-8
export LANG=en_US.UTF-8
export LANGUAGE=en_US.UTF-8
&lt;/code>&lt;/pre>&lt;p>For some reason, I also had to edit &lt;code>xfce4-terminal&lt;/code>'s preferences in advanced to change the default character encoding to UTF-8. This also solved my issues with pasting things into the terminal, and also proper rendering! I guess pastes were not working because it had some characters that could not be encoded.&lt;/p>&lt;p>To have working notifications, I added the following to &lt;code>~/.bash_profile&lt;/code> after &lt;code>exec startx&lt;/code>:&lt;/p>&lt;pre>&lt;code class="language-sh">systemctl --user start xfce4-notifyd.service
&lt;/code>&lt;/pre>&lt;p>I'm pretty sure there's a better way to do this, or maybe it's not even necessary, but this works for me.&lt;/p>&lt;p>Some of the other things I had left to do was setting up &lt;code>sccache&lt;/code> to speed up Rust builds:&lt;/p>&lt;pre>&lt;code class="language-sh">cargo install sccache
echo export RUSTC_WRAPPER=sccache &amp;gt;&amp;gt; ~/.bashrc
&lt;/code>&lt;/pre>&lt;p>Once I had &lt;code>cargo&lt;/code> ready, installed &lt;code>hacksaw&lt;/code> and &lt;code>shotgun&lt;/code> with it to perform screenshots.&lt;/p>&lt;p>I also disabled the security delay when downloading files in Firefox because it's just annoying, in &lt;code>about:config&lt;/code> setting &lt;code>security.dialog_enable_delay&lt;/code> to &lt;code>0&lt;/code>, and added the &lt;a href="https://alisdair.mcdiarmid.org/kill-sticky-headers/">Kill sticky headers&lt;/a> to my bookmarks (you may prefer &lt;a href="https://github.com/t-mart/kill-sticky">the updated version&lt;/a>).&lt;/p>&lt;p>The &lt;code>utils-linux&lt;/code> comes with a &lt;code>fstrim&lt;/code> utility to &lt;a href="https://wiki.archlinux.org/index.php/Solid_state_drive#Periodic_TRIM">trim the SSD weekly&lt;/a>, which I want enabled via &lt;code>systemctl enable fstrim.timer&lt;/code> (you may also want to &lt;code>start&lt;/code> it if you don't reboot often). For more SSD tips, check &lt;a href="https://easylinuxtipsproject.blogspot.com/p/ssd.html">How to optimize your Solid State Drive&lt;/a>.&lt;/p>&lt;p>If the sound is funky prior to reboot, try &lt;code>pulseaudio --kill&lt;/code> and &lt;code>pulseaudio --start&lt;/code>, or delete &lt;code>~/.config/pulse&lt;/code>.&lt;/p>&lt;p>I haven't been able to get the brightness keys to work yet, but it's not a big deal, because scrolling on the power manager plugin of Xfce does work (and also &lt;code>xbacklight&lt;/code> works, or writing directly to &lt;code>/sys/class/backlight/*&lt;/code>).&lt;/p>&lt;h2 id="tuning-windows">&lt;a href="#tuning-windows">Tuning Windows&lt;/a>&lt;/h2>&lt;p>On the Windows side, I disabled the annoying Windows defender by running (&lt;kbd>Ctrl+R&lt;/kbd>) &lt;code>gpedit.msc&lt;/code> and editing:&lt;/p>&lt;ul>&lt;li>&lt;em>Computer Configuration &amp;gt; Administrative Templates &amp;gt; Windows Components &amp;gt; Windows Defender » Turn off Windows Defender » Enable&lt;/em>&lt;/li>&lt;li>&lt;em>User Configuration &amp;gt; Administrative Templates &amp;gt; Start Menu and Taskbar » Remove Notifications and Action Center » Enable&lt;/em>&lt;/li>&lt;/ul>&lt;p>I also updated the &lt;a href="https://github.com/WindowsLies/BlockWindows/raw/master/hosts">&lt;code>hosts&lt;/code> file&lt;/a> (located at &lt;code>%windir%\system32\Drivers\etc\hosts&lt;/code>) with the hope that it will stop some of the telemetry.&lt;/p>&lt;p>Last, to have consistent time on Windows and Linux, I changed the following registry key for a &lt;code>qword&lt;/code> with value &lt;code>1&lt;/code>:&lt;/p>&lt;pre>HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\TimeZoneInformation\RealTimeIsUniversal
&lt;/pre>&lt;p>(The key might not exist, but you can create it if that's the case).&lt;/p>&lt;p>All this time, my laptop had the keyboard lights on, which have been quite annoying. Apparently, they also can cause &lt;a href="https://www.reddit.com/r/ValveIndex/comments/cm6pos/psa_uninstalldisable_aura_sync_lighting_if_you/">massive FPS drops&lt;/a>. I headed over to &lt;a href="https://rog.asus.com/downloads/">Asus Rog downloads&lt;/a>, selected Aura Sync…&lt;/p>&lt;pre>&lt;code class="language-md"># Not Found

The requested URL /campaign/aura/us/Sync.html was not found on this server.

Additionally, a 404 Not Found error was encountered while trying to use an ErrorDocument to handle the request.
&lt;/code>&lt;/pre>&lt;p>…great! I'll just find the &lt;a href="https://www.asus.com/campaign/aura/global/">Aura site&lt;/a> somewhere else…&lt;/p>&lt;pre>&lt;code class="language-md"># ASUS

# We'll be back.

Hi, our website is temporarily closed for service enhancements.

We'll be back shortly.Thank you for your patience!
&lt;/code>&lt;/pre>&lt;p>Oh come on. After waiting for the next day, I headed over, downloaded their software, tried to install it and it was an awful experience. It felt like I was purposedly installing malware. It spammed and flashed a lot of &lt;code>cmd&lt;/code>'s on screen as if it was a virus. It was stuck at 100% doing that and then, Windows blue-screened with &lt;code>KERNEL_MODE_HEAP_CORRUPTION&lt;/code>. Amazing. How do you screw up this bad?&lt;/p>&lt;p>Well, at least rebooting worked. I tried to &lt;a href="https://answers.microsoft.com/en-us/windows/forum/all/unable-to-uninstall-asus-aura-sync-utility/e9bec36c-e62f-4773-80be-88fb68dace16">uninstall Aura, but of course that failed&lt;/a>. Using the &lt;a href="https://support.microsoft.com/en-us/help/17588/windows-fix-problems-that-block-programs-being-installed-or-removed">troubleshooter to uninstall programs&lt;/a> helped me remove most of the crap that was installed.&lt;/p>&lt;p>After searching around how to disable the lights (because &lt;a href="https://rog.asus.com/forum/showthread.php?112786-Option-to-Disable-Aura-Lights-on-Strix-G-series-(G531GT%29-irrespective-of-OSes">my BIOS did not have this setting&lt;/a>), I stumbled upon &lt;a href="https://rog.asus.com/us/innovation/armoury_crate/">"Armoury Crate"&lt;/a>. Okay, fine, I will install that.&lt;/p>&lt;p>The experience wasn't much better. It did the same thing with a lot of consoles flashing on screen. And of course, it resulted in another blue-screen, this time &lt;code>KERNEL_SECURITY_CHECK_FAILURE&lt;/code>. To finish up, the BSOD kept happening as I rebooted the system. &lt;del>Time to reinstall Windows once more.&lt;/del> After booting and crashing a few more times I could get into secure mode and perform the reinstall from there, which saved me from burning the &lt;code>.iso&lt;/code> again.&lt;/p>&lt;p>Asus software might be good, but the software is utter crap.&lt;/p>&lt;p>After trying out &lt;a href="https://github.com/wroberts/rogauracore">rogauracore&lt;/a> (which didn't list my model), it worked! I could disable the stupid lights from Linux, and &lt;a href="https://gitlab.com/CalcProgrammer1/OpenRGB/-/wikis/home">OpenRGB&lt;/a> also works on Windows which may be worth checking out too.&lt;/p>&lt;p>Because &lt;code>rougauracore&lt;/code> helped me and they linked to &lt;a href="https://github.com/linuxhw/hw-probe/blob/master/README.md#appimage">hw-probe&lt;/a>, I decided to &lt;a href="https://linux-hardware.org/?probe=0e3e48c501">run it on my system&lt;/a>, with the hopes it is useful for other people.&lt;/p>&lt;h2 id="closing-words">&lt;a href="#closing-words">Closing words&lt;/a>&lt;/h2>&lt;p>I hope the installation journey is at least useful to someone, or that you enjoyed reading about it all. If not, sorry!&lt;/p></content></entry><entry xml:lang="en"><title>Tips for Outpost</title><published>2020-05-10T00:00:00+00:00</published><updated>2020-05-22T00:00:00+00:00</updated><link href="https://lonami.dev/blog/tips-outpost/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/tips-outpost/</id><content type="html">&lt;p>&lt;a href="https://store.steampowered.com/app/1127110/Outpost/">Outpost&lt;/a> is a fun little game by Open Mid Interactive that has popped in recently in my recommended section of Steam, and I decided to give it a try.&lt;/p>&lt;p>It's a fun tower-defense game with progression, different graphics and random world generation which makes it quite fun for a few hours. In this post I want to talk about some tips I found useful to get past night 50.&lt;/p>&lt;h2 id="build-pattern">&lt;a href="#build-pattern">Build Pattern&lt;/a>&lt;/h2>&lt;p>At first, you may be inclined to design a checkerboard pattern like the following, where "C" is the Crystal shrine, "S" is a stone launcher and "B" is a booster:&lt;/p>&lt;p>&lt;img src="outpost-bad-pattern.svg" alt="Bad Outpost build pattern">&lt;/p>&lt;p>Indeed, this pattern will apply &lt;strong>4&lt;/strong> boosts to every turret, but unfortunately, the other 4 slots of the booster are wasted! This is because boosters are able to power 8 different towers, and you really want to maximize that. Here's a better design:&lt;/p>&lt;p>&lt;img src="outpost-good-pattern.svg" alt="Good Outpost build pattern">&lt;/p>&lt;p>The shrine's tower does get boosted, but it's still not really worth it to boost it. This pattern works good, and it's really easy to tile: just repeat the same 3x3 pattern.&lt;/p>&lt;p>Nonetheless, we can do better. What if we applied multiple boosters to the same tower while still applying all 8 boosts?&lt;/p>&lt;p>&lt;img src="outpost-best-pattern.svg" alt="Best Outpost build pattern">&lt;/p>&lt;p>That's what peak performance looks like. You can actually apply multiple boosters to the same tower, and it works great.&lt;/p>&lt;p>Now, is it really worth it building anywhere except around the shrine? Not really. You never know where a boss will come from, so all sides need a lot of defense if you want to stand a chance.&lt;/p>&lt;p>The addition of traps in 1.6 is amazing. You want to build these outside your strong "core", mostly to slow the enemies down so your turrets have more time to finish them off. Don't waste boosters on the traps, and build them at a reasonable distance from the center (the sixth tile is a good spot):&lt;/p>&lt;p>&lt;img src="outpost-trap-pattern.svg" alt="Trap Outpost build pattern">&lt;/p>&lt;p>If you gather enough materials, you can build more trap and cannon layers outside, roughly at enough distance to slow them for enough duration until they reach the next layer of traps, and so on. Probably a single gap of "cannon, booster, cannon" is enough between trap layers, just not in the center where you need a lot of fire power.&lt;/p>&lt;h2 id="talents">&lt;a href="#talents">Talents&lt;/a>&lt;/h2>&lt;p>Talents are the way progression works in the game. Generally, after a run, you will have enough experience to upgrade nearly all talents of roughly the same tier. However, some are worth upgrading more than others (which provide basically no value).&lt;/p>&lt;p>The best ones to upgrade are:&lt;/p>&lt;ul>&lt;li>Starting supplies. Amazing to get good tools early.&lt;/li>&lt;li>Shrine shield. Very useful to hold against tough bosses.&lt;/li>&lt;li>Better buildings (cannon, boosters, bed and traps). They're a must to deal the most damage.&lt;/li>&lt;li>Better pickaxe. Stone is limited, so better make good use of it.&lt;/li>&lt;li>Better chests. They provide an insane amount of resources early.&lt;/li>&lt;li>Winter slow. Turrets will have more time to deal damage, it's perfect.&lt;/li>&lt;li>More time. Useful if you're running out, although generally you enter nights early after having a good core anyway.&lt;/li>&lt;li>More rocks. Similar to a better pickaxe, more stone is always better.&lt;/li>&lt;/ul>&lt;p>Some decent ones:&lt;/p>&lt;ul>&lt;li>In-shrine turret. It's okay to get past the first night without building but not much beyond that.&lt;/li>&lt;li>Better axe and greaves. Great to save some energy and really nice quality of life to move around.&lt;/li>&lt;li>Tree growth. Normally there's enough trees for this not to be an issue but it can save some time gathering wood.&lt;/li>&lt;li>Wisps. They're half-decent since they can provide materials once you max out or max out expensive gear.&lt;/li>&lt;/ul>&lt;p>Some okay ones:&lt;/p>&lt;ul>&lt;li>Extra XP while playing. Generally not needed due to the way XP scales per night, but can be a good boost.&lt;/li>&lt;li>Runestones. Not as reliable as chests but some can grant more energy per day.&lt;/li>&lt;/ul>&lt;p>Some crap ones:&lt;/p>&lt;ul>&lt;li>Boosts for other seasons. I mean, winter is already the best, no use there.&lt;/li>&lt;li>Bow. The bow is very useless at the moment, it's not worth your experience.&lt;/li>&lt;li>More energy per bush. Not really worth hunting for bushes since you will have enough energy to do well.&lt;/li>&lt;/ul>&lt;h2 id="turrets">&lt;a href="#turrets">Turrets&lt;/a>&lt;/h2>&lt;p>Always build the highest tier, there's no point in anything lower than that. You will need to deal a lot of damage in a small area, which means space is a premium.&lt;/p>&lt;h2 id="boosters">&lt;a href="#boosters">Boosters&lt;/a>&lt;/h2>&lt;p>If you're very early in the game, I recommend alternating both the flag and torch in a checkerboard pattern where the boosters should go in the pattern above. This way your towers will get extra speed and extra range, which works great.&lt;/p>&lt;p>When you're in mid-game (stone launchers, gears and campfires), I do not recommend using campfires. The issue is their range boost is way too long, and the turrets will miss quite a few shots. It's better to put all your power into fire speed for increased DPS, at least near the center. If you manage to build too far out and some of the turrets hardly ever shoot, you may put campfires there.&lt;/p>&lt;p>In end-game, of course alternate both of the highest tier upgrades. They are really good, and provide the best benefit / cost ratio.&lt;/p>&lt;h2 id="gathering-materials">&lt;a href="#gathering-materials">Gathering Materials&lt;/a>&lt;/h2>&lt;p>It is &lt;strong>very&lt;/strong> important to use all your energy every day! Otherwise it will go to waste, and you will need a lot of materials.&lt;/p>&lt;p>As of 1.6, you can mine two things at once if they're close enough! I don't know if this is intended or a bug, but it sure is great.&lt;/p>&lt;p>Once you're in mid-game, your stone-based fort should stand pretty well against the nights on its own. After playing for a while you will notice, if your base can defend a boss, then it will have no issue carrying you through the nights until the next boss. You can (and should!) spend the nights gathering materials, but only when you're confident that the night won't run out.&lt;/p>&lt;p>Before the boss hits (every fifth night), come back to your base and use all of your materials. This is the next fort upgrade that will carry it the five next nights.&lt;/p>&lt;p>You may also speed up time during night, but make sure you use all your energy before hand. And also take care, in the current version of the game speeding up time only speeds up monster movement, not the fire rate or projectile speed of your turrets! This means they will miss more shots and can be pretty dangerous. If you're speeding up time, consider speeding it up for a little bit, then go back to normal until things are more calm, and repeat.&lt;/p>&lt;p>If you're in the end-game, try to rush for chests. They provide a huge amount of materials which is really helpful to upgrade all your tools early so you can make sure to get the most out of every rock left in the map.&lt;/p>&lt;p>In the end-game, after all stone has been collected, you don't really need to use all of your energy anymore. Just enough to have enough wood to build with the remaining stone. This will also be nice with the bow upgrades, which admitedly can get quite powerful, but it's best to have a strong fort first.&lt;/p>&lt;h2 id="season">&lt;a href="#season">Season&lt;/a>&lt;/h2>&lt;p>In my opinion, winter is just the best of the seasons. You don't &lt;em>really&lt;/em> need that much energy (it gets tiresome), or extra tree drops, or luck. Slower movement means your turrets will be able to shoot enemies for longer, dealing more damage over time, giving them more chance to take enemies out before they reach the shrine.&lt;/p>&lt;p>Feel free to re-roll the map a few times (play and exit, or even restart the game) until you get winter if you want to go for The Play.&lt;/p>&lt;h2 id="gear">&lt;a href="#gear">Gear&lt;/a>&lt;/h2>&lt;p>In my opinion, you really should rush for the best pickaxe you can afford. Stone is a limited resource that doesn't regrow like trees, so once you run out, it's over. Better to make the best use out of it with a good pickaxe!&lt;/p>&lt;p>You may also upgrade your greaves, we all known faster movement is a &lt;em>really&lt;/em> nice quality of life improvement.&lt;/p>&lt;p>Of course, you will eventually upgrade your axe to chop wood (otherwise it's wasted energy, really), but it's not as much of a priority as the pickaxe.&lt;/p>&lt;p>Now, the bow is completely useless. Don't bother with it. Your energy is better spent gathering materials to build permanent turrets that deal constant damage while you're away, and the damage adds up with every extra turret you build.&lt;/p>&lt;p>With regards to items you carry (like sword, or helmet), look for these (from best to worst):&lt;/p>&lt;ul>&lt;li>Less minion life.&lt;/li>&lt;li>Chance to not consume energy.&lt;/li>&lt;li>+1 turret damage.&lt;/li>&lt;li>Extra energy.&lt;/li>&lt;li>+1 drop from trees or stones.&lt;/li>&lt;li>+1 free wood or stone per day.&lt;/li>&lt;/ul>&lt;p>Less minion life, nothing to say. You will need it near end-game.&lt;/p>&lt;p>The chance to not consume energy is better the more energy you have. With a 25% chance not to consume energy, you can think of it as 1 extra energy for every 4 energy you have on average.&lt;/p>&lt;p>Turret damage is a tough one, it's &lt;em>amazing&lt;/em> mid-game (it basically doubles your damage) but falls short once you unlock the cannon where you may prefer other items. Definitely recommended if you're getting started. You may even try to roll it on low tiers by dying on the second night, because it's that good.&lt;/p>&lt;p>Extra energy is really good, because it means you can get more materials before it gets too rough. Make sure you have built at least two beds in the first night! This extra energy will pay of for the many nights to come.&lt;/p>&lt;p>The problem with free wood or stone per day is that you have, often, five times as much energy per day. By this I mean you can get easily 5 stone every day, which means 5 extra stone, whereas the other would provide just 1 per night. On a good run, you will get around 50 free stone or 250 extra stone. It's a clear winner.&lt;/p>&lt;p>In end-game, more quality of life are revealing chests so that you can rush them early, if you like to hunt for them try to make better use of the slot.&lt;/p>&lt;h2 id="closing-words">&lt;a href="#closing-words">Closing words&lt;/a>&lt;/h2>&lt;p>I hope you enjoy the game as much as I do! Movement is sometimes janky and there's the occassional lag spikes, but despite this it should provide at least a few good hours of gameplay. Beware however a good run can take up to an hour!&lt;/p></content></entry><entry xml:lang="en"><title>Python ctypes and Windows</title><published>2019-06-19T00:00:00+00:00</published><updated>2019-06-19T00:00:00+00:00</updated><link href="https://lonami.dev/blog/ctypes-and-windows/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/ctypes-and-windows/</id><content type="html">&lt;p>&lt;a href="https://www.python.org/">Python&lt;/a>'s &lt;a href="https://docs.python.org/3/library/ctypes.html">&lt;code>ctypes&lt;/code>&lt;/a> is quite a nice library to easily load and invoke C methods available in already-compiled &lt;a href="https://en.wikipedia.org/wiki/Dynamic-link_library">&lt;code>.dll&lt;/code> files&lt;/a> without any additional dependencies. And I &lt;em>love&lt;/em> depending on as little as possible.&lt;/p>&lt;p>In this blog post, we will walk through my endeavors to use &lt;code>ctypes&lt;/code> with the &lt;a href="https://docs.microsoft.com/en-us/windows/desktop/api/">Windows API&lt;/a>, and do some cool stuff with it.&lt;/p>&lt;p>We will assume some knowledge of C/++ and Python, since we will need to read and write a bit of both. Please note that this post is only an introduction to &lt;code>ctypes&lt;/code>, and if you need more information you should consult the &lt;a href="https://docs.python.org/3/library/ctypes.html">Python's documentation for &lt;code>ctypes&lt;/code>&lt;/a>.&lt;/p>&lt;p>While the post focuses on Windows' API, the code here probably applies to unix-based systems with little modifications.&lt;/p>&lt;h2 id="basics">&lt;a href="#basics">Basics&lt;/a>&lt;/h2>&lt;p>First of all, let's learn how to load a library. Let's say we want to load &lt;code>User32.dll&lt;/code>:&lt;/p>&lt;pre>&lt;code class="language-python">import ctypes

ctypes.windll.user32
&lt;/code>&lt;/pre>&lt;p>Yes, it's that simple. When you access an attribute of &lt;code>windll&lt;/code>, said library will load. Since Windows is case-insensitive, we will use lowercase consistently.&lt;/p>&lt;p>Calling a function is just as simple. Let's say you want to call &lt;a href="https://docs.microsoft.com/en-us/windows/desktop/api/winuser/nf-winuser-setcursorpos">&lt;code>SetCursorPos&lt;/code>&lt;/a>, which is defined as follows:&lt;/p>&lt;pre>&lt;code class="language-c">BOOL SetCursorPos(
    int X,
    int Y
);
&lt;/code>&lt;/pre>&lt;p>Okay, it returns a &lt;code>bool&lt;/code> and takes two inputs, &lt;code>x&lt;/code> and &lt;code>y&lt;/code>. So we can call it like so:&lt;/p>&lt;pre>&lt;code class="language-python">ctypes.windll.user32.SetCursorPos(100, 100)
&lt;/code>&lt;/pre>&lt;p>Try it! Your cursor will move!&lt;/p>&lt;h2 id="funky-stuff">&lt;a href="#funky-stuff">Funky Stuff&lt;/a>&lt;/h2>&lt;p>We can go a bit more crazy and make it form a spiral:&lt;/p>&lt;pre>&lt;code class="language-python">import math
import time

for i in range(200):
    x = int(500 + math.cos(i / 5) * i)
    y = int(500 + math.sin(i / 5) * i)
    ctypes.windll.user32.SetCursorPos(x, y)
    time.sleep(0.05)
&lt;/code>&lt;/pre>&lt;p>Ah, it's always so pleasant to do random stuff when programming. Sure makes it more fun.&lt;/p>&lt;h2 id="complex-structures">&lt;a href="#complex-structures">Complex Structures&lt;/a>&lt;/h2>&lt;p>&lt;code>SetCursorPos&lt;/code> was really simple. It took two parameters and they both were integers. Let's go with something harder. Let's go with &lt;a href="https://docs.microsoft.com/en-us/windows/desktop/api/winuser/nf-winuser-sendinput">&lt;code>SendInput&lt;/code>&lt;/a>! Emulating input will be a fun exercise:&lt;/p>&lt;pre>&lt;code class="language-c">UINT SendInput(
    UINT    cInputs,
    LPINPUT pInputs,
    int     cbSize
);
&lt;/code>&lt;/pre>&lt;p>Okay, &lt;code>LPINPUT&lt;/code>, what are you? Microsoft likes to prefix types with what they are. In this case, &lt;code>LP&lt;/code> stands for "Long Pointer" (I guess?), so &lt;code>LPINPUT&lt;/code> is just a Long Pointer to &lt;a href="https://docs.microsoft.com/en-us/windows/desktop/api/winuser/ns-winuser-taginput">&lt;code>INPUT&lt;/code>&lt;/a>:&lt;/p>&lt;pre>&lt;code class="language-c">typedef struct tagINPUT {
    DWORD type;
    union {
        MOUSEINPUT    mi;
        KEYBDINPUT    ki;
        HARDWAREINPUT hi;
    } DUMMYUNIONNAME;
} INPUT, *PINPUT, *LPINPUT;
&lt;/code>&lt;/pre>&lt;p>Alright, that's new. We have a &lt;code>struct&lt;/code> and &lt;code>union&lt;/code>, two different concepts. We can define both with &lt;code>ctypes&lt;/code>:&lt;/p>&lt;pre>&lt;code class="language-python">INPUT_MOUSE = 0
INPUT_KEYBOARD = 1
INPUT_HARDWARE = 2

class INPUT(ctypes.Structure):
    _fields_ = [
        ('type', ctypes.c_long),
        ...
    ]
&lt;/code>&lt;/pre>&lt;p>Structures are classes that subclass &lt;code>ctypes.Structure&lt;/code>, and you define their fields in the &lt;code>_fields_&lt;/code> class-level variable, which is a list of tuples &lt;code>(field name, field type)&lt;/code>.&lt;/p>&lt;p>The C structure had a &lt;code>DWORD type&lt;/code>. &lt;code>DWORD&lt;/code> is a &lt;code>c_long&lt;/code>, and &lt;code>type&lt;/code> is a name like any other, which is why we did &lt;code>('type', ctypes.c_long)&lt;/code>.&lt;/p>&lt;p>But what about the union? It's anonymous, and we can't make anonymous unions (&lt;em>citation needed&lt;/em>) with &lt;code>ctypes&lt;/code>. We will give it a concrete name and a type.&lt;/p>&lt;p>Before defining the union, we need to define its inner structures, &lt;a href="https://docs.microsoft.com/en-us/windows/desktop/api/winuser/ns-winuser-tagmouseinput">&lt;code>MOUSEINPUT&lt;/code>&lt;/a>, &lt;a href="https://docs.microsoft.com/en-us/windows/desktop/api/winuser/ns-winuser-tagkeybdinput">&lt;code>KEYBDINPUT&lt;/code>&lt;/a> and &lt;a href="https://docs.microsoft.com/en-us/windows/desktop/api/winuser/ns-winuser-taghardwareinput">&lt;code>HARDWAREINPUT&lt;/code>&lt;/a>. We won't be using them all, but since they count towards the final struct size (C will choose the largest structure as the final size), we need them, or Windows' API will get confused and refuse to work (personal experience):&lt;/p>&lt;pre>&lt;code class="language-python">class MOUSEINPUT(ctypes.Structure):
    _fields_ = [
        ('dx', ctypes.c_long),
        ('dy', ctypes.c_long),
        ('mouseData', ctypes.c_long),
        ('dwFlags', ctypes.c_long),
        ('time', ctypes.c_long),
        ('dwExtraInfo', ctypes.POINTER(ctypes.c_ulong))
    ]


class KEYBDINPUT(ctypes.Structure):
    _fields_ = [
        ('wVk', ctypes.c_short),
        ('wScan', ctypes.c_short),
        ('dwFlags', ctypes.c_long),
        ('time', ctypes.c_long),
        ('dwExtraInfo', ctypes.POINTER(ctypes.c_ulong))
    ]


class HARDWAREINPUT(ctypes.Structure):
    _fields_ = [
        ('uMsg', ctypes.c_long),
        ('wParamL', ctypes.c_short),
        ('wParamH', ctypes.c_short)
    ]


class INPUTUNION(ctypes.Union):
    _fields_ = [
        ('mi', MOUSEINPUT),
        ('ki', KEYBDINPUT),
        ('hi', HARDWAREINPUT)
    ]


class INPUT(ctypes.Structure):
    _fields_ = [
        ('type', ctypes.c_long),
        ('value', INPUTUNION)
    ]
&lt;/code>&lt;/pre>&lt;p>Some things to note:&lt;/p>&lt;ul>&lt;li>Pointers are defined as &lt;code>ctypes.POINTER(inner type)&lt;/code>.&lt;/li>&lt;li>The field names can be anything you want. You can make them more "pythonic" if you want (such as changing &lt;code>dwExtraInfo&lt;/code> for just &lt;code>extra_info&lt;/code>), but I chose to stick with the original naming.&lt;/li>&lt;li>The union is very similar, but it uses &lt;code>ctypes.Union&lt;/code> instead of &lt;code>ctypes.Structure&lt;/code>.&lt;/li>&lt;li>We gave a name to the anonymous union, &lt;code>INPUTUNION&lt;/code>, and used it inside &lt;code>INPUT&lt;/code> with also a made-up name, &lt;code>('value', INPUTUNION)&lt;/code>.&lt;/li>&lt;/ul>&lt;p>Now that we have all the types we need defined, we can use them:&lt;/p>&lt;pre>&lt;code class="language-python">KEYEVENTF_KEYUP = 0x0002

def press(vk, down):
    inputs = INPUT(type=INPUT_KEYBOARD, value=INPUTUNION(ki=KEYBDINPUT(
        wVk=vk,
        wScan=0,
        dwFlags=0 if down else KEYEVENTF_KEYUP,
        time=0,
        dwExtraInfo=None
    )))
    ctypes.windll.user32.SendInput(1, ctypes.byref(inputs), ctypes.sizeof(inputs))


for char in 'HELLO':
    press(ord(char), down=True)
    press(ord(char), down=False)
&lt;/code>&lt;/pre>&lt;p>Run it! It will press and release the keys &lt;code>hello&lt;/code> to type the word &lt;code>"hello"&lt;/code>!&lt;/p>&lt;p>&lt;code>vk&lt;/code> stands for "virtual key". Letters correspond with their upper-case ASCII value, which is what we did above. You can find all the available keys in the page with all the &lt;a href="https://docs.microsoft.com/en-us/windows/desktop/inputdev/virtual-key-codes">Virtual Key Codes&lt;/a>.&lt;/p>&lt;h2 id="dynamic-inputs-and-pointers">&lt;a href="#dynamic-inputs-and-pointers">Dynamic Inputs and Pointers&lt;/a>&lt;/h2>&lt;p>What happens if a method wants something by reference? That is, a pointer to your thing? For example, &lt;a href="https://docs.microsoft.com/en-us/windows/desktop/api/winuser/nf-winuser-getcursorpos">&lt;code>GetCursorPos&lt;/code>&lt;/a>:&lt;/p>&lt;pre>&lt;code class="language-c">typedef struct tagPOINT {
    LONG x;
    LONG y;
} POINT, *PPOINT, *NPPOINT, *LPPOINT;

BOOL GetCursorPos(
    LPPOINT lpPoint
);
&lt;/code>&lt;/pre>&lt;p>It wants a Long Pointer to &lt;a href="https://docs.microsoft.com/en-us/windows/desktop/api/windef/ns-windef-point">&lt;code>POINT&lt;/code>&lt;/a>. We can do just that with &lt;code>ctypes.byref&lt;/code>:&lt;/p>&lt;pre>&lt;code class="language-python">class POINT(ctypes.Structure):
    _fields_ = [
        ('x', ctypes.c_long),
        ('y', ctypes.c_long)
    ]


def get_mouse():
    point = POINT()
    ctypes.windll.user32.GetCursorPos(ctypes.byref(point))
    #                  pass our point by ref ^^^^^
    # this lets GetCursorPos fill its x and y fields

    return point.x, point.y


while True:
    print(get_mouse())
    time.sleep(0.05)
&lt;/code>&lt;/pre>&lt;p>Now you can track the mouse position! Make sure to &lt;code>Ctrl+C&lt;/code> the program when you're tired of it.&lt;/p>&lt;p>What happens if a method wants a dynamically-sized input?&lt;/p>&lt;pre>&lt;code class="language-python">buffer = ctypes.create_string_buffer(size)
&lt;/code>&lt;/pre>&lt;p>In that case, you can create an in-memory &lt;code>buffer&lt;/code> of &lt;code>size&lt;/code> with &lt;code>ctypes.create_string_buffer&lt;/code>. It will return a character array of that size, which you can pass as a pointer directly (without &lt;code>ctypes.byref&lt;/code>).&lt;/p>&lt;p>To access the buffer's contents, you can use either &lt;code>.raw&lt;/code> or &lt;code>.value&lt;/code>:&lt;/p>&lt;pre>&lt;code class="language-python">entire_buffer_as_bytes = buffer.raw
up_until_null = buffer.value
&lt;/code>&lt;/pre>&lt;p>When the method fills in the data, you can &lt;code>cast&lt;/code> your buffer back into a pointer of a concrete type:&lt;/p>&lt;pre>&lt;code class="language-python">result_ptr = ctypes.cast(buffer, ctypes.POINTER(ctypes.c_long))
&lt;/code>&lt;/pre>&lt;p>And you can de-reference pointers with &lt;code>.contents&lt;/code>:&lt;/p>&lt;pre>&lt;code class="language-python">first_result = result_ptr.contents
&lt;/code>&lt;/pre>&lt;h2 id="arrays">&lt;a href="#arrays">Arrays&lt;/a>&lt;/h2>&lt;p>Arrays are defined as &lt;code>type * size&lt;/code>. Your linter may not like that, and if you don't know the size beforehand, consider creating a 0-sized array. For example:&lt;/p>&lt;pre>&lt;code class="language-python"># 10 longs
ten_longs = (ctypes.c_long * 10)()
for i in range(10):
    ten_longs[i] = 2 ** i

# Unknown size of longs, e.g. inside some Structure
longs = (ctypes.c_long * 0)

# Now you know how many longs it actually was
known_longs = ctypes.cast(
    ctypes.byref(longs),
    ctypes.POINTER(ctypes.c_long * size)
).contents
&lt;/code>&lt;/pre>&lt;p>If there's a better way to initialize arrays, please let me know.&lt;/p>&lt;h2 id="wintypes">&lt;a href="#wintypes">wintypes&lt;/a>&lt;/h2>&lt;p>Under Windows, the &lt;code>ctypes&lt;/code> module has a &lt;code>wintypes&lt;/code> submodule. This one contains definitions like &lt;code>HWND&lt;/code> which may be useful and can be imported as:&lt;/p>&lt;pre>&lt;code class="language-python">from ctypes.wintypes import HWND, LPCWSTR, UINT
&lt;/code>&lt;/pre>&lt;h2 id="callbacks">&lt;a href="#callbacks">Callbacks&lt;/a>&lt;/h2>&lt;p>Some functions (I'm looking at you, &lt;a href="https://docs.microsoft.com/en-us/windows/win32/api/winuser/nf-winuser-enumwindows">&lt;code>EnumWindows&lt;/code>&lt;/a>) ask us to pass a callback. In this case, it wants a &lt;a href="https://docs.microsoft.com/en-us/previous-versions/windows/desktop/legacy/ms633498(v=vs.85)">&lt;code>EnumWindowsProc&lt;/code>&lt;/a>:&lt;/p>&lt;pre>&lt;code class="language-c">BOOL EnumWindows(
    WNDENUMPROC lpEnumFunc,
    LPARAM      lParam
);

BOOL CALLBACK EnumWindowsProc(
    _In_ HWND   hwnd,
    _In_ LPARAM lParam
);
&lt;/code>&lt;/pre>&lt;p>The naive approach won't work:&lt;/p>&lt;pre>&lt;code class="language-python">def callback(hwnd, lParam):
    print(hwnd)
    return True

ctypes.windll.user32.EnumWindows(callback, 0)
# ctypes.ArgumentError: argument 1: &amp;lt;class 'TypeError'&amp;gt;: Don't know how to convert parameter 1
# Aww.
&lt;/code>&lt;/pre>&lt;p>Instead, you must wrap your function as a C definition like so:&lt;/p>&lt;pre>&lt;code class="language-python">from ctypes.wintypes import BOOL, HWND, LPARAM

EnumWindowsProc = ctypes.WINFUNCTYPE(BOOL, HWND, LPARAM)

def callback(hwnd, lParam):
    print(hwnd)
    return True

# Wrap the function in the C definition
callback = EnumWindowsProc(callback)

ctypes.windll.user32.EnumWindows(callback, 0)
# Yay, it works.
&lt;/code>&lt;/pre>&lt;p>You may have noticed this is what decorators do, wrap the function. So…&lt;/p>&lt;pre>&lt;code class="language-python">from ctypes.wintypes import BOOL, HWND, LPARAM

@ctypes.WINFUNCTYPE(BOOL, HWND, LPARAM)
def callback(hwnd, lParam):
    print(hwnd)
    return True

ctypes.windll.user32.EnumWindows(callback, 0)
&lt;/code>&lt;/pre>&lt;p>…will also work. And it is a &lt;em>lot&lt;/em> fancier.&lt;/p>&lt;h2 id="closing-words">&lt;a href="#closing-words">Closing Words&lt;/a>&lt;/h2>&lt;p>With the knowledge above and some experimentation, you should be able to call and do (almost) anything you want. That was pretty much all I needed on my project anyway :)&lt;/p>&lt;p>We have been letting Python convert Python values into C values, but you can do so explicitly too. For example, you can use &lt;code>ctypes.c_short(17)&lt;/code> to make sure to pass that &lt;code>17&lt;/code> as a &lt;code>short&lt;/code>. And if you have a &lt;code>c_short&lt;/code>, you can convert or cast it to its Python &lt;code>.value&lt;/code> as &lt;code>some_short.value&lt;/code>. The same applies for integers, longs, floats, doubles… pretty much anything, char pointers (strings) included.&lt;/p>&lt;p>If you can't find something in their online documentation, you can always &lt;a href="https://github.com/BurntSushi/ripgrep">&lt;code>rg&lt;/code>&lt;/a> for it in the &lt;code>C:\Program Files (x86)\Windows Kits\10\Include\*&lt;/code> directory.&lt;/p>&lt;p>Note that the &lt;code>ctypes.Structure&lt;/code>'s that you define can have more methods of your own. For example, you can write them a &lt;code>__str__&lt;/code> to easily view its fields, or define a &lt;code>@property&lt;/code> to re-interpret some data in a meaningful way.&lt;/p>&lt;p>For enumerations, you can pass just the right integer number, make a constant for it, or if you prefer, use a &lt;a href="https://docs.python.org/3/library/enum.html#enum.IntEnum">&lt;code>enum.IntEnum&lt;/code>&lt;/a>. For example, &lt;a href="https://docs.microsoft.com/en-us/windows-hardware/manufacture/desktop/dism/dismloglevel-enumeration">&lt;code>DismLogLevel&lt;/code>&lt;/a> would be:&lt;/p>&lt;pre>&lt;code class="language-python">class DismLogLevel(enum.IntEnum):
    DismLogErrors = 0
    DismLogErrorsWarnings = 1
    DismLogErrorsWarningsInfo = 2
&lt;/code>&lt;/pre>&lt;p>And you &lt;em>should&lt;/em> be able to pass &lt;code>DismLogLevel.DismLogErrors&lt;/code> as the parameter now.&lt;/p>&lt;p>If you see a function definition like &lt;code>Function(void)&lt;/code>, that's C's way of saying it takes no parameters, so just call it as &lt;code>Function()&lt;/code>.&lt;/p>&lt;p>Make sure to pass all parameters, even if they seem optional they probably still want a &lt;code>NULL&lt;/code> at least, and of course, read the documentation well. Some methods have certain pre-conditions.&lt;/p>&lt;p>Have fun hacking!&lt;/p></content></entry><entry xml:lang="en"><title>Shattered Pixel Dungeon</title><published>2019-06-03T00:00:00+00:00</published><updated>2019-06-03T00:00:00+00:00</updated><link href="https://lonami.dev/blog/pixel-dungeon/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/pixel-dungeon/</id><content type="html">&lt;p>&lt;a href="https://shatteredpixel.com/shatteredpd/">Shattered Pixel Dungeon&lt;/a> is the classic roguelike RPG game with randomly-generated dungeons. As a new player, it was a bit frustrating to be constantly killed on the first levels of the dungeon, but with some practice it's easy to reach high levels if you can kill the first boss.&lt;/p>&lt;h2 id="basic-tips">&lt;a href="#basic-tips">Basic Tips&lt;/a>&lt;/h2>&lt;p>The game comes with its own tips, but here's a short and straight-forward summary:&lt;/p>&lt;ul>&lt;li>&lt;strong>Don't rush into enemies&lt;/strong>. Abuse doors and small corridors to kill them one by one. You can use the clock on the bottom left to wait a turn without moving.&lt;/li>&lt;li>&lt;strong>Explore each level at full&lt;/strong>. You will find goodies and gain XP while doing so.&lt;/li>&lt;li>&lt;strong>Upon finding a special room&lt;/strong> (e.g. has a chest but is protected by piranhas), drink all potions that you found in that level until there's one that helps you (e.g. be invisible so piranhas leave you alone). There is guaranteed to be a helpful one per level with special rooms.&lt;/li>&lt;li>&lt;strong>Drink potions as early as possible&lt;/strong>. Harmful potions do less damage on early levels (and if you die, you lose less). This will keep them identified early for the rest of the game.&lt;/li>&lt;li>&lt;strong>Read scrolls as early as possible&lt;/strong> as well. This will keep them identified. It may be worth to wait until you have an item which may be cursed and until the level is clear, because some scrolls clean curses and others alert enemies.&lt;/li>&lt;li>&lt;strong>Food and health are resources&lt;/strong> that you have to &lt;em>manage&lt;/em>, not keep them always at full. Even if you are starving and taking damage, you may not need to eat &lt;em>just yet&lt;/em>, since food is scarce. Eat when you are low on health or in possible danger.&lt;/li>&lt;li>&lt;strong>Piranhas&lt;/strong>. Seriously, just leave them alone if you are melee. They're free food if you're playing ranged, though.&lt;/li>&lt;li>&lt;strong>Prefer armor over weapons&lt;/strong>. And make sure to identify or clean it from curses before wearing anything!&lt;/li>&lt;li>&lt;strong>Find a dew vial early&lt;/strong>. It's often a better idea to store dew (health) for later than to use it as soon as possible.&lt;/li>&lt;/ul>&lt;h2 id="bosses">&lt;a href="#bosses">Bosses&lt;/a>&lt;/h2>&lt;p>There is a boss every 5 levels.&lt;/p>&lt;ul>&lt;li>&lt;strong>Level 5 boss&lt;/strong>. Try to stay on water, but don't let &lt;em>it&lt;/em> stay on water since it will heal. Be careful when he starts enraging.&lt;/li>&lt;li>&lt;strong>Level 10 boss&lt;/strong>. Ranged weapons are good against it.&lt;/li>&lt;li>&lt;strong>Level 15 boss&lt;/strong>. I somehow managed to tank it with a health potion.&lt;/li>&lt;li>&lt;strong>Level 20 boss&lt;/strong>. I didn't get this far just yet. You are advised to use scrolls of magic mapping in the last levels to skip straight to the boss, since there's nothing else of value.&lt;/li>&lt;li>&lt;strong>Level 25 boss&lt;/strong>. The final boss. Good job if you made it this far!&lt;/li>&lt;/ul>&lt;h2 id="mage">&lt;a href="#mage">Mage&lt;/a>&lt;/h2>&lt;p>If you followed the basic tips, you will sooner or later make use of two scrolls of upgrade in a single run. This will unlock the mage class, which is ridiculously powerful. He starts with a ranged-weapon, a magic missile wand, which is really helpful to keep enemies at a distance. Normally, you want to use this at first to surprise attack them soon, and if you are low on charges, you may go melee on normal enemies if you are confident.&lt;/p>&lt;h2 id="luck">&lt;a href="#luck">Luck&lt;/a>&lt;/h2>&lt;p>This game is all about luck and patience! Some runs will be better than others, and you should thank and pray the RNG gods for them. If you don't, they will only give you cursed items and not a single scroll to clean them. So, good luck and enjoy playing!&lt;/p></content></entry><entry xml:lang="en"><title>Installing NixOS, Take 2</title><published>2019-02-15T00:00:00+00:00</published><updated>2019-02-16T00:00:00+00:00</updated><link href="https://lonami.dev/blog/installing-nixos-2/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/installing-nixos-2/</id><content type="html">&lt;p>This is my second take at installing NixOS, after a while being frustrated with Arch Linux and the fact that a few kernel upgrades ago, the system crashed randomly from time to time. &lt;code>journalctl&lt;/code> did not have any helpful hints and I thought reinstalling could be worthwhile anyway.&lt;/p>&lt;p>This time, I started with more knowledge! The first step is heading to the &lt;a href="https://nixos.org">NixOS website&lt;/a> and downloading their minimal installation CD for 64 bits. I didn't go with their graphical live CD, because their &lt;a href="https://nixos.org/nixos/manual">installation manual&lt;/a> is a wonderful resource that guides you nicely.&lt;/p>&lt;p>Once you have downloaded their &lt;code>.iso&lt;/code>, you should probably verify it's &lt;code>sha256sum&lt;/code> and make sure that it matches. The easiest thing to do in my opinion is using an USB to burn the image in it. Plug it in and check its device name with &lt;code>fdisk -l&lt;/code>. In my case, it was &lt;code>/dev/sdb&lt;/code>, so I went ahead with it and ran &lt;code>dd if=nixos.iso of=/dev/sdb status=progress&lt;/code>. Make sure to run &lt;code>sync&lt;/code> once that's done.&lt;/p>&lt;p>If either &lt;code>dd&lt;/code> or &lt;code>sync&lt;/code> seem "stuck" in the end, they are just flushing the changes to disk to make sure all is good. This is normal, and depends on your drives.&lt;/p>&lt;p>Now, reboot your computer with the USB plugged in and make sure to boot into it. You should be welcome with a pretty screen. Just select the first option and wait until it logs you in as root. Once you're there you probably want to &lt;code>loadkeys es&lt;/code> or whatever your keyboard layout is, or you will have a hard time with passwords, since the characters are all over the place.&lt;/p>&lt;p>In a clean disk, you would normally create the partitions now. In my case, I already had the partitions made (100MB for the EFI system, where &lt;code>/boot&lt;/code> lives, 40GB for the root &lt;code>/&lt;/code> partition with my old Linux installation, and 700G for &lt;code>/home&lt;/code>), so I didn't need to do anything here. The manual showcases &lt;code>parted&lt;/code>, but I personally use &lt;code>fdisk&lt;/code>, which has very helpful help I check every time I use it.&lt;/p>&lt;p>&lt;strong>Important&lt;/strong>: The &lt;code>XY&lt;/code> in &lt;code>/dev/sdXY&lt;/code> is probably different in your system! Make sure you use &lt;code>fdisk -l&lt;/code> to see the correct letters and numbers!&lt;/p>&lt;p>With the partitions ready in my UEFI system, I formatted both &lt;code>/&lt;/code> and &lt;code>/boot&lt;/code> just to be safe with &lt;code>mkfs.ext4 -L nixos /dev/sda2&lt;/code> and &lt;code>mkfs.fat -F 32 -n boot /dev/sda1&lt;/code> (remember that these are the letters and numbers used in my partition scheme). Don't worry about the warning in the second command regarding lowercase letters and Windows. It's not really an issue.&lt;/p>&lt;p>Now, since we gave each partition a label, we can easily mount them through &lt;code>mount /dev/disk/by-label/nixos /mnt&lt;/code> and, in UEFI systems, be sure to &lt;code>mkdir -p /mnt/boot&lt;/code> and &lt;code>mount /dev/disk/by-label/boot /mnt/boot&lt;/code>. I didn't bother setting up swap, since I have 8GB of RAM in my laptop and that's really enough for my use case.&lt;/p>&lt;p>With that done, we will now ask the configuration wizard to do some work for us (in particular, generate a template) with &lt;code>nixos-generate-config --root /mnt&lt;/code>. This generates a very well documented file that we should edit right now (and this is important!) with whatever editor you prefer. I used &lt;code>vim&lt;/code>, but you can change it for &lt;code>nano&lt;/code> if you prefer.&lt;/p>&lt;p>On to the configuration file, we need to enable a few things, so &lt;code>vim /mnt/etc/nixos/configuration.nix&lt;/code> and start scrolling down. We want to make sure to uncomment:&lt;/p>&lt;pre># We really want network!
networking.wireless.enable = true;

# This "fixes" the keyboard layout. Put the one you use.
i18n = {
consoleKeyMap = "es";
}

# Timezones are tricky so let's get this right.
time.timeZone = "Europe/Madrid";

# We *really* want some base packages installed, such as
# wpa_supplicant, or we won't have a way to connect to the
# network once we install...
environment.systemPackages = with pkgs; [
wpa_supplicant wget curl vim neovim cmus mpv firefox git tdesktop
];

# Printing is useful, sure, enable CUPS
services.printing.enable = true;

# We have speakers, let's make use of them.
sound.enable = true;
hardware.pulseaudio.enable = true;

# We want the X11 windowing system enabled, in Spanish.
services.xserver.enable = true;
services.xserver.layout = "es";

# I want a desktop manager in my laptop.
# I personally prefer XFCE, but the manual shows plenty
# of other options, such as Plasma, i3 WM, or whatever.
services.xserver.desktopManager.xfce.enable = true;
services.xserver.desktopManager.default = "xfce";

# Touchpad is useful (although sometimes annoying) in a laptop
services.xserver.libinput.enable = true;

# We don't want to do everything as root!
users.users.lonami = {
isNormalUser = true;
uid = 1000;
home = "/home/lonami";
extraGroups = [ "wheel" "networkmanager" "audio" ];
};
&lt;/pre>&lt;p>&lt;em>(Fun fact, I overlooked the configuration file until I wrote this and hadn't noticed sound/pulseaudio was there. It wasn't hard to find online how to enable it though!)&lt;/em>&lt;/p>&lt;p>Now, let's modify &lt;code>hardware-configuration.nix&lt;/code>. But if you have &lt;code>/home&lt;/code> in a separate partition like me, you should run &lt;code>blkid&lt;/code> to figure out its UUID. To avoid typing it out myself, I just ran &lt;code>blkid &amp;gt;&amp;gt; /mnt/etc/nixos/hardware-configuration.nix&lt;/code> so that I could easily move it around with &lt;code>vim&lt;/code>:&lt;/p>&lt;pre># (stuff...)

fileSystems."/home" =
{ device = "/dev/disk/by-uuid/d344c686-cae7-4dd3-840e-308eddf86608";
fsType = "ext4";
};

# (more stuff...)
&lt;/pre>&lt;p>Note that, obviously, you should put your own partition's UUID there. Modifying the configuration is where I think the current NixOS' manual should have made more emphasis, at this step of the installation. They do detail it below, but that was already too late in my first attempt. Anyway, you can boot from the USB and run &lt;code>nixos-install&lt;/code> as many times as you need until you get it working!&lt;/p>&lt;p>But before installing, we need to configure the network since there are plenty of things to download. If you want to work from WiFi, you should first figure out the name of your network card with &lt;code>ip link show&lt;/code>. In my case it's called &lt;code>wlp3s0&lt;/code>. So with that knowledge we can run &lt;code>wpa_supplicant -B -i wlp3s0 -c &amp;lt;(wpa_passphrase SSID key)&lt;/code>. Be sure to replace both &lt;code>SSID&lt;/code> and &lt;code>key&lt;/code> with the name of your network and password key, respectively. If they have spaces, surround them in quotes.&lt;/p>&lt;p>Another funny pitfall was typing &lt;code>wpa_supplicant&lt;/code> in the command above twice (instead of &lt;code>wpa_passphrase&lt;/code>). That sure spit out a few funny errors! Once you have ran that, wait a few seconds and &lt;code>ping 1.1.1.1&lt;/code> to make sure that you can reach the internet. If you do, &lt;code>^C&lt;/code> and let's install NixOS!&lt;/p>&lt;pre>nixos-install
&lt;/pre>&lt;p>Well, that was pretty painless. You can now &lt;code>reboot&lt;/code> and enjoy your new, functional system.&lt;/p>&lt;h2 id="afterword">&lt;a href="#afterword">Afterword&lt;/a>&lt;/h2>&lt;p>The process of installing NixOS was really painless once you have made sense out of what things mean. I was far more pleased this time than in my previous attempt, despite the four attempts I needed to have it up and running.&lt;/p>&lt;p>However not all is so good. I'm not sure where I went wrong, but the first time I tried with &lt;code>i3&lt;/code> instead of &lt;code>xfce&lt;/code>, all I was welcome with was a white, small terminal in the top left corner. I even generated a configuration file with &lt;code>i3-config-wizard&lt;/code> to make sure it could detect my Mod1/Mod4 keys (which, it did), but even after rebooting, my commands weren't responding. For example, I couldn't manage to open another terminal with &lt;code>Mod1+Enter&lt;/code>. I'm not even sure that I was in &lt;code>i3&lt;/code>…&lt;/p>&lt;p>In my very first attempt, I pressed &lt;code>Alt+F8&lt;/code> as suggested in the welcome message. This took me an offline copy of the manual, which is really nicely done. Funny enough, though, I couldn't exit &lt;code>w3m&lt;/code>. Both &lt;code>Q&lt;/code> and &lt;code>B&lt;/code> to quit and take me back wouldn't work. Somehow, it kept throwing me back into &lt;code>w3m&lt;/code>, so I had to forcibly shutdown.&lt;/p>&lt;p>In my second attempt, I also forgot to configure network, so I had no way to download &lt;code>wpa_supplicant&lt;/code> without having &lt;code>wpa_supplicant&lt;/code> itself to connect my laptop to the network! So, it was important to do that through the USB before installing it (which comes with the program preinstalled), just by making sure to add it in the configuration file.&lt;/p>&lt;p>Some other notes, if you can't reach the internet, don't add any DNS in &lt;code>/etc/resolv.conf&lt;/code>. This should be done declaratively in &lt;code>configuration.nix&lt;/code>.&lt;/p>&lt;p>In the end, I spent the entire afternoon playing around with it, taking breaks and what-not. I still haven't figured out why &lt;code>nvim&lt;/code> was printing the literal escape character when going from normal to insert mode in the &lt;code>xfce4-terminal&lt;/code> (and other actions also made it print this "garbage" to the console), why sometimes the network can reach the internet (and only some sites!) and sometimes not, and how to setup dualboot.&lt;/p>&lt;p>But despite all of this, I think it was a worth installing it again. One sure sees things from a different perspective, and gets the chance to write another blog post!&lt;/p>&lt;p>If there's something I overlooked or that could be done better, or maybe you can explain it differently, please be sure to &lt;a href="https://lonami.dev/contact">contact me&lt;/a> to let me know!&lt;/p>&lt;h2 id="update">&lt;a href="#update">Update&lt;/a>&lt;/h2>&lt;p>Well, that was surprisingly fast feedback. Thank you very much &lt;a href="https://bb010g.keybase.pub/">@bb010g&lt;/a> for it! As they rightfully pointed out, one can avoid adding &lt;code>/home&lt;/code> manually to &lt;code>hardware-configuration.nix&lt;/code> if you mount it before generating the configuration files. However, the installation process doesn't need &lt;code>/home&lt;/code> mounted, so I didn't do it.&lt;/p>&lt;p>The second weird issue with &lt;code>w3m&lt;/code> is actually a funny one. &lt;code>Alt+F8&lt;/code> &lt;em>switches to another TTY&lt;/em>! That's why quitting the program wouldn't do anything. You'd still be in a different TTY! Normally, this is &lt;code>Ctrl+Alt+FX&lt;/code>, so I hadn't even thought that this is what could be happening. Anyway, the solution is not quitting the program, but rather going back to the main TTY with &lt;code>Alt+F1&lt;/code>. You can switch back and forth all you need to consult the manual.&lt;/p>&lt;p>More suggestions are having &lt;a href="https://github.com/rycee/home-manager">&lt;code>home-manager&lt;/code>&lt;/a> manage the graphical sessions, since it should be easier to deal with than the alternatives.&lt;/p>&lt;p>Despite having followed the guide and having read it over and over several times, it seems like my thoughts in this blog post may be a bit messy. So I recommend you also reading through the guide to have two versions of all this, just in case.&lt;/p>&lt;p>Regarding network issues, they use &lt;code>connman&lt;/code> so that may be worth checking out.&lt;/p>&lt;p>Regarding terminal issues with &lt;code>nvim&lt;/code> printing the literal escape character, I was told off for not having checked what my &lt;code>$TERM&lt;/code> was. I hadn't really looked into it much myself, just complained about it here, so sorry for being annoying about that. A quick search in the &lt;code>nixpkgs&lt;/code> repository lets us find &lt;a href="https://github.com/NixOS/nixpkgs/blob/release-18.09/pkgs/applications/editors/neovim/default.nix">neovim/default.nix&lt;/a>, with version 0.3.1. Looking at &lt;a href="https://github.com/neovim/neovim">Neovim's main repository&lt;/a> we can see that this is a bit outdated, but that is fine.&lt;/p>&lt;p>If only I had bothered to look at &lt;a href="https://github.com/neovim/neovim/wiki/FAQ#nvim-shows-weird-symbols-2-q-when-changing-modes">Neovim's wiki&lt;/a>, (which they found through &lt;a href="https://github.com/neovim/neovim/issues/7749">Neovim's GitHub issues&lt;/a>) I would've seen that some terminals just don't support the program properly. The solution is, of course, to use a different terminal emulator with better support or to disable the &lt;code>guicursor&lt;/code> in Neovim's config.&lt;/p>&lt;p>This is a pretty good life lesson. 30 seconds of searching, maybe two minutes and a half for also checking XFCE issues, are often more than enough to troubleshoot your issues. The internet is a big place and more people have surely came across the problem before, so make sure to look online first. In my defense I'll say that it didn't bother me so much so I didn't bother looking for that soon either.&lt;/p></content></entry><entry xml:lang="en"><title>Breaking Risk of Rain</title><published>2019-01-12T00:00:00+00:00</published><updated>2019-01-12T00:00:00+00:00</updated><link href="https://lonami.dev/blog/breaking-ror/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/breaking-ror/</id><content type="html">&lt;p>&lt;a href="https://riskofraingame.com/">Risk of Rain&lt;/a> is a fun little game you can spend a lot of hours on. It's incredibly challenging for new players, and fun once you have learnt the basics. This blog will go through what I've learnt and how to play the game correctly.&lt;/p>&lt;h2 id="getting-started">&lt;a href="#getting-started">Getting Started&lt;/a>&lt;/h2>&lt;p>If you're new to the game, you may find it frustrating. You must learn very well to dodge.&lt;/p>&lt;p>Your first &lt;a href="http://riskofrain.wikia.com/wiki/Category:Characters">character&lt;/a> will be &lt;a href="http://riskofrain.wikia.com/wiki/Commando">Commando&lt;/a>. He's actually a very nice character. Use your third skill (dodge) to move faster, pass through large groups of enemies, and negate fall damage.&lt;/p>&lt;p>If there are a lot of monsters, remember to &lt;strong>leave&lt;/strong> from there! It's really important for survival. Most enemies &lt;strong>don't do body damage&lt;/strong>. Not even the body of the &lt;a href="http://riskofrain.wikia.com/wiki/Magma_Worm">Magma Worm&lt;/a> or the &lt;a href="http://riskofrain.wikia.com/wiki/Wandering_Vagrant">Wandering Vagrant&lt;/a> (just dodge the head and projectiles respectively).&lt;/p>&lt;p>The first thing you must do is always &lt;strong>rush for the teleporter&lt;/strong>. Completing the levels quick will make the game easier. But make sure to take note of &lt;strong>where the chests are&lt;/strong>! When you have time (even when the countdown finishes), go back for them and buy as many as you can. Generally, prefer &lt;a href="http://riskofrain.wikia.com/wiki/Chest">chests&lt;/a> over &lt;a href="http://riskofrain.wikia.com/wiki/Shrine">shrines&lt;/a> since they may eat all your money.&lt;/p>&lt;p>Completing the game on &lt;a href="http://riskofrain.wikia.com/wiki/Difficulty">Drizzle&lt;/a> is really easy if you follow these tips.&lt;/p>&lt;h2 id="requisites">&lt;a href="#requisites">Requisites&lt;/a>&lt;/h2>&lt;p>Before breaking the game, you must obtain several &lt;a href="http://riskofrain.wikia.com/wiki/Item#Artifacts">artifacts&lt;/a>. We are interested in particular in the following:&lt;/p>&lt;ul>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Sacrifice">Sacrifice&lt;/a>. You really need this one, and may be a bit hard to get. With it, you will be able to farm the first level for 30 minutes and kill the final boss in 30 seconds.&lt;/li>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Command">Command&lt;/a>. You need this unless you want to grind for hours to get enough of the items you really need for the rest of the game. Getting this one is easy.&lt;/li>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Glass">Glass&lt;/a>. Your life will be very small (at the beginning…), but you will be able to one-shot everything easily.&lt;/li>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Kin">Kin&lt;/a> (optional). It makes it easier to obtain a lot of boxes if you restart the first level until you get &lt;a href="http://riskofrain.wikia.com/wiki/Lemurian">lemurians&lt;/a> or &lt;a href="http://riskofrain.wikia.com/wiki/Jellyfish">jellyfish&lt;/a> as the monster, since they're cheap to spawn.&lt;/li>&lt;/ul>&lt;p>With those, the game becomes trivial. Playing as &lt;a href="http://riskofrain.wikia.com/wiki/Huntress">Huntress&lt;/a> is excellent since she can move at high speed while killing everything on screen.&lt;/p>&lt;h2 id="breaking-the-game">&lt;a href="#breaking-the-game">Breaking the Game&lt;/a>&lt;/h2>&lt;p>The rest is easy! With the command artifact you want the following items.&lt;/p>&lt;h3 id="">&lt;a href="#">&lt;a href="http://riskofrain.wikia.com/wiki/Category:Common_Items">Common Items&lt;/a>&lt;/a>&lt;/h3>&lt;ul>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Soldier's_Syringe">Soldier's Syringe&lt;/a>. &lt;strong>Stack 13&lt;/strong> of these and you will triple your attack speed. You can get started with 4 or so.&lt;/li>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Paul's_Goat_Hoof">Paul's Goat Hoof&lt;/a>. &lt;strong>Stack +30&lt;/strong> of these and your movement speed will be insane. You can get a very good speed with 8 or so.&lt;/li>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Crowbar">Crowbar&lt;/a>. &lt;strong>Stack +20&lt;/strong> to guarantee you can one-shot bosses.&lt;/li>&lt;/ul>&lt;p>If you want to be safer:&lt;/p>&lt;ul>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Hermit's_Scarf">Hermit's Scarf&lt;/a>. &lt;strong>Stack 6&lt;/strong> of these to dodge 1/3 of the attacks.&lt;/li>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Monster_Tooth">Monster Tooth&lt;/a>. &lt;strong>Stack 9&lt;/strong> of these to recover 50 life on kill. This is plenty, since you will be killing &lt;em>a lot&lt;/em>.&lt;/li>&lt;/ul>&lt;p>If you don't have enough and want more fun, get one of these:&lt;/p>&lt;ul>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Gasoline">Gasoline&lt;/a>. Burn the ground on kill, and more will die!&lt;/li>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Headstompers">Headstompers&lt;/a>. They make a pleasing sound on fall, and hurt.&lt;/li>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Lens-Maker's_Glasses">Lens-Maker's Glasses&lt;/a>. &lt;strong>Stack 14&lt;/strong> and you will always deal a critical strike for double the damage.&lt;/li>&lt;/ul>&lt;h3 id="">&lt;a href="#">&lt;a href="http://riskofrain.wikia.com/wiki/Category:Uncommon_Items">Uncommon Items&lt;/a>&lt;/a>&lt;/h3>&lt;ul>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Infusion">Infusion&lt;/a>. You only really need one of this. Your life will skyrocket after a while, since this gives you 1HP per kill.&lt;/li>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Hopoo_Feather">Hopoo Feather&lt;/a>. &lt;strong>Stack +10&lt;/strong> of these. You will pretty much be able to fly with so many jumps.&lt;/li>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Guardian's_Heart">Guardian's Heart&lt;/a>. Not really necessary, but useful for early and late game, since it will absorb infinite damage the first hit.&lt;/li>&lt;/ul>&lt;p>If, again, you want more fun, get one of these:&lt;/p>&lt;ul>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Ukulele">Ukelele&lt;/a>. Spazz your enemies!&lt;/li>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Will-o'-the-wisp">Will-o'-the-wisp&lt;/a>. Explode your enemies!&lt;/li>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Chargefield_Generator">Chargefield Generator&lt;/a>. It should cover your entire screen after a bit, hurting all enemies without moving a finger.&lt;/li>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Golden_Gun">Golden Gun&lt;/a>. You will be rich, so this gives you +40% damage.&lt;/li>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Predatory_Instincts">Predatory Instincts&lt;/a>. If you got 14 glasses, you will always be doing critical strikes, and this will give even more attack speed.&lt;/li>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/56_Leaf_Clover">56 Leaf Clover&lt;/a>. More drops, in case you didn't have enough.&lt;/li>&lt;/ul>&lt;h3 id="">&lt;a href="#">&lt;a href="http://riskofrain.wikia.com/wiki/Category:Rare_Items">Rare Items&lt;/a>&lt;/a>&lt;/h3>&lt;ul>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Ceremonial_Dagger">Ceremonial Dagger&lt;/a>. &lt;strong>Stack +3&lt;/strong>, then killing one thing kills another thing and makes a chain reaction.&lt;/li>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Alien_Head">Alien Head&lt;/a>. &lt;strong>Stack 3&lt;/strong>, and you will be able to use your abilities more often.&lt;/li>&lt;/ul>&lt;p>For more fun:&lt;/p>&lt;ul>&lt;li>&lt;a href="http://riskofrain.wikia.com/wiki/Brilliant_Behemoth">Brilliant Behemoth&lt;/a>. Boom boom.&lt;/li>&lt;/ul>&lt;h2 id="closing-words">&lt;a href="#closing-words">Closing Words&lt;/a>&lt;/h2>&lt;p>You can now beat the game in Monsoon solo with any character. Have fun! And be careful with the sadly common crashes.&lt;/p></content></entry><entry xml:lang="en"><title>WorldEdit Commands</title><published>2018-07-11T00:00:00+00:00</published><updated>2018-07-11T00:00:00+00:00</updated><link href="https://lonami.dev/blog/world-edit/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/world-edit/</id><content type="html">&lt;p>&lt;a href="https://dev.bukkit.org/projects/worldedit">WorldEdit&lt;/a> is an extremely powerful tool for modifying entire worlds within &lt;a href="https://minecraft.net">Minecraft&lt;/a>, which can be used as either a mod for your single-player worlds or as a plugin for your &lt;a href="https://getbukkit.org/">Bukkit&lt;/a> servers.&lt;/p>&lt;p>This command guide was written for Minecraft 1.12.1, version &lt;a href="https://dev.bukkit.org/projects/worldedit/files/2460562">6.1.7.3&lt;/a>, but should work for newer versions too. All WorldEdit commands can be used with a double slash (&lt;code>//&lt;/code>) so they don't conlict with built-in commands. This means you can get a list of all commands with &lt;code>//help&lt;/code>. Let's explore different categories!&lt;/p>&lt;h2 id="movement">&lt;a href="#movement">Movement&lt;/a>&lt;/h2>&lt;p>In order to edit a world properly you need to learn how to move in said world properly. There are several straightforward commands that let you move:&lt;/p>&lt;ul>&lt;li>&lt;code>//ascend&lt;/code> goes up one floor.&lt;/li>&lt;li>&lt;code>//descend&lt;/code> goes down one floor.&lt;/li>&lt;li>&lt;code>//thru&lt;/code> let's you pass through walls.&lt;/li>&lt;li>&lt;code>//jumpto&lt;/code> to go wherever you are looking.&lt;/li>&lt;/ul>&lt;h2 id="information">&lt;a href="#information">Information&lt;/a>&lt;/h2>&lt;p>Knowing your world properly is as important as knowing how to move within it, and will also let you change the information in said world if you need to.&lt;/p>&lt;ul>&lt;li>&lt;code>//biomelist&lt;/code> shows all known biomes.&lt;/li>&lt;li>&lt;code>//biomeinfo&lt;/code> shows the current biome.&lt;/li>&lt;li>&lt;code>//setbiome&lt;/code> lets you change the biome.&lt;/li>&lt;/ul>&lt;h2 id="blocks">&lt;a href="#blocks">Blocks&lt;/a>&lt;/h2>&lt;p>You can act over all blocks in a radius around you with quite a few commands. Some won't actually act over the entire range you specify, so 100 is often a good number.&lt;/p>&lt;h3 id="filling">&lt;a href="#filling">Filling&lt;/a>&lt;/h3>&lt;p>You can fill pools with &lt;code>//fill water 100&lt;/code> or caves with &lt;code>//fillr water 100&lt;/code>, both of which act below your feet.&lt;/p>&lt;h3 id="fixing">&lt;a href="#fixing">Fixing&lt;/a>&lt;/h3>&lt;p>If the water or lava is buggy use &lt;code>//fixwater 100&lt;/code> or &lt;code>//fixlava 100&lt;/code> respectively.&lt;/p>&lt;p>Some creeper removed the snow or the grass? Fear not, you can use &lt;code>//snow 10&lt;/code> or &lt;code>//grass 10&lt;/code>.&lt;/p>&lt;h3 id="emptying">&lt;a href="#emptying">Emptying&lt;/a>&lt;/h3>&lt;p>You can empty a pool completely with &lt;code>//drain 100&lt;/code>, remove the snow with &lt;code>//thaw 10&lt;/code>, and remove fire with &lt;code>//ex 10&lt;/code>.&lt;/p>&lt;h3 id="removing">&lt;a href="#removing">Removing&lt;/a>&lt;/h3>&lt;p>You can remove blocks above and below you in some area with the &lt;code>//removeabove N&lt;/code> and &lt;code>//removebelow N&lt;/code>. You probably want to set a limit though, or you could fall off the world with &lt;code>//removebelow 1 10&lt;/code> for radius and depth. You can also remove near blocks with &lt;code>//removenear block 10&lt;/code>.&lt;/p>&lt;h3 id="shapes">&lt;a href="#shapes">Shapes&lt;/a>&lt;/h3>&lt;p>Making a cylinder (or circle) can be done with through &lt;code>//cyl stone 10&lt;/code>, a third argument for the height. The radius can be comma-separated to make a ellipses instead, such as &lt;code>//cyl stone 5,10&lt;/code>.&lt;/p>&lt;p>Spheres are done with &lt;code>//sphere stone 5&lt;/code>. This will build one right at your center, so you can raise it to be on your feet with &lt;code>//sphere stone 5 yes&lt;/code>. Similar to cylinders, you can comma separate the radius &lt;code>x,y,z&lt;/code>.&lt;/p>&lt;p>Pyramids can be done with &lt;code>//pyramic stone 5&lt;/code>.&lt;/p>&lt;p>All these commands can be prefixed with "h" to make them hollow. For instance, &lt;code>//hsphere stone 10&lt;/code>.&lt;/p>&lt;h2 id="regions">&lt;a href="#regions">Regions&lt;/a>&lt;/h2>&lt;h3 id="basics">&lt;a href="#basics">Basics&lt;/a>&lt;/h3>&lt;p>Operating over an entire region is really important, and the first thing you need to work comfortably with them is a tool to make selections. The default wooden-axe tool can be obtained with &lt;code>//wand&lt;/code>, but you must be near the blocks to select. You can use a different tool, like a golden axe, to use as your "far wand" (wand usable over distance). Once you have one in your hand type &lt;code>//farwand&lt;/code> to use it as your "far wand". You can select the two corners of your region with left and right click. If you have selected the wrong tool, use &lt;code>//none&lt;/code> to clear it.&lt;/p>&lt;p>If there are no blocks but you want to use your current position as a corner, use &lt;code>//pos1&lt;/code> or 2.&lt;/p>&lt;p>If you made a region too small, you can enlarge it with &lt;code>//expand 10 up&lt;/code>, or &lt;code>//expand vert&lt;/code> for the entire vertical range, etc., or make it smaller with &lt;code>//contract 10 up&lt;/code> etc., or &lt;code>//inset&lt;/code> it to contract in both directions. You can use short-names for the cardinal directions (NSEW).&lt;/p>&lt;p>Finally, if you want to move your selection, you can &lt;code>//shift 1 north&lt;/code> it to wherever you need.&lt;/p>&lt;h3 id="information">&lt;a href="#information">Information&lt;/a>&lt;/h3>&lt;p>You can get the &lt;code>//size&lt;/code> of the selection or even &lt;code>//count torch&lt;/code> in some area. If you want to count all blocks, get their distribution &lt;code>//distr&lt;/code>.&lt;/p>&lt;h3 id="filling">&lt;a href="#filling">Filling&lt;/a>&lt;/h3>&lt;p>With a region selected, you can &lt;code>//set&lt;/code> it to be any block! For instance, you can use &lt;code>//set air&lt;/code> to clear it entirely. You can use more than one block evenly by separting them with a comma &lt;code>//set stone,dirt&lt;/code>, or with a custom chance &lt;code>//set 20%stone,80%dirt&lt;/code>.&lt;/p>&lt;p>You can use &lt;code>//replace from to&lt;/code> instead if you don't want to override all blocks in your selection.&lt;/p>&lt;p>You can make an hollow set with &lt;code>//faces&lt;/code>, and if you just want the walls, use &lt;code>//walls&lt;/code>.&lt;/p>&lt;h3 id="cleaning">&lt;a href="#cleaning">Cleaning&lt;/a>&lt;/h3>&lt;p>If someone destroyed your wonderful snow landscape, fear not, you can use &lt;code>//overlay snow&lt;/code> over it (although for this you actually have &lt;code>//snow N&lt;/code> and its opposite &lt;code>//thaw&lt;/code>).&lt;/p>&lt;p>If you set some rough area, you can always &lt;code>//smooth&lt;/code> it, even more than one time with &lt;code>//smooth 3&lt;/code>. You can get your dirt and stone back with &lt;code>//naturalize&lt;/code> and put some plants with &lt;code>//flora&lt;/code> or &lt;code>//forest&lt;/code>, both of which support a density or even the type for the trees. If you already have the dirt use &lt;code>//green&lt;/code> instead. If you want some pumpkins, with &lt;code>//pumpkins&lt;/code>.&lt;/p>&lt;h3 id="moving">&lt;a href="#moving">Moving&lt;/a>&lt;/h3>&lt;p>You can repeat an entire selection many times by stacking them with &lt;code>//stack N DIR&lt;/code>. This is extremely useful to make things like corridors or elevators. For instance, you can make a small section of the corridor, select it entirely, and then repeat it 10 times with &lt;code>//stack 10 north&lt;/code>. Or you can make the elevator and then &lt;code>//stack 10 up&lt;/code>. If you need to also copy the air use &lt;code>//stackair&lt;/code>.&lt;/p>&lt;p>Finally, if you don't need to repeat it and simply move it just a bit towards the right direction, you can use &lt;code>//move N&lt;/code>. The default direction is "me" (towards where you are facing) but you can set one with &lt;code>//move 1 up&lt;/code> for example.&lt;/p>&lt;h3 id="selecting">&lt;a href="#selecting">Selecting&lt;/a>&lt;/h3>&lt;p>You can not only select cuboids. You can also select different shapes, or even just points:&lt;/p>&lt;ul>&lt;li>&lt;code>//sel cuboid&lt;/code> is the default.&lt;/li>&lt;li>&lt;code>//sel extend&lt;/code> expands the default.&lt;/li>&lt;li>&lt;code>//sel poly&lt;/code> first point with left click and right click to add new points.&lt;/li>&lt;li>&lt;code>//sel ellipsoid&lt;/code> first point to select the center and right click to select the different radius.&lt;/li>&lt;li>&lt;code>//sel sphere&lt;/code> first point to select the center and one more right click for the radius.&lt;/li>&lt;li>&lt;code>//sel cyl&lt;/code> for cylinders, first click being the center.&lt;/li>&lt;li>&lt;code>//sel convex&lt;/code> for convex shapes. This one is extremely useful for &lt;code>//curve&lt;/code>.&lt;/li>&lt;/ul>&lt;h2 id="brushes">&lt;a href="#brushes">Brushes&lt;/a>&lt;/h2>&lt;p>Brushes are a way to paint in 3D without first bothering about making a selection, and there are spherical and cylinder brushes with e.g. &lt;code>//brush sphere stone 2&lt;/code>, or the shorter form &lt;code>//br s stone&lt;/code>. For cylinder, one must use &lt;code>cyl&lt;/code> instead &lt;code>sphere&lt;/code>.&lt;/p>&lt;p>There also exists a brush to smooth the terrain which can be enabled on the current item with &lt;code>//br smooth&lt;/code>, which can be used with right-click like any other brush.&lt;/p>&lt;h2 id="clipboard">&lt;a href="#clipboard">Clipboard&lt;/a>&lt;/h2>&lt;p>Finally, you can copy and cut things around like you would do with normal text with &lt;code>//copy&lt;/code> and &lt;code>//cut&lt;/code>. The copy is issued from wherever you issue the command, so when you use &lt;code>//paste&lt;/code>, remember that if you were 4 blocks apart when copying, it will be 4 blocks apart when pasting.&lt;/p>&lt;p>The contents of the clipboard can be flipped to wherever you are looking via &lt;code>//flip&lt;/code>, and can be rotated via the &lt;code>//rotate 90&lt;/code> command (in degrees).&lt;/p>&lt;p>To remove the copy use &lt;code>//clearclipboard&lt;/code>.&lt;/p></content></entry><entry xml:lang="en"><title>An Introduction to Asyncio</title><published>2018-06-13T00:00:00+00:00</published><updated>2023-11-22T00:00:00+00:00</updated><link href="https://lonami.dev/blog/asyncio/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/asyncio/</id><content type="html">&lt;h2 id="index">&lt;a href="#index">Index&lt;/a>&lt;/h2>&lt;ul>&lt;li>&lt;a href="#background">Background&lt;/a>&lt;/li>&lt;li>&lt;a href="#input-output">Input / Output&lt;/a>&lt;/li>&lt;li>&lt;a href="#diving-in">Diving In&lt;/a>&lt;/li>&lt;li>&lt;a href="#a-toy-example">A Toy Example&lt;/a>&lt;/li>&lt;li>&lt;a href="#a-real-example">A Real Example&lt;/a>&lt;/li>&lt;li>&lt;a href="#extra-material">Extra Material&lt;/a>&lt;/li>&lt;/ul>&lt;h2 id="background">&lt;a href="#background">Background&lt;/a>&lt;/h2>&lt;p>After seeing some friends struggle with &lt;code>asyncio&lt;/code> I decided that it could be a good idea to write a blog post using my own words to explain how I understand the world of asynchronous IO. I will focus on Python's &lt;code>asyncio&lt;/code> module but this post should apply to any other language easily.&lt;/p>&lt;p>So what is &lt;code>asyncio&lt;/code> and what makes it good? Why don't we just use the old and known threads to run several parts of the code concurrently, at the same time?&lt;/p>&lt;p>The first reason is that &lt;code>asyncio&lt;/code> makes your code easier to reason about, as opposed to using threads, because the amount of ways in which your code can run grows exponentially. Let's see that with an example. Imagine you have this code:&lt;/p>&lt;pre>&lt;code class="language-python">def method():
	line 1
	line 2
	line 3
	line 4
	line 5
&lt;/code>&lt;/pre>&lt;p>And you start two threads to run the method at the same time. What is the order in which the lines of code get executed? The answer is that you can't know! The first thread can run the entire method before the second thread even starts. Or it could be the first thread that runs after the second thread. Perhaps both run the "line 1", and then the line 2. Maybe the first thread runs lines 1 and 2, and then the second thread only runs the line 1 before the first thread finishes.&lt;/p>&lt;p>As you can see, any combination of the order in which the lines run is possible. If the lines modify some global shared state, that will get messy quickly.&lt;/p>&lt;p>Second, in Python, threads &lt;em>won't&lt;/em> make your code faster most of the time. It will only increase the concurrency of your program (which is okay if it makes many blocking calls), allowing you to run several things at the same time.&lt;/p>&lt;p>If you have a lot of CPU work to do though, threads aren't a real advantage. Indeed, your code will probably run slower under the most common Python implementation, CPython, which makes use of a Global Interpreter Lock (GIL) that only lets a thread run at once. The operations won't run in parallel!&lt;/p>&lt;h2 id="input-output">&lt;a href="#input-output">Input / Output&lt;/a>&lt;/h2>&lt;p>Before we go any further, let's first stop to talk about input and output, commonly known as "IO". There are two main ways to perform IO operations, such as reading or writing from a file or a network socket.&lt;/p>&lt;p>The first one is known as "blocking IO". What this means is that, when you try performing IO, the current application thread is going to &lt;em>block&lt;/em> until the Operative System can tell you it's done. Normally, this is not a problem, since disks are pretty fast anyway, but it can soon become a performance bottleneck. And network IO will be much slower than disk IO!&lt;/p>&lt;pre>&lt;code class="language-python">import socket

# Setup a network socket and a very simple HTTP request.
# By default, sockets are open in blocking mode.
sock = socket.socket()
request = b'''HEAD / HTTP/1.0\r
Host: example.com\r
\r
'''

# "connect" will block until a successful TCP connection
# is made to the host "example.com" on port 80.
sock.connect(('example.com', 80))

# "sendall" will repeatedly call "send" until all the data in "request" is
# sent to the host we just connected, which blocks until the data is sent.
sock.sendall(request)

# "recv" will try to receive up to 1024 bytes from the host, and block until
# there is any data to receive (or empty if the host closes the connection).
response = sock.recv(1024)

# After all those blocking calls, we got out data! These are the headers from
# making a HTTP request to example.com.
print(response.decode())
&lt;/code>&lt;/pre>&lt;p>Blocking IO offers timeouts, so that you can get control back in your code if the operation doesn't finish. Imagine that the remote host doesn't want to reply, your code would be stuck for as long as the connection remains alive!&lt;/p>&lt;p>But wait, what if we make the timeout small? Very, very small? If we do that, we will never block waiting for an answer. That's how asynchronous IO works, and it's the opposite of blocking IO (you can also call it non-blocking IO if you want to).&lt;/p>&lt;p>How does non-blocking IO work if the IO device needs a while to answer with the data? In that case, the operative system responds with "not ready", and your application gets control back so it can do other stuff while the IO device completes your request. It works a bit like this:&lt;/p>&lt;pre>&amp;lt;app&amp;gt; Hey, I would like to read 16 bytes from this file
&amp;lt;OS&amp;gt; Okay, but the disk hasn't sent me the data yet
&amp;lt;app&amp;gt; Alright, I will do something else then
(a lot of computer time passes)
&amp;lt;app&amp;gt; Do you have my 16 bytes now?
&amp;lt;OS&amp;gt; Yes, here they are! "Hello, world !!\n"
&lt;/pre>&lt;p>In reality, you can tell the OS to notify you when the data is ready, as opposed to polling (constantly asking the OS whether the data is ready yet or not), which is more efficient.&lt;/p>&lt;p>But either way, that's the difference between blocking and non-blocking IO, and what matters is that your application gets to run more without ever needing to wait for data to arrive, because the data will be there immediately when you ask, and if it's not yet, your app can do more things meanwhile.&lt;/p>&lt;h2 id="diving-in">&lt;a href="#diving-in">Diving In&lt;/a>&lt;/h2>&lt;p>Now we've seen what blocking and non-blocking IO is, and how threads make your code harder to reason about, but they give concurrency (yet not more speed). Is there any other way to achieve this concurrency that doesn't involve threads? Yes! The answer is &lt;code>asyncio&lt;/code>.&lt;/p>&lt;p>So how does &lt;code>asyncio&lt;/code> help? First we need to understand a very crucial concept before we can dive any deeper, and I'm talking about the &lt;em>event loop&lt;/em>. What is it and why do we need it?&lt;/p>&lt;p>You can think of the event loop as a &lt;em>loop&lt;/em> that will be responsible for calling your &lt;code>async&lt;/code> functions:&lt;/p>&lt;p>&lt;img src="eventloop.svg" alt="The Event Loop">&lt;/p>&lt;p>That's silly you may think. Now not only we run our code but we also have to run some "event loop". It doesn't sound beneficial at all. What are these events? Well, they are the IO events we talked about before!&lt;/p>&lt;p>&lt;code>asyncio&lt;/code>'s event loop is responsible for handling those IO events, such as file is ready, data arrived, flushing is done, and so on. As we saw before, we can make these events non-blocking by setting their timeout to 0.&lt;/p>&lt;p>Let's say you want to read from 10 files at the same time. You will ask the OS to read data from 10 files, and at first none of the reads will be ready. But the event loop will be constantly asking the OS to know which are done, and when they are done, you will get your data.&lt;/p>&lt;p>This has some nice advantages. It means that, instead of waiting for a network request to send you a response or some file, instead of blocking there, the event loop can decide to run other code meanwhile. Whenever the contents are ready, they can be read, and your code can continue. Waiting for the contents to be received is done with the &lt;code>await&lt;/code> keyword, and it tells the loop that it can run other code meanwhile:&lt;/p>&lt;p>&lt;img src="awaitkwd1.svg" alt="Step 1, await keyword">&lt;/p>&lt;p>&lt;img src="awaitkwd2.svg" alt="Step 2, await keyword">&lt;/p>&lt;p>Start reading the code of the event loop and follow the arrows. You can see that, in the beginning, there are no events yet, so the loop calls one of your functions. The code runs until it has to &lt;code>await&lt;/code> for some IO operation to complete, such as sending a request over the network. The method is "paused" until an event occurs (for example, an "event" occurs when the request has been sent completely).&lt;/p>&lt;p>While the first method is busy, the event loop can enter the second method, and run its code until the first &lt;code>await&lt;/code>. But it can happen that the event of the second query occurs before the request on the first method, so the event loop can re-enter the second method because it has already sent the query, but the first method isn't done sending the request yet.&lt;/p>&lt;p>Then, the second method &lt;code>await&lt;/code>'s for an answer, and an event occurs telling the event loop that the request from the first method was sent. The code can be resumed again, until it has to &lt;code>await&lt;/code> for a response, and so on. Here's an explanation with pseudo-code for this process if you prefer:&lt;/p>&lt;pre>&lt;code class="language-python">async def method(request):
    prepare request
    await send request

    await receive request

    process request
    return result

run concurrently (
	method with request 1,
	method with request 2,
)
&lt;/code>&lt;/pre>&lt;p>This is what the event loop will do on the above pseudo-code:&lt;/p>&lt;pre>no events pending, can advance

enter method with request 1
	prepare request
	await sending request
pause method with request 1

no events ready, can advance

enter method with request 2
	prepare request
	await sending request
pause method with request 2

both requests are paused, cannot advance
wait for events
event for request 2 arrives (sending request completed)

enter method with request 2
	await receiving response
pause method with request 2

event for request 1 arrives (sending request completed)

enter method with request 1
	await receiving response
pause method with request 1

...and so on
&lt;/pre>&lt;p>You may be wondering "okay, but threads work for me, so why should I change?". There are some important things to note here. The first is that we only need one thread to be running! The event loop decides when and which methods should run. This results in less pressure for the operating system. The second is that we know when it may run other methods. Those are the &lt;code>await&lt;/code> keywords! Whenever there is one of those, we know that the loop is able to run other things until the resource (again, like network) becomes ready (when a event occurs telling us it's ready to be used without blocking or it has completed).&lt;/p>&lt;p>So far, we already have two advantages. We are only using a single thread so the cost for switching between methods is low, and we can easily reason about where our program may interleave operations.&lt;/p>&lt;p>Another advantage is that, with the event loop, you can easily schedule when a piece of code should run, such as using the method &lt;a href="https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.loop.call_at">&lt;code>loop.call_at&lt;/code>&lt;/a>, without the need for spawning another thread at all.&lt;/p>&lt;p>To tell the &lt;code>asyncio&lt;/code> to run the two methods shown above, we can use &lt;a href="https://docs.python.org/3/library/asyncio-future.html#asyncio.ensure_future">&lt;code>asyncio.ensure_future&lt;/code>&lt;/a>, which is a way of saying "I want the future of my method to be ensured". That is, you want to run your method in the future, whenever the loop is free to do so. This method returns a &lt;code>Future&lt;/code> object, so if your method returns a value, you can &lt;code>await&lt;/code> this future to retrieve its result.&lt;/p>&lt;p>What is a &lt;code>Future&lt;/code>? This object represents the value of something that will be there in the future, but might not be there yet. Just like you can &lt;code>await&lt;/code> your own &lt;code>async def&lt;/code> functions, you can &lt;code>await&lt;/code> these &lt;code>Future&lt;/code>'s.&lt;/p>&lt;p>The &lt;code>async def&lt;/code> functions are also called "coroutines", and Python does some magic behind the scenes to turn them into such. The coroutines can be &lt;code>await&lt;/code>'ed, and this is what you normally do.&lt;/p>&lt;h2 id="a-toy-example">&lt;a href="#a-toy-example">A Toy Example&lt;/a>&lt;/h2>&lt;p>That's all about &lt;code>asyncio&lt;/code>! Let's wrap up with some example code. We will create a server that replies with the text a client sends, but reversed. First, we will show what you could write with normal synchronous code, and then we will port it.&lt;/p>&lt;p>Here is the &lt;strong>synchronous version&lt;/strong>:&lt;/p>&lt;pre>&lt;code class="language-python"># server.py
import socket


def server_method():
	# create a new server socket to listen for connections
	server = socket.socket()

	# bind to localhost:6789 for new connections
	server.bind(('localhost', 6789))

	# we will listen for one client at most
	server.listen(1)

	# *block* waiting for a new client
	client, _ = server.accept()

	# *block* waiting for some data
	data = client.recv(1024)

	# reverse the data
	data = data[::-1]

	# *block* sending the data
	client.sendall(data)

	# close client and server
	server.close()
	client.close()


if __name__ == '__main__':
	# block running the server
	server_method()
&lt;/code>&lt;/pre>&lt;pre>&lt;code class="language-python"># client.py
import socket


def client_method():
	message = b'Hello Server!\n'
	client = socket.socket()

	# *block* trying to stabilish a connection
	client.connect(('localhost', 6789))

	# *block* trying to send the message
	print('Sending', message)
	client.sendall(message)

	# *block* until we receive a response
	response = client.recv(1024)
	print('Server replied', response)

	client.close()


if __name__ == '__main__':
	client_method()
&lt;/code>&lt;/pre>&lt;p>From what we've seen, this code will block on all the lines with a comment above them saying that they will block. This means that for running more than one client or server, or both in the same file, you will need threads. But we can do better, we can rewrite it into &lt;code>asyncio&lt;/code>!&lt;/p>&lt;p>The first step is to mark all your &lt;code>def&lt;/code>initions that may block with &lt;code>async&lt;/code>. This marks them as coroutines, which can be &lt;code>await&lt;/code>ed on.&lt;/p>&lt;p>Second, since we're using low-level sockets, we need to make use of the methods that &lt;code>asyncio&lt;/code> provides directly. If this was a third-party library, this would be just like using their &lt;code>async def&lt;/code>initions.&lt;/p>&lt;p>Here is the &lt;strong>asynchronous version&lt;/strong>:&lt;/p>&lt;pre>&lt;code class="language-python"># server.py
import asyncio
import socket

# get the default "event loop" that we will run
loop = asyncio.get_event_loop()


# notice our new "async" before the definition
async def server_method():
	server = socket.socket()
	server.bind(('localhost', 6789))
	server.listen(1)

	# await for a new client
	# the event loop can run other code while we wait here!
	client, _ = await loop.sock_accept(server)

	# await for some data
	data = await loop.sock_recv(client, 1024)
	data = data[::-1]

	# await for sending the data
	await loop.sock_sendall(client, data)

	server.close()
	client.close()


if __name__ == '__main__':
	# run the loop until "server method" is complete
	loop.run_until_complete(server_method())
&lt;/code>&lt;/pre>&lt;pre>&lt;code class="language-python"># client.py
import asyncio
import socket

loop = asyncio.get_event_loop()


async def client_method():
	message = b'Hello Server!\n'
	client = socket.socket()

	# await to stabilish a connection
	await loop.sock_connect(client, ('localhost', 6789))

	# await to send the message
	print('Sending', message)
	await loop.sock_sendall(client, message)

	# await to receive a response
	response = await loop.sock_recv(client, 1024)
	print('Server replied', response)

	client.close()


if __name__ == '__main__':
	loop.run_until_complete(client_method())
&lt;/code>&lt;/pre>&lt;p>That's it! You can place these two files separately and run, first the server, then the client. You should see output in the client.&lt;/p>&lt;p>The big difference here is that you can easily modify the code to run more than one server or clients at the same time. Whenever you &lt;code>await&lt;/code> the event loop will run other of your code. It seems to "block" on the &lt;code>await&lt;/code> parts, but remember it's actually jumping to run more code, and the event loop will get back to you whenever it can.&lt;/p>&lt;p>In short, you need an &lt;code>async def&lt;/code> to &lt;code>await&lt;/code> things, and you run them with the event loop instead of calling them directly. So this…&lt;/p>&lt;pre>&lt;code class="language-python">def main():
	...  # some code


if __name__ == '__main__':
	main()
&lt;/code>&lt;/pre>&lt;p>…becomes this:&lt;/p>&lt;pre>&lt;code class="language-python">import asyncio


async def main():
	...  # some code


if __name__ == '__main__':
	asyncio.get_event_loop().run_until_complete(main)
&lt;/code>&lt;/pre>&lt;p>This is pretty much how most of your &lt;code>async&lt;/code> scripts will start, running the main method until its completion.&lt;/p>&lt;h2 id="a-real-example">&lt;a href="#a-real-example">A Real Example&lt;/a>&lt;/h2>&lt;p>Let's have some fun with a real library. We'll be using &lt;a href="https://github.com/LonamiWebs/Telethon">Telethon&lt;/a> to broadcast a message to our three best friends, all at the same time, thanks to the magic of &lt;code>asyncio&lt;/code>. We'll dive right into the code, and then I'll explain our new friend &lt;code>asyncio.wait(...)&lt;/code>:&lt;/p>&lt;pre>&lt;code class="language-python"># broadcast.py
import asyncio
import sys

from telethon import TelegramClient

# (you need your own values here, check Telethon's documentation)
api_id = 123
api_hash = '123abc'
friends = [
	'@friend1__username',
	'@friend2__username',
	'@bestie__username'
]

# we will have to await things, so we need an async def
async def main(message):
	# start is a coroutine, so we need to await it to run it
	client = await TelegramClient('me', api_id, api_hash).start()

	# wait for all three client.send_message to complete
	await asyncio.wait([
		client.send_message(friend, message)
		for friend in friends
	])

	# and close our client
	await client.disconnect()


if __name__ == '__main__':
	if len(sys.argv) != 2:
		print('You must pass the message to broadcast!')
		quit()

	message = sys.argv[1]
	asyncio.get_event_loop().run_until_complete(main(message))
&lt;/code>&lt;/pre>&lt;p>Wait… how did that send a message to all three of my friends? The magic is done here:&lt;/p>&lt;pre>&lt;code class="language-python">[
	client.send_message(friend, message)
	for friend in friends
]
&lt;/code>&lt;/pre>&lt;p>This list comprehension creates another list with three coroutines, the three &lt;code>client.send_message(...)&lt;/code>. Then we just pass that list to &lt;code>asyncio.wait&lt;/code>:&lt;/p>&lt;pre>&lt;code class="language-python">await asyncio.wait([...])
&lt;/code>&lt;/pre>&lt;p>This method, by default, waits for the list of coroutines to run until they've all finished. You can read more on the Python &lt;a href="https://docs.python.org/3/library/asyncio-task.html#asyncio.wait">documentation&lt;/a>. Truly a good function to know about!&lt;/p>&lt;p>Now whenever you have some important news for your friends, you can simply &lt;code>python3 broadcast.py 'I bought a car!'&lt;/code> to tell all your friends about your new car! All you need to remember is that you need to &lt;code>await&lt;/code> on coroutines, and you will be good. &lt;code>asyncio&lt;/code> will warn you when you forget to do so.&lt;/p>&lt;h2 id="extra-material">&lt;a href="#extra-material">Extra Material&lt;/a>&lt;/h2>&lt;p>If you want to understand how &lt;code>asyncio&lt;/code> works under the hood, I recommend you to watch this hour-long talk &lt;a href="https://youtu.be/M-UcUs7IMIM">Get to grips with asyncio in Python 3&lt;/a> by Robert Smallshire. In the video, they will explain the differences between concurrency and parallelism, along with others concepts, and how to implement your own &lt;code>asyncio&lt;/code> "scheduler" from scratch.&lt;/p></content></entry><entry xml:lang="en"><title>Atemporal Blog Posts</title><published>2018-02-03T00:00:00+00:00</published><updated>2021-02-19T00:00:00+00:00</updated><link href="https://lonami.dev/blog/posts/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/posts/</id><content type="html">&lt;p>These are some interesting posts and links I've found around the web. I believe they are quite interesting and nice reads, so if you have the time, I encourage you to check some out.&lt;/p>&lt;h2 id="algorithms">&lt;a href="#algorithms">Algorithms&lt;/a>&lt;/h2>&lt;ul>&lt;li>&lt;a href="http://www.tannerhelland.com/4660/dithering-eleven-algorithms-source-code/">Image Dithering: Eleven Algorithms and Source Code&lt;/a>. What does it mean and how to achieve it?&lt;/li>&lt;li>&lt;a href="https://cristian.io/post/bloom-filters/">Idempotence layer on bloom filters&lt;/a>. What are they and how can they help?&lt;/li>&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Huffman_coding">Huffman coding&lt;/a>. This encoding is a simple yet interesting way of compressing information.&lt;/li>&lt;li>&lt;a href="https://github.com/mxgmn/WaveFunctionCollapse">Wave Function Collapse&lt;/a>. Bitmap &amp;amp; tilemap generation from a single example with the help of ideas from quantum mechanics.&lt;/li>&lt;li>&lt;a href="https://blog.nelhage.com/2015/02/regular-expression-search-with-suffix-arrays/">Regular Expression Search with Suffix Arrays&lt;/a>. A way to efficiently search large amounts of text.&lt;/li>&lt;/ul>&lt;h2 id="culture">&lt;a href="#culture">Culture&lt;/a>&lt;/h2>&lt;ul>&lt;li>&lt;a href="https://www.wired.com/story/ideas-joi-ito-robot-overlords/">Why Westerners Fear Robots and the Japanese Do Not&lt;/a>. Explains some possible reasons for this case.&lt;/li>&lt;li>&lt;a href="http://catb.org/~esr/faqs/smart-questions.html">How To Ask Questions The Smart Way&lt;/a>. Some bits of hacker culture and amazing tips on how to ask a question.&lt;/li>&lt;li>&lt;a href="http://apenwarr.ca/log/?m=201809#14">XML, blockchains, and the strange shapes of progress&lt;/a>. Some of history about XML and blockchain.&lt;/li>&lt;li>&lt;a href="https://czep.net/17/legion-of-lobotomized-unices.html">Legion of lobotomized unices&lt;/a>. A time where computers are treated a lot more nicely.&lt;/li>&lt;li>&lt;a href="https://eli.thegreenplace.net/2016/the-expression-problem-and-its-solutions/">The Expression Problem and its solutions&lt;/a>. What is it and what can we do to solve it?&lt;/li>&lt;li>&lt;a href="http://allendowney.blogspot.com/2015/08/the-inspection-paradox-is-everywhere.html">The Inspection Paradox is Everywhere&lt;/a>. Interesting and very common phenomena.&lt;/li>&lt;li>&lt;a href="https://github.com/ChrisKnott/Algojammer">An experimental code editor for writing algorithms&lt;/a>. Contains several links to different tools for reverse debugging.&lt;/li>&lt;li>&lt;a href="http://habitatchronicles.com/2017/05/what-are-capabilities/">What Are Capabilities?&lt;/a> Good ideas with great security implications.&lt;/li>&lt;li>&lt;a href="https://blog.aurynn.com/2015/12/16-contempt-culture">Contempt Culture&lt;/a>. Or why you should not speak crap about your non-favourite programming languages.&lt;/li>&lt;li>&lt;a href="https://www.lesswrong.com/posts/tscc3e5eujrsEeFN4/well-kept-gardens-die-by-pacifism">Well-Kept Gardens Die By Pacifism&lt;/a>. Risks any online community can run into.&lt;/li>&lt;li>&lt;a href="https://ncase.me/">It's Nicky Case!&lt;/a> They make some cool things worth checking out, I really like "we become what we behold".&lt;/li>&lt;li>&lt;a href="https://eev.ee/blog/2016/07/22/on-a-technicality/">On a technicality&lt;/a>. A timeless classic on online communities.&lt;/li>&lt;li>&lt;a href="https://siderea.dreamwidth.org/1209794.html">The Asshole Filter&lt;/a>. You might have one!&lt;/li>&lt;/ul>&lt;h2 id="debate">&lt;a href="#debate">Debate&lt;/a>&lt;/h2>&lt;ul>&lt;li>&lt;a href="https://steemit.com/opensource/@crell/open-source-is-awful">Open Source is awful&lt;/a>. Has some points about why is it bad and how it could improve.&lt;/li>&lt;li>&lt;a href="http://www.mondo2000.com/2018/01/17/pink-lexical-goop-dark-side-autocorrect/">Pink Lexical Goop: The Dark Side of Autocorrect&lt;/a>. It can shape how you think.&lt;/li>&lt;li>&lt;a href="http://blog.ploeh.dk/2015/08/03/idiomatic-or-idiosyncratic/">Idiomatic or idiosyncratic?&lt;/a> Can porting code constructs from other languages have a positive effect?&lt;/li>&lt;li>&lt;a href="https://gamasutra.com/view/news/169296/Indepth_Functional_programming_in_C.php">In-depth: Functional programming in C++&lt;/a>. Is it useful to bother with functional concepts in a language like C++?&lt;/li>&lt;li>&lt;a href="https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/">Notes on structured concurrency, or: Go statement considered harmful&lt;/a>.&lt;/li>&lt;li>&lt;a href="https://queue.acm.org/detail.cfm?id=3212479">C Is Not a Low-level Language&lt;/a>. Could there be alternative programming models designed for more specialized CPUs?&lt;/li>&lt;/ul>&lt;h2 id="food-for-thought">&lt;a href="#food-for-thought">Food for Thought&lt;/a>&lt;/h2>&lt;ul>&lt;li>&lt;a href="https://www.hillelwayne.com/post/divide-by-zero/">1/0 = 0&lt;/a>. Explores why it makes sense to redefine mathemathics under some circumstances, and why it is possible to do so.&lt;/li>&lt;li>&lt;a href="https://jeremykun.com/2018/04/13/for-mathematicians-does-not-mean-equality/">For mathematicians, = does not mean equality&lt;/a>. What other definitions does the equal sign have?&lt;/li>&lt;li>&lt;a href="https://www.lesswrong.com/posts/2MD3NMLBPCqPfnfre/cached-thoughts">Cached Thoughts&lt;/a>. How is it possible that our brains work at all?&lt;/li>&lt;li>&lt;a href="http://tonsky.me/blog/disenchantment/">Software disenchantment&lt;/a>. Faster hardware and slower software is a trend.&lt;ul>&lt;li>&lt;a href="https://blackhole12.com/blog/software-engineering-is-bad-but-it-s-not-that-bad/">Software Engineering Is Bad, But That's Not Why&lt;/a>. This post has some good counterpoints to Software disenchantment.&lt;/li>&lt;/ul>&lt;/li>&lt;li>&lt;a href="http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/">What Color is Your Function?&lt;/a>. Spoiler: can we approach asynchronous IO better?&lt;/li>&lt;li>&lt;a href="https://hackernoon.com/im-harvesting-credit-card-numbers-and-passwords-from-your-site-here-s-how-9a8cb347c5b5">I'm harvesting credit card numbers and passwords from your site&lt;/a>. A word of warning when mindlessly adding dependencies.&lt;/li>&lt;li>&lt;a href="https://medium.com/message/everything-is-broken-81e5f33a24e1">Everything Is Broken&lt;/a>. Some of the (probable) truths about our world.&lt;/li>&lt;li>&lt;a href="http://johnsalvatier.org/blog/2017/reality-has-a-surprising-amount-of-detail">Reality has a surprising amount of detail&lt;/a>.&lt;/li>&lt;/ul>&lt;h2 id="funny">&lt;a href="#funny">Funny&lt;/a>&lt;/h2>&lt;ul>&lt;li>&lt;a href="http://thedailywtf.com/articles/We-Use-BobX">We Use BobX&lt;/a>. BobX.&lt;/li>&lt;li>&lt;a href="http://thedailywtf.com/articles/the-inner-json-effect">The Inner JSON Effect&lt;/a>. For some reason, custom languages are in.&lt;/li>&lt;li>&lt;a href="https://thedailywtf.com/articles/exponential-backup">Exponential Backup&lt;/a>. Far better than git.&lt;/li>&lt;li>&lt;a href="https://thedailywtf.com/articles/ITAPPMONROBOT">ITAPPMONROBOT&lt;/a>. Solving software problems with hardware.&lt;/li>&lt;li>&lt;a href="https://thedailywtf.com/articles/a-tapestry-of-threads">A Tapestry of Threads&lt;/a>. More threads must mean faster code, right?&lt;/li>&lt;li>&lt;a href="https://medium.com/commitlog/a-brief-totally-accurate-history-of-programming-languages-cd93ec806124">A Brief Totally Accurate History Of Programming Languages&lt;/a>. Don't take offense for it!&lt;/li>&lt;/ul>&lt;h2 id="graphics">&lt;a href="#graphics">Graphics&lt;/a>&lt;/h2>&lt;ul>&lt;li>&lt;a href="http://shaunlebron.github.io/visualizing-projections/">Visualizing Projections&lt;/a>. Small post about different projection methods.&lt;/li>&lt;li>&lt;a href="http://www.iquilezles.org/www/index.htm">Inigo Quilez :: fractals, computer graphics, mathematics, shaders, demoscene and more&lt;/a> A &lt;em>lot&lt;/em> of useful and quality articles regarding computer graphics.&lt;/li>&lt;/ul>&lt;h2 id="history">&lt;a href="#history">History&lt;/a>&lt;/h2>&lt;ul>&lt;li>&lt;a href="https://twobithistory.org/2018/08/18/ada-lovelace-note-g.html">What Did Ada Lovelace's Program Actually Do?&lt;/a>. And other characters that took part in the beginning's of programming.&lt;/li>&lt;li>&lt;a href="https://chrisdown.name/2018/01/02/in-defence-of-swap.html">In defence of swap: common misconceptions&lt;/a>. Swap is still an useful concept.&lt;/li>&lt;li>&lt;a href="https://www.pacifict.com/Story/">The Graphing Calculator Story&lt;/a>. A great classic Apple tale.&lt;/li>&lt;li>&lt;a href="https://twobithistory.org/2018/10/14/lisp.html">How Lisp Became God's Own Programming Language&lt;/a>. Lisp as a foundational programming language.&lt;/li>&lt;/ul>&lt;h2 id="motivational">&lt;a href="#motivational">Motivational&lt;/a>&lt;/h2>&lt;ul>&lt;li>&lt;a href="https://www.joelonsoftware.com/2002/01/06/fire-and-motion/">Fire And Motion&lt;/a>. What does actually take to get things done?&lt;/li>&lt;li>&lt;a href="https://realmensch.org/2017/08/25/the-parable-of-the-two-programmers/">The Parable of the Two Programmers&lt;/a>. This tale is about two different types of programmer and their respective endings in a company, illustrating how the one you wouldn't expect to actually ends in a better situation.&lt;/li>&lt;li>&lt;a href="https://byorgey.wordpress.com/2018/05/06/conversations-with-a-six-year-old-on-functional-programming/">Conversations with a six-year-old on functional programming&lt;/a>. Little kids today can be really interested in technological topics.&lt;/li>&lt;li>&lt;a href="https://bulletproofmusician.com/how-many-hours-a-day-should-you-practice/">How Many Hours a Day Should You Practice?&lt;/a>. While the article is about music, it applies to any other areas.&lt;/li>&lt;li>&lt;a href="http://nathanmarz.com/blog/suffering-oriented-programming.html">Suffering-oriented programming&lt;/a>. A possibly new approach on how you could tackle your new projects.&lt;/li>&lt;li>&lt;a href="https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/">Things You Should Never Do, Part I&lt;/a>. There is no need to rewrite your code.&lt;/li>&lt;/ul>&lt;h2 id="optimization">&lt;a href="#optimization">Optimization&lt;/a>&lt;/h2>&lt;ul>&lt;li>&lt;a href="http://blog.llvm.org/2011/05/what-every-c-programmer-should-know.html">What Every C Programmer Should Know About Undefined Behavior #1/3&lt;/a>. Explains what undefined behaviour is and why it makes sense.&lt;/li>&lt;li>&lt;a href="http://ridiculousfish.com/blog/posts/labor-of-division-episode-i.html">Labor of Division (Episode I)&lt;/a>. Some tricks to divide without division.&lt;/li>&lt;li>&lt;a href="http://blog.moertel.com/posts/2013-12-14-great-old-timey-game-programming-hack.html">A Great Old-Timey Game-Programming Hack&lt;/a>. Abusing instructions to make games playable even on the slowest hardware.&lt;/li>&lt;li>&lt;a href="https://web.archive.org/web/20191213224640/https://people.eecs.berkeley.edu/~sangjin/2012/12/21/epoll-vs-kqueue.html">Scalable Event Multiplexing: epoll vs kqueue&lt;/a>. How good OS primitives can really help performance and scability.&lt;/li>&lt;li>&lt;a href="https://adamdrake.com/command-line-tools-can-be-235x-faster-than-your-hadoop-cluster.html">Command-line Tools can be 235x Faster than your Hadoop Cluster&lt;/a>. Or how to use the right tool for the right job.&lt;/li>&lt;li>&lt;a href="https://nullprogram.com/blog/2018/05/27/">When FFI Function Calls Beat Native C&lt;/a>. How lua beat C at it and the explanation behind it.&lt;/li>&lt;li>&lt;a href="http://igoro.com/archive/gallery-of-processor-cache-effects/">Gallery of Processor Cache Effects&lt;/a>. Knowing a few things about the cache can make a big difference.&lt;/li>&lt;/ul></content></entry><entry xml:lang="en"><title>Graphs</title><published>2017-06-02T00:00:00+00:00</published><updated>2017-06-02T00:00:00+00:00</updated><link href="https://lonami.dev/blog/graphs/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/graphs/</id><content type="html">&lt;noscript>There are a few things which won't render unless you enable JavaScript. No tracking, I promise!&lt;/noscript>&lt;blockquote>&lt;p>¿No hablas inglés? &lt;a href="/golb/graphs-es">Lee la versión en español&lt;/a>.&lt;/p>&lt;/blockquote>&lt;p>Let's imagine we have 5 bus stations, which we'll denote by ((s_i)):&lt;/p>&lt;div class="matrix"> ' s_1 ' s_2 ' s_3 ' s_4 ' s_5 \\
s_1 ' ' V ' ' ' \\
s_2 ' V ' ' ' ' V \\
s_3 ' ' ' ' V ' \\
s_4 ' ' V ' V ' ' \\
s_5 ' V ' ' ' V '
&lt;/div>&lt;p>This is known as a &lt;em>"table of direct interconnections"&lt;/em>. The ((V)) represent connected paths. For instance, on the first row starting at ((s_1)), reaching the ((V)), allows us to turn up to get to ((s_2)).&lt;/p>&lt;p>We can see the above table represented in a more graphical way:&lt;/p>&lt;p>&lt;img src="example1.svg" alt="Table 1 as a Graph">&lt;/p>&lt;p>This type of graph is called, well, a graph, and it's a directed graph (or digraph), since the direction on which the arrows go does matter. It's made up of vertices, joined together by edges (also known as lines or directed &lt;strong>arcs&lt;/strong>).&lt;/p>&lt;p>One can walk from a node to another through different &lt;strong>paths&lt;/strong>. For example, ((s_4 $rightarrow s_2 $rightarrow s_5)) is an indirect path of &lt;strong>order&lt;/strong> two, because we must use two edges to go from ((s_4)) to ((s_5)).&lt;/p>&lt;p>Let's now represent its &lt;strong>adjacency&lt;/strong> matrix called A which represents the same table, but uses 1 instead V to represent a connection:&lt;/p>&lt;div class="matrix"> 0 ' 1 ' 0 ' 0 ' 0 \\
1 ' 0 ' 0 ' 0 ' 1 \\
0 ' 0 ' 0 ' 1 ' 0 \\
0 ' 1 ' 1 ' 0 ' 0 \\
1 ' 0 ' 0 ' 1 ' 0
&lt;/div>&lt;p>This way we can see how the ((a_{2,1})) element represents the connection ((s_2 $rightarrow s_1)), and the ((a_{5,1})) element the ((s_5 $rightarrow s_1)) connection, etc.&lt;/p>&lt;p>In general, ((a_{i,j})) represents a connection from ((s_i $rightarrow s_j))as long as ((a_{i,j}$geq 1)).&lt;/p>&lt;p>Working with matrices allows us to have a computable representation of any graph, which is very useful.&lt;/p>&lt;hr />&lt;p>Graphs have a lot of interesting properties besides being representable by a computer. What would happen if, for instance, we calculated ((A^2))? We obtain the following matrix:&lt;/p>&lt;div class="matrix"> 1 ' 0 ' 0 ' 0 ' 1 \\
1 ' 1 ' 0 ' 1 ' 0 \\
0 ' 1 ' 1 ' 0 ' 0 \\
1 ' 0 ' 0 ' 1 ' 1 \\
0 ' 2 ' 1 ' 0 ' 0
&lt;/div>&lt;p>We can interpret this as the paths of order &lt;strong>two&lt;/strong>. But what does the element ((a_{5,2}=2)) represent? It indicates the amount of possible ways to go from ((s_5 $rightarrow s_i $rightarrow s_2)).&lt;/p>&lt;p>One can manually multiply the involved row and column to determine which element is the one we need to pass through, this way we have the row (([1 0 0 1 0])) and the column (([1 0 0 1 0])) (on vertical). The elements ((s_i·$geq 1)) are ((s_1)) and ((s_4)). This is, we can go from ((s_5)) to ((s_2)) via ((s_5 $rightarrow s_1 $rightarrow s_2)) or via ((s_5 $rightarrow s_4 $rightarrow s_2)):&lt;/p>&lt;p>&lt;img src="example2.svg" alt="Previous table as a graph">&lt;/p>&lt;p>It's important to note that graphs to not consider self-connections, this is, ((s_i $rightarrow s_i)) is not allowed; neither we work with multigraphs here (those which allow multiple connections, for instance, an arbitrary number ((n)) of times).&lt;/p>&lt;div class="matrix"> 1 ' 1 ' 0 ' 1 ' 0 \\
1 ' 2 ' #1# ' 0 ' 1 \\
1 ' 0 ' 0 ' 1 ' 1 \\
1 ' 2 ' 1 ' 1 ' 0 \\
2 ' 0 ' 0 ' 1 ' 2
&lt;/div>&lt;p>We can see how the first ((1)) just appeared on the element ((a_{2,3})), which means that the shortest path to it is at least of order three.&lt;/p>&lt;hr />&lt;p>A graph is said to be &lt;strong>strongly connected&lt;/strong> as long as there is a way to reach all its elements.&lt;/p>&lt;p>We can see all the available paths until now by simply adding up all the direct and indirect ways to reach a node, so for now, we can add ((A + A^2 + A^3)) in such a way that:&lt;/p>&lt;div class="matrix"> 2 ' 2 ' 0 ' 1 ' 1 \\
3 ' 3 ' 1 ' 1 ' 3 \\
1 ' 1 ' 1 ' 2 ' 1 \\
2 ' 3 ' 2 ' 2 ' 1 \\
3 ' 2 ' 1 ' 2 ' 2
&lt;/div>&lt;p>There isn't a connection between ((s_1)) and ((s_3)) yet. If we were to calculate ((A^4)):&lt;/p>&lt;div class="matrix"> 1 ' 2 ' 1 ' ' \\
' ' ' ' \\
' ' ' ' \\
' ' ' ' \\
' ' ' '
&lt;/div>&lt;p>We don't need to calculate anymore. We now know that the graph is strongly connected!&lt;/p>&lt;hr />&lt;p>Congratulations! You've completed this tiny introduction to graphs. Now you can play around with them and design your own connections.&lt;/p>&lt;p>Hold the left mouse button on the above area and drag it down to create a new node, or drag a node to this area to delete it.&lt;/p>&lt;p>To create new connections, hold the right mouse button on the node you want to start with, and drag it to the node you want it to be connected to.&lt;/p>&lt;p>To delete the connections coming from a specific node, middle click it.&lt;/p>&lt;table>&lt;tr>&lt;td style="width:100%;">&lt;button onclick="resetConnections()">Reset connections&lt;/button>&lt;button onclick="clearNodes()">Clear all the nodes&lt;/button>&lt;br>&lt;br>&lt;label for="matrixOrder">Show matrix of order:&lt;/label>&lt;input id="matrixOrder" type="number" min="1" max="5"
value="1" oninput="updateOrder()">&lt;br>&lt;label for="matrixAccum">Show accumulated matrix&lt;/label>&lt;input id="matrixAccum" type="checkbox" onchange="updateOrder()">&lt;br>&lt;br>&lt;div>&lt;table id="matrixTable">&lt;/table>&lt;/div>&lt;p>&lt;/td>&lt;td> &lt;canvas id="canvas" width="400" height="400" oncontextmenu="return false;"> Looks like your browser won't let you see this fancy example :(
&lt;/canvas> &lt;br> &lt;/td>&lt;/tr>&lt;/table>&lt;/p>&lt;p>&lt;script src="tinyparser.js">&lt;/script>&lt;script src="enhancements.js">&lt;/script>&lt;script src="graphs.js">&lt;/script> &lt;/p></content></entry><entry xml:lang="en"><title>Installing NixOS</title><published>2017-05-13T00:00:00+00:00</published><updated>2019-02-16T00:00:00+00:00</updated><link href="https://lonami.dev/blog/installing-nixos/" rel="alternate" type="text/html"/><id>https://lonami.dev/blog/installing-nixos/</id><content type="html">&lt;h2 id="update">&lt;a href="#update">Update&lt;/a>&lt;/h2>&lt;p>&lt;em>Please see &lt;a href="/blog/installing-nixos-2">my followup post with NixOS&lt;/a> for a far better experience with it&lt;/em>&lt;/p>&lt;hr>&lt;p>Today I decided to install &lt;a href="http://nixos.org/">NixOS&lt;/a> as a recommendation, a purely functional Linux distribution, since &lt;a href="https://xubuntu.org/">Xubuntu&lt;/a> kept crashing. Here's my journey, and how I managed to install it from a terminal for the first time in my life. Steps aren't hard, but they may not seem obvious at first.&lt;/p>&lt;ul>&lt;li>&lt;p>Grab the Live CD, burn it on a USB stick and boot. I recommend using &lt;a href="https://etcher.io/">Etcher&lt;/a>.&lt;/p>&lt;/li>&lt;li>&lt;p>Type &lt;code>systemctl start display-manager&lt;/code> and wait.&lt;a href="#fn:1">&lt;sup id="fnref:1">↪1&lt;/sup>&lt;/a>&lt;/p>&lt;/li>&lt;li>&lt;p>Open both the manual and the &lt;code>konsole&lt;/code>.&lt;/p>&lt;/li>&lt;li>&lt;p>Connect to the network using the GUI.&lt;/p>&lt;/li>&lt;li>&lt;p>Create the disk partitions by using &lt;code>fdisk&lt;/code>.&lt;/p>&lt;p>You can list them with &lt;code>fdisk -l&lt;/code>, modify a certain drive with &lt;code>fdisk /dev/sdX&lt;/code> (for instance, &lt;code>/dev/sda&lt;/code>) and follow the instructions.&lt;/p>&lt;p>To create the file system, use &lt;code>mkfs.ext4 -L &amp;lt;label&amp;gt; /dev/sdXY&lt;/code> and swap with &lt;code>mkswap -L &amp;lt;label&amp;gt; /dev/sdXY&lt;/code>.&lt;/p>&lt;p>The EFI partition should be done with &lt;code>mkfs.vfat&lt;/code>.&lt;/p>&lt;/li>&lt;li>&lt;p>Mount the target to &lt;code>/mnt&lt;/code> e.g. if the label was &lt;code>nixos&lt;/code>, &lt;code>mount /dev/disk/by-label/nixos /mnt&lt;/code>&lt;/p>&lt;/li>&lt;li>&lt;p>&lt;code>mkdir /mnt/boot&lt;/code> and then mount your EFI partition to it.&lt;/p>&lt;/li>&lt;li>&lt;p>Generate a configuration template with &lt;code>nixos-generate-config --root /mnt&lt;/code>, and modify it with &lt;code>nano /etc/nixos/configuration.nix&lt;/code>.&lt;/p>&lt;/li>&lt;li>&lt;p>While modifying the configuration, make sure to add &lt;code>boot.loader.grub.device = "/dev/sda"&lt;/code>&lt;/p>&lt;/li>&lt;li>&lt;p>More useful configuration things are:&lt;/p>&lt;ul>&lt;li>Uncomment the whole &lt;code>i18n&lt;/code> block.&lt;/li>&lt;li>Add some essential packages like &lt;code>environment.systemPackages = with pkgs; [wget git firefox pulseaudio networkmanagerapplet];&lt;/code>.&lt;/li>&lt;li>If you want to use XFCE, add &lt;code>services.xserver.desktopManager.xfce.enable = true;&lt;/code>, otherwise, you don't need &lt;code>networkmanagerapplet&lt;/code> either. Make sure to add &lt;code>networking.networkmanager.enable = true;&lt;/code> too.&lt;/li>&lt;li>Define some user for yourself (modify &lt;code>guest&lt;/code> name) and use a UID greater than 1000. Also, add yourself to &lt;code>extraGroups = ["wheel" "networkmanager"];&lt;/code> (the first to be able to &lt;code>sudo&lt;/code>, the second to use network related things).&lt;/li>&lt;/ul>&lt;/li>&lt;li>&lt;p>Run &lt;code>nixos-install&lt;/code>. If you ever modify that file again, to add more packages for instance (this is how they're installed), run &lt;code>nixos-rebuild switch&lt;/code> (or use &lt;code>test&lt;/code> to test but don't boot to it, or &lt;code>boot&lt;/code> not to switch but to use on next boot.&lt;/p>&lt;/li>&lt;li>&lt;p>&lt;code>reboot&lt;/code>.&lt;/p>&lt;/li>&lt;li>&lt;p>Login as &lt;code>root&lt;/code>, and set a password for your user with &lt;code>passwd &amp;lt;user&amp;gt;&lt;/code>. Done!&lt;/p>&lt;/li>&lt;/ul>&lt;p>I enjoyed the process of installing it, and it's really cool that it has versioning and is so clean to keep track of which packages you install. But not being able to run arbitrary binaries by default is something very limitting in my opinion, though they've done a good job.&lt;/p>&lt;p>I'm now back to Xubuntu, with a fresh install.&lt;/p>&lt;h2 id="update">&lt;a href="#update">Update&lt;/a>&lt;/h2>&lt;p>It is not true that "they don't allow running arbitrary binaries by default", as pointed out in their &lt;a href="https://nixos.org/nixpkgs/manual/#sec-fhs-environments">manual, buildFHSUserEnv&lt;/a>:&lt;/p>&lt;blockquote>&lt;p>&lt;code>buildFHSUserEnv&lt;/code> provides a way to build and run FHS-compatible lightweight sandboxes. It creates an isolated root with bound &lt;code>/nix/store&lt;/code>, so its footprint in terms of disk space needed is quite small. This allows one to run software which is hard or unfeasible to patch for NixOS -- 3rd-party source trees with FHS assumptions, games distributed as tarballs, software with integrity checking and/or external self-updated binaries. It uses Linux namespaces feature to create temporary lightweight environments which are destroyed after all child processes exit, without root user rights requirement.&lt;/p>&lt;/blockquote>&lt;p>Thanks to &lt;a href="https://github.com/bb010g">@bb010g&lt;/a> for pointing this out.&lt;/p>&lt;h2 id="notes">&lt;a href="#notes">Notes&lt;/a>&lt;/h2>&lt;p id="fn:1" class="footnote-definition">&lt;span>1&lt;/span> The keyboard mapping is a bit strange. On my Spanish keyboard, the keys were as follows:&amp;nbsp;&lt;a href="#fnref:1">↩&lt;/a>&lt;/p>&lt;table>&lt;thead>&lt;tr>&lt;th>Keyboard&lt;/th>&lt;th>Maps to&lt;/th>&lt;th>Shift&lt;/th>&lt;/tr>&lt;/thread>&lt;tbody>&lt;tr>&lt;td>&lt;kbd>'&lt;/kbd>&lt;/td>&lt;td>&lt;kbd>-&lt;/kbd>&lt;/td>&lt;td>&lt;kbd>_&lt;/kbd>&lt;/td>&lt;/tr>&lt;tr>&lt;td>&lt;kbd>´&lt;/kbd>&lt;/td>&lt;td>&lt;kbd>'&lt;/kbd>&lt;/td>&lt;td>&lt;kbd>"&lt;/kbd>&lt;/td>&lt;/tr>&lt;tr>&lt;td>&lt;kbd>`&lt;/kbd>&lt;/td>&lt;td>&lt;kbd>[&lt;/kbd>&lt;/td>&lt;td>&lt;/td>&lt;/tr>&lt;tr>&lt;td>&lt;kbd>+&lt;/kbd>&lt;/td>&lt;td>&lt;kbd>]&lt;/kbd>&lt;/td>&lt;td>&lt;/td>&lt;/tr>&lt;tr>&lt;td>&lt;kbd>¡&lt;/kbd>&lt;/td>&lt;td>&lt;kbd>=&lt;/kbd>&lt;/td>&lt;td>&lt;/td>&lt;/tr>&lt;tr>&lt;td>&lt;kbd>-&lt;/kbd>&lt;/td>&lt;td>&lt;kbd>/&lt;/kbd>&lt;/td>&lt;td>&lt;/td>&lt;/tr>&lt;tr>&lt;td>&lt;kbd>ñ&lt;/kbd>&lt;/td>&lt;td>&lt;kbd>;&lt;/kbd>&lt;/td>&lt;td>&lt;/td>&lt;/tr>&lt;/tbody>&lt;/table></content></entry></feed>